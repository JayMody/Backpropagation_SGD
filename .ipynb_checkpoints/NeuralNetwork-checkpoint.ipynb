{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent and Backpropagation\n",
    "### Understanding the math behind gradient descent and how to implement backprogagation in python\n",
    "--------------------\n",
    "**Author: Jay Mody**\n",
    "\n",
    "**Required Knowledge:**\n",
    "- Basic Python Skills\n",
    "- Numpy\n",
    "- Calculus (derivatives, gradients, chain rule)\n",
    "- Linear Algebra (matrices, matrix multiplication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Imports ####\n",
    "# import sys\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# from matplotlib.colors import ListedColormap\n",
    "# from sklearn.datasets import make_blobs\n",
    "\n",
    "# # #### Data Parameters ####\n",
    "# n_features = 784  # n_input_nodes\n",
    "# n_classes = 10 # n_output_nodes\n",
    "\n",
    "# colors_list = ['red', 'cyan', 'magenta', 'green', 'black', 'blue']\n",
    "# colors = ListedColormap(colors_list)\n",
    "\n",
    "# ##  Loading Data  ##\n",
    "# mnist = tf.keras.datasets.mnist\n",
    "# (x_train, y_train_raw), (x_test, y_test_raw) = mnist.load_data()\n",
    "\n",
    "# # Flattening for mlp\n",
    "# x_train = x_train.reshape(x_train.shape[0], 784)\n",
    "# x_test = x_test.reshape(x_test.shape[0], 784)\n",
    "\n",
    "# print(x_train.shape) #--> (60000, 28, 28)\n",
    "# print(y_train_raw.shape) #--> (60000,)\n",
    "# print(x_test.shape) #--> (10000, 28, 28)\n",
    "# print(y_test_raw.shape) #--> (10000,)\n",
    "\n",
    "# ##  Normalizing Data  ##\n",
    "# normal_val = 255\n",
    "\n",
    "# x_train = np.divide(x_train, normal_val)\n",
    "# x_test = np.divide(x_test, normal_val)\n",
    "\n",
    "# ##  Splitting Data into Validation and Train Sets  ##\n",
    "# percent_train = 0.80\n",
    "\n",
    "# train_samples = int(percent_train * len(x_train))\n",
    "# val_x = x_train[train_samples:]\n",
    "# x_train = x_train[:train_samples]\n",
    "\n",
    "# target_samples = int(percent_train * len(y_train_raw))\n",
    "# val_y = y_train_raw[target_samples:]\n",
    "# y_train_raw = y_train_raw[:target_samples]\n",
    "\n",
    "# ## One Hot Encoding Y_train for training ##\n",
    "# y_train = np.zeros((y_train_raw.shape[0], n_classes))\n",
    "# y_train[np.arange(y_train_raw.size), y_train_raw] = 1\n",
    "\n",
    "# ## One Hot Encoding Y_test for testing ##\n",
    "# y_test = np.zeros((y_test_raw.shape[0], n_classes))\n",
    "# y_test[np.arange(y_test_raw.size), y_test_raw] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Imports ####\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "\n",
    "#### Data Parameters ####\n",
    "n_features = 2  # n_input_nodes\n",
    "n_classes = 2 # n_output_nodes\n",
    "\n",
    "n_training_samples = 300 \n",
    "n_testing_samples = 200\n",
    "\n",
    "cluster_std = 0.5\n",
    "center_box = (-2, 2)\n",
    "\n",
    "colors_list = ['red', 'cyan', 'magenta', 'green', 'black', 'blue']\n",
    "colors = ListedColormap(colors_list)\n",
    "\n",
    "seed = 45\n",
    "\n",
    "\n",
    "\n",
    "#### Training Data ####\n",
    "x_train, y_train_raw = make_blobs(n_samples = n_training_samples, \n",
    "                                  n_features = n_features,\n",
    "                                  centers = n_classes,\n",
    "                                  center_box = center_box,\n",
    "                                  cluster_std =  cluster_std, \n",
    "                                  random_state = seed)\n",
    "\n",
    "# One-hot encodes the y values (categorically encoding the data)\n",
    "y_train = np.zeros((y_train_raw.shape[0], n_classes))\n",
    "y_train[np.arange(y_train_raw.size), y_train_raw] = 1\n",
    "\n",
    "\n",
    "\n",
    "#### Testing Data ####\n",
    "x_test, y_test_raw = make_blobs(n_samples = n_testing_samples + n_training_samples, \n",
    "                            n_features = n_features,\n",
    "                            centers = n_classes,\n",
    "                            center_box = center_box,\n",
    "                            cluster_std =  cluster_std, \n",
    "                            random_state = seed)\n",
    "x_test = x_test[-n_testing_samples:]\n",
    "y_test_raw = y_test_raw[-n_testing_samples:]\n",
    "\n",
    "# One-hot encodes the y values (categorically encoding the data)\n",
    "y_test = np.zeros((y_test_raw.shape[0], n_classes))\n",
    "y_test[np.arange(y_test_raw.size), y_test_raw] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey = True, sharex = True, figsize=(16, 6))\n",
    "\n",
    "_ = ax1.scatter(x_train[:, 0], x_train[:, 1], c = y_train_raw, cmap = colors)\n",
    "_ = ax1.set_title('training set')\n",
    "\n",
    "_ = ax2.scatter(x_test[:, 0], x_test[:, 1], c = y_test_raw, cmap = colors)\n",
    "_ = ax2.set_title('testing set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Neural Network Class ####\n",
    "class NeuralNetwork:\n",
    "    ##### Constructor ####\n",
    "    def __init__(self, n_input_nodes, hidden_nodes, n_output_nodes, lr):\n",
    "        ## Network ##\n",
    "        self.n_input_nodes = n_input_nodes\n",
    "        self.n_output_nodes = n_output_nodes\n",
    "        \n",
    "        self.nodes = hidden_nodes\n",
    "        self.nodes.insert(0, n_input_nodes)\n",
    "        self.nodes.append(n_output_nodes)\n",
    "        \n",
    "        ## Weights and Biases##\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        for i in range(1, len(self.nodes)):\n",
    "            self.weights.append(np.random.uniform(-1.0, 1.0, (self.nodes[i-1], self.nodes[i])))\n",
    "            self.biases.append(np.random.uniform(-1.0, 1.0, (1, self.nodes[i])))\n",
    "        \n",
    "        ## Learning Rate ##\n",
    "        self.lr = lr\n",
    "        \n",
    "        ## Activation Functions ##\n",
    "        # Linear Activation\n",
    "        self.linear = lambda x: x\n",
    "        self.d_linear = lambda x: np.ones(x.shape)\n",
    "        \n",
    "        # Relu Activation\n",
    "        def relu(x):\n",
    "            x[x<0] = 0\n",
    "            return x\n",
    "        def d_relu(out):\n",
    "            out: x[x>0] = 1\n",
    "            return out\n",
    "        self.relu = relu\n",
    "        self.d_relu = d_relu\n",
    "            \n",
    "        # Sigmoid Activation\n",
    "        self.sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "        self.d_sigmoid = lambda out: out * (1 - out)  # assumes out is tanh(x)\n",
    "        \n",
    "        # Hyperbolic Tangent Activation\n",
    "        self.tanh = lambda x: np.tanh(x)\n",
    "        self.d_tanh = lambda out: 1 - out**2 # assumes out is tanh(x)\n",
    "        \n",
    "    def getWeights(self):\n",
    "        return self.weights.copy()\n",
    "    def getBiases(self):\n",
    "        return self.biases.copy()\n",
    "    \n",
    "    def setWeights(self, weights):\n",
    "        self.weights = weights.copy()\n",
    "    def setBiases(self, biases):\n",
    "        self.biases = biases.copy()\n",
    "    \n",
    "    #### Feed Forward ####\n",
    "    def feed_forward(self, X):\n",
    "        outputs = []\n",
    "        \n",
    "        logits = np.dot(X, self.weights[0]) + self.biases[0]\n",
    "        \n",
    "        for i in range(1, len(self.nodes) - 1):\n",
    "            out = self.relu(logits)\n",
    "            outputs.append(out)\n",
    "            logits = np.dot(out, self.weights[i]) + self.biases[i]\n",
    "        \n",
    "        out = self.sigmoid(logits)\n",
    "        outputs.append(out)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    #### Backpropagation ####\n",
    "    def backpropagation(self, X, y, outputs):\n",
    "        weights_gradients = []\n",
    "        biases_gradients = []\n",
    "        \n",
    "        d1 = y - outputs[-1]\n",
    "        d2 = self.d_sigmoid(outputs[-1])\n",
    "        error = d1 * d2\n",
    "        \n",
    "        grad = outputs[-2].T * error \n",
    "        weights_gradients.append(grad)\n",
    "        biases_gradients.append(error)\n",
    "        \n",
    "        for i in range(len(outputs) - 2, 1, -1):\n",
    "            d = self.d_relu(outputs[i])\n",
    "            error = np.dot(error, self.weights[i+1].T) * d\n",
    "            \n",
    "            grad = outputs[i-1].T * error \n",
    "            weights_gradients.append(grad)\n",
    "            biases_gradients.append(error)\n",
    "        \n",
    "        return weights_gradients, biases_gradients\n",
    "    \n",
    "    #### Training ####\n",
    "    def train(self, features, targets):\n",
    "        # Batch Size for weight update step\n",
    "        batch_size = features.shape[0]\n",
    "        \n",
    "        # Delta Weights Variables\n",
    "        delta_weights = [np.zeros(weight.shape) for weight in self.weights]\n",
    "        delta_biases = [np.zeros(bias.shape) for bias in self.biases]\n",
    "        \n",
    "        # For every data point, forward pass, backpropogation, store weights change\n",
    "        for X, y in zip(features, targets):\n",
    "            # Forward pass\n",
    "            X = X.reshape(1, X.shape[0])\n",
    "            outputs = self.feed_forward(X)\n",
    "            \n",
    "            # Back propogation\n",
    "            weights_gradients, biases_gradients = self.backpropagation(X, y, outputs)\n",
    "            \n",
    "            for i in range(len(weights_gradients)):\n",
    "                delta_weights[-(i+1)] += weights_gradients[i]\n",
    "                delta_biases[-(i+1)] += biases_gradients[i]\n",
    "        \n",
    "        print('\\nweight before', self.weights[-1][0], sep = '\\t')\n",
    "        print('gradient', (self.lr * delta_weights[-1][0]) / batch_size, sep = '\\t')\n",
    "        for i in range(len(delta_weights)):\n",
    "            self.weights[i] += (self.lr * delta_weights[i]) / batch_size\n",
    "            self.biases[i] += (self.lr * delta_biases[i]) / batch_size\n",
    "        print('weight after', self.weights[-1][0], sep = '\\t')\n",
    "\n",
    "    #### Testing Methods ####\n",
    "    def predict(self, X):\n",
    "        # Gives prediction\n",
    "        return self.feed_forward(X)[-1]\n",
    "    \n",
    "    def test(self, features, targets):\n",
    "        predictions = self.predict(features)\n",
    "\n",
    "        n_correct = 0\n",
    "        for i in range(len(predictions)):\n",
    "            prediction = np.argmax(predictions[i])\n",
    "            correct = np.argmax(targets[i])\n",
    "\n",
    "            if prediction == correct:\n",
    "                n_correct += 1\n",
    "\n",
    "        return n_correct / len(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, y_hat):\n",
    "    return np.mean((y-y_hat)**2)\n",
    "\n",
    "def generate_area_map(features, points_per_int = 10, alpha = 0.2):\n",
    "    ###  Area Map Set  ###\n",
    "    xstart = int((features[:, 0].min() - 1) * points_per_int) # min start point of the x data\n",
    "    xrang = int((features[:, 0].max() + 1) * points_per_int - xstart) # range of the data on x\n",
    "\n",
    "    ystart = int((features[:, 1].min()  - 1) * points_per_int) # min start poing of the y data\n",
    "    yrang = int((features[:, 1].max() + 1) * points_per_int - ystart) # range of teh data on y\n",
    "\n",
    "    # Creates an array with all the coordinates of area map set\n",
    "    area_map_set = np.array([[x + xstart, y + ystart] for x in range(xrang) for y in range(yrang)])\n",
    "    area_map_set = area_map_set / points_per_int\n",
    "    \n",
    "    return area_map_set\n",
    "\n",
    "def area_map_plot(network, area_map_set, features, targets, path = '', alpha = 0.1):\n",
    "    # gets the prediction the model made for the area map set\n",
    "    pred = network.predict(area_map_set)\n",
    "    pred = [pred[i,:].argmax() for i in range(int(pred.shape[0]))]\n",
    "\n",
    "    # draws the current area map and the test set overtop it, saves the scatter\n",
    "    plt.scatter(features[:, 0], features[:, 1], c = targets, cmap =colors)\n",
    "    plt.scatter(area_map_set[:, 0], area_map_set[:, 1], c = pred, alpha = alpha, cmap = colors)\n",
    "    \n",
    "    if path == '':\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(path)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Network Parameters ####\n",
    "n_input_nodes = n_features\n",
    "n_output_nodes = n_classes\n",
    "\n",
    "n_hidden_nodes = [64, 32]\n",
    "\n",
    "n_epochs = 2000\n",
    "lr = 0.02\n",
    "batch_size = 64\n",
    "\n",
    "#### Neural Network ####\n",
    "network = NeuralNetwork(n_input_nodes, n_hidden_nodes, n_output_nodes, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Train Set: 0.5\n",
      "Accuracy on Test Set: 0.505\n"
     ]
    }
   ],
   "source": [
    "area_map_set = generate_area_map(x_test, points_per_int = 5)\n",
    "area_map_plot(network, area_map_set, x_test, y_test_raw, alpha = 0.15)\n",
    "    \n",
    "print(\"Accuracy on Train Set:\", network.test(x_train, y_train))\n",
    "print(\"Accuracy on Test Set:\", network.test(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "weight before\t[-0.84268026 -0.14125231]\n",
      "gradient\t[-2.49210009e-05  3.79864072e-08]\n",
      "weight after\t[-0.84270519 -0.14125227]\n",
      "Progress: 0.0% ... Training loss: 0.308 ... Validation loss: 0.324 ... Training Acc: 0.5 ... Validation Acc: 0.5\n",
      "\n",
      "weight before\t[-0.84270519 -0.14125227]\n",
      "gradient\t[-1.89357400e-05  3.66583502e-08]\n",
      "weight after\t[-0.84272412 -0.14125224]\n",
      "Progress: 0.1% ... Training loss: 0.312 ... Validation loss: 0.330 ... Training Acc: 0.5 ... Validation Acc: 0.5\n",
      "\n",
      "weight before\t[-0.84272412 -0.14125224]\n",
      "gradient\t[-1.87252738e-05  1.12921960e-07]\n",
      "weight after\t[-0.84274285 -0.14125212]\n",
      "Progress: 0.1% ... Training loss: 0.317 ... Validation loss: 0.336 ... Training Acc: 0.5 ... Validation Acc: 0.5\n",
      "\n",
      "weight before\t[-0.84274285 -0.14125212]\n",
      "gradient\t[-1.26438910e-05  1.06569794e-08]\n",
      "weight after\t[-0.84275549 -0.14125211]\n",
      "Progress: 0.1% ... Training loss: 0.321 ... Validation loss: 0.342 ... Training Acc: 0.5 ... Validation Acc: 0.5\n",
      "\n",
      "weight before\t[-0.84275549 -0.14125211]\n",
      "gradient\t[-1.94258821e-05  2.04079858e-08]\n",
      "weight after\t[-0.84277492 -0.14125209]\n",
      "Progress: 0.2% ... Training loss: 0.326 ... Validation loss: 0.348 ... Training Acc: 0.5 ... Validation Acc: 0.5\n",
      "\n",
      "weight before\t[-0.84277492 -0.14125209]\n",
      "gradient\t[-1.60939151e-05  2.17071141e-08]\n",
      "weight after\t[-0.84279101 -0.14125207]\n",
      "Progress: 0.2% ... Training loss: 0.329 ... Validation loss: 0.353 ... Training Acc: 0.5 ... Validation Acc: 0.5\n",
      "\n",
      "weight before\t[-0.84279101 -0.14125207]\n",
      "gradient\t[-8.62794788e-06  9.46365745e-09]\n",
      "weight after\t[-0.84279964 -0.14125206]\n",
      "Progress: 0.3% ... Training loss: 0.332 ... Validation loss: 0.358 ... Training Acc: 0.5 ... Validation Acc: 0.5\n",
      "\n",
      "weight before\t[-0.84279964 -0.14125206]\n",
      "gradient\t[-2.12070333e-06  1.21685418e-10]\n",
      "weight after\t[-0.84280176 -0.14125206]\n",
      "Progress: 0.3% ... Training loss: 0.335 ... Validation loss: 0.363 ... Training Acc: 0.5 ... Validation Acc: 0.5\n",
      "\n",
      "weight before\t[-0.84280176 -0.14125206]\n",
      "gradient\t[-8.81851251e-06  2.73490955e-08]\n",
      "weight after\t[-0.84281058 -0.14125203]\n",
      "Progress: 0.4% ... Training loss: 0.340 ... Validation loss: 0.370 ... Training Acc: 0.5 ... Validation Acc: 0.5\n",
      "\n",
      "weight before\t[-0.84281058 -0.14125203]\n",
      "gradient\t[-3.32983198e-06  1.08459193e-08]\n",
      "weight after\t[-0.84281391 -0.14125202]\n",
      "Progress: 0.5% ... Training loss: 0.342 ... Validation loss: 0.373 ... Training Acc: 0.5 ... Validation Acc: 0.5\n",
      "\n",
      "weight before\t[-0.84281391 -0.14125202]\n",
      "gradient\t[-4.89941916e-06  1.68147289e-07]\n",
      "weight after\t[-0.84281881 -0.14125185]\n",
      "Progress: 0.5% ... Training loss: 0.346 ... Validation loss: 0.379 ... Training Acc: 0.503 ... Validation Acc: 0.503\n",
      "\n",
      "weight before\t[-0.84281881 -0.14125185]\n",
      "gradient\t[-3.96832519e-06  7.72584275e-09]\n",
      "weight after\t[-0.84282278 -0.14125185]\n",
      "Progress: 0.6% ... Training loss: 0.348 ... Validation loss: 0.382 ... Training Acc: 0.51 ... Validation Acc: 0.51\n",
      "\n",
      "weight before\t[-0.84282278 -0.14125185]\n",
      "gradient\t[-3.36282140e-06  1.17905951e-08]\n",
      "weight after\t[-0.84282614 -0.14125183]\n",
      "Progress: 0.6% ... Training loss: 0.351 ... Validation loss: 0.386 ... Training Acc: 0.513 ... Validation Acc: 0.513\n",
      "\n",
      "weight before\t[-0.84282614 -0.14125183]\n",
      "gradient\t[-4.20264981e-06  3.05243856e-08]\n",
      "weight after\t[-0.84283034 -0.1412518 ]\n",
      "Progress: 0.7% ... Training loss: 0.354 ... Validation loss: 0.390 ... Training Acc: 0.52 ... Validation Acc: 0.52\n",
      "\n",
      "weight before\t[-0.84283034 -0.1412518 ]\n",
      "gradient\t[-4.61784602e-06  8.26113858e-08]\n",
      "weight after\t[-0.84283496 -0.14125172]\n",
      "Progress: 0.7% ... Training loss: 0.359 ... Validation loss: 0.396 ... Training Acc: 0.53 ... Validation Acc: 0.53\n",
      "\n",
      "weight before\t[-0.84283496 -0.14125172]\n",
      "gradient\t[-3.62111010e-06  3.79479847e-08]\n",
      "weight after\t[-0.84283858 -0.14125168]\n",
      "Progress: 0.8% ... Training loss: 0.364 ... Validation loss: 0.402 ... Training Acc: 0.536 ... Validation Acc: 0.536\n",
      "\n",
      "weight before\t[-0.84283858 -0.14125168]\n",
      "gradient\t[-2.62088017e-06  3.29598639e-08]\n",
      "weight after\t[-0.8428412  -0.14125165]\n",
      "Progress: 0.8% ... Training loss: 0.366 ... Validation loss: 0.405 ... Training Acc: 0.543 ... Validation Acc: 0.543\n",
      "\n",
      "weight before\t[-0.8428412  -0.14125165]\n",
      "gradient\t[-1.28059090e-06  5.87981873e-08]\n",
      "weight after\t[-0.84284248 -0.14125159]\n",
      "Progress: 0.8% ... Training loss: 0.371 ... Validation loss: 0.410 ... Training Acc: 0.55 ... Validation Acc: 0.55\n",
      "\n",
      "weight before\t[-0.84284248 -0.14125159]\n",
      "gradient\t[-7.45780845e-07  9.85859259e-09]\n",
      "weight after\t[-0.84284323 -0.14125158]\n",
      "Progress: 0.9% ... Training loss: 0.374 ... Validation loss: 0.414 ... Training Acc: 0.563 ... Validation Acc: 0.563\n",
      "\n",
      "weight before\t[-0.84284323 -0.14125158]\n",
      "gradient\t[-1.54955761e-06  1.56254652e-08]\n",
      "weight after\t[-0.84284478 -0.14125157]\n",
      "Progress: 0.9% ... Training loss: 0.378 ... Validation loss: 0.418 ... Training Acc: 0.57 ... Validation Acc: 0.57\n",
      "\n",
      "weight before\t[-0.84284478 -0.14125157]\n",
      "gradient\t[-8.22252865e-07  1.03045304e-09]\n",
      "weight after\t[-0.8428456  -0.14125157]\n",
      "Progress: 1.0% ... Training loss: 0.381 ... Validation loss: 0.422 ... Training Acc: 0.593 ... Validation Acc: 0.593\n",
      "\n",
      "weight before\t[-0.8428456  -0.14125157]\n",
      "gradient\t[-8.52580606e-07  2.06799477e-10]\n",
      "weight after\t[-0.84284645 -0.14125156]\n",
      "Progress: 1.1% ... Training loss: 0.383 ... Validation loss: 0.425 ... Training Acc: 0.603 ... Validation Acc: 0.603\n",
      "\n",
      "weight before\t[-0.84284645 -0.14125156]\n",
      "gradient\t[-2.46833502e-06  5.04366983e-08]\n",
      "weight after\t[-0.84284892 -0.14125151]\n",
      "Progress: 1.1% ... Training loss: 0.387 ... Validation loss: 0.429 ... Training Acc: 0.623 ... Validation Acc: 0.623\n",
      "\n",
      "weight before\t[-0.84284892 -0.14125151]\n",
      "gradient\t[-1.17561629e-06  2.95578765e-08]\n",
      "weight after\t[-0.8428501  -0.14125148]\n",
      "Progress: 1.1% ... Training loss: 0.391 ... Validation loss: 0.433 ... Training Acc: 0.65 ... Validation Acc: 0.65\n",
      "\n",
      "weight before\t[-0.8428501  -0.14125148]\n",
      "gradient\t[-2.33411182e-06  3.66474920e-07]\n",
      "weight after\t[-0.84285243 -0.14125112]\n",
      "Progress: 1.2% ... Training loss: 0.396 ... Validation loss: 0.438 ... Training Acc: 0.653 ... Validation Acc: 0.653\n",
      "\n",
      "weight before\t[-0.84285243 -0.14125112]\n",
      "gradient\t[-6.10632180e-07  2.89256159e-08]\n",
      "weight after\t[-0.84285304 -0.14125109]\n",
      "Progress: 1.2% ... Training loss: 0.401 ... Validation loss: 0.443 ... Training Acc: 0.673 ... Validation Acc: 0.673\n",
      "\n",
      "weight before\t[-0.84285304 -0.14125109]\n",
      "gradient\t[-2.75297651e-07  5.83362996e-07]\n",
      "weight after\t[-0.84285332 -0.14125051]\n",
      "Progress: 1.3% ... Training loss: 0.406 ... Validation loss: 0.447 ... Training Acc: 0.68 ... Validation Acc: 0.68\n",
      "\n",
      "weight before\t[-0.84285332 -0.14125051]\n",
      "gradient\t[-6.45271760e-07  1.09962828e-07]\n",
      "weight after\t[-0.84285396 -0.1412504 ]\n",
      "Progress: 1.4% ... Training loss: 0.409 ... Validation loss: 0.450 ... Training Acc: 0.696 ... Validation Acc: 0.696\n",
      "\n",
      "weight before\t[-0.84285396 -0.1412504 ]\n",
      "gradient\t[-1.21534723e-06  6.94240897e-08]\n",
      "weight after\t[-0.84285518 -0.14125033]\n",
      "Progress: 1.4% ... Training loss: 0.412 ... Validation loss: 0.453 ... Training Acc: 0.713 ... Validation Acc: 0.713\n",
      "\n",
      "weight before\t[-0.84285518 -0.14125033]\n",
      "gradient\t[-5.71034920e-07  3.84520748e-08]\n",
      "weight after\t[-0.84285575 -0.14125029]\n",
      "Progress: 1.4% ... Training loss: 0.416 ... Validation loss: 0.456 ... Training Acc: 0.72 ... Validation Acc: 0.72\n",
      "\n",
      "weight before\t[-0.84285575 -0.14125029]\n",
      "gradient\t[-2.16574652e-07  2.14741966e-09]\n",
      "weight after\t[-0.84285596 -0.14125029]\n",
      "Progress: 1.5% ... Training loss: 0.420 ... Validation loss: 0.459 ... Training Acc: 0.733 ... Validation Acc: 0.733\n",
      "\n",
      "weight before\t[-0.84285596 -0.14125029]\n",
      "gradient\t[-2.95208959e-07  4.41417494e-09]\n",
      "weight after\t[-0.84285626 -0.14125028]\n",
      "Progress: 1.6% ... Training loss: 0.422 ... Validation loss: 0.462 ... Training Acc: 0.776 ... Validation Acc: 0.776\n",
      "\n",
      "weight before\t[-0.84285626 -0.14125028]\n",
      "gradient\t[-3.23577736e-07  3.81701211e-07]\n",
      "weight after\t[-0.84285658 -0.1412499 ]\n",
      "Progress: 1.6% ... Training loss: 0.427 ... Validation loss: 0.466 ... Training Acc: 0.783 ... Validation Acc: 0.783\n",
      "\n",
      "weight before\t[-0.84285658 -0.1412499 ]\n",
      "gradient\t[-2.34333329e-07  3.83610764e-07]\n",
      "weight after\t[-0.84285682 -0.14124952]\n",
      "Progress: 1.6% ... Training loss: 0.433 ... Validation loss: 0.471 ... Training Acc: 0.796 ... Validation Acc: 0.796\n",
      "\n",
      "weight before\t[-0.84285682 -0.14124952]\n",
      "gradient\t[-4.76811118e-07  3.22842731e-08]\n",
      "weight after\t[-0.84285729 -0.14124948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1.7% ... Training loss: 0.438 ... Validation loss: 0.475 ... Training Acc: 0.81 ... Validation Acc: 0.81\n",
      "\n",
      "weight before\t[-0.84285729 -0.14124948]\n",
      "gradient\t[-6.52055461e-07  4.45995235e-07]\n",
      "weight after\t[-0.84285795 -0.14124904]\n",
      "Progress: 1.8% ... Training loss: 0.442 ... Validation loss: 0.479 ... Training Acc: 0.813 ... Validation Acc: 0.813\n",
      "\n",
      "weight before\t[-0.84285795 -0.14124904]\n",
      "gradient\t[-8.78631897e-07  6.60214859e-08]\n",
      "weight after\t[-0.84285882 -0.14124897]\n",
      "Progress: 1.8% ... Training loss: 0.446 ... Validation loss: 0.482 ... Training Acc: 0.813 ... Validation Acc: 0.813\n",
      "\n",
      "weight before\t[-0.84285882 -0.14124897]\n",
      "gradient\t[-8.28482932e-07  4.27930593e-08]\n",
      "weight after\t[-0.84285965 -0.14124893]\n",
      "Progress: 1.9% ... Training loss: 0.449 ... Validation loss: 0.485 ... Training Acc: 0.823 ... Validation Acc: 0.823\n",
      "\n",
      "weight before\t[-0.84285965 -0.14124893]\n",
      "gradient\t[-1.87814466e-07  2.17310167e-08]\n",
      "weight after\t[-0.84285984 -0.14124891]\n",
      "Progress: 1.9% ... Training loss: 0.452 ... Validation loss: 0.487 ... Training Acc: 0.826 ... Validation Acc: 0.826\n",
      "\n",
      "weight before\t[-0.84285984 -0.14124891]\n",
      "gradient\t[-7.07229252e-07  9.66802071e-08]\n",
      "weight after\t[-0.84286055 -0.14124881]\n",
      "Progress: 1.9% ... Training loss: 0.455 ... Validation loss: 0.489 ... Training Acc: 0.833 ... Validation Acc: 0.833\n",
      "\n",
      "weight before\t[-0.84286055 -0.14124881]\n",
      "gradient\t[-5.79378987e-07  7.47180265e-08]\n",
      "weight after\t[-0.84286113 -0.14124874]\n",
      "Progress: 2.0% ... Training loss: 0.457 ... Validation loss: 0.491 ... Training Acc: 0.84 ... Validation Acc: 0.84\n",
      "\n",
      "weight before\t[-0.84286113 -0.14124874]\n",
      "gradient\t[-4.90867843e-07  5.24822893e-08]\n",
      "weight after\t[-0.84286162 -0.14124868]\n",
      "Progress: 2.0% ... Training loss: 0.460 ... Validation loss: 0.493 ... Training Acc: 0.84 ... Validation Acc: 0.84\n",
      "\n",
      "weight before\t[-0.84286162 -0.14124868]\n",
      "gradient\t[-4.49527032e-07  4.11559435e-08]\n",
      "weight after\t[-0.84286207 -0.14124864]\n",
      "Progress: 2.1% ... Training loss: 0.461 ... Validation loss: 0.494 ... Training Acc: 0.846 ... Validation Acc: 0.846\n",
      "\n",
      "weight before\t[-0.84286207 -0.14124864]\n",
      "gradient\t[-9.59634102e-08  4.94589071e-07]\n",
      "weight after\t[-0.84286216 -0.14124815]\n",
      "Progress: 2.1% ... Training loss: 0.464 ... Validation loss: 0.496 ... Training Acc: 0.85 ... Validation Acc: 0.85\n",
      "\n",
      "weight before\t[-0.84286216 -0.14124815]\n",
      "gradient\t[-2.50381751e-07  5.08532200e-08]\n",
      "weight after\t[-0.84286241 -0.1412481 ]\n",
      "Progress: 2.2% ... Training loss: 0.464 ... Validation loss: 0.496 ... Training Acc: 0.856 ... Validation Acc: 0.856\n",
      "\n",
      "weight before\t[-0.84286241 -0.1412481 ]\n",
      "gradient\t[-2.11222699e-07  2.13137778e-07]\n",
      "weight after\t[-0.84286263 -0.14124788]\n",
      "Progress: 2.2% ... Training loss: 0.466 ... Validation loss: 0.498 ... Training Acc: 0.86 ... Validation Acc: 0.86\n",
      "\n",
      "weight before\t[-0.84286263 -0.14124788]\n",
      "gradient\t[-4.15754142e-07  2.59931861e-07]\n",
      "weight after\t[-0.84286304 -0.14124762]\n",
      "Progress: 2.3% ... Training loss: 0.468 ... Validation loss: 0.499 ... Training Acc: 0.87 ... Validation Acc: 0.87\n",
      "\n",
      "weight before\t[-0.84286304 -0.14124762]\n",
      "gradient\t[-3.56144783e-07  5.15595858e-08]\n",
      "weight after\t[-0.8428634  -0.14124757]\n",
      "Progress: 2.4% ... Training loss: 0.470 ... Validation loss: 0.501 ... Training Acc: 0.876 ... Validation Acc: 0.876\n",
      "\n",
      "weight before\t[-0.8428634  -0.14124757]\n",
      "gradient\t[-4.15489909e-07  1.09015966e-07]\n",
      "weight after\t[-0.84286381 -0.14124746]\n",
      "Progress: 2.4% ... Training loss: 0.473 ... Validation loss: 0.503 ... Training Acc: 0.883 ... Validation Acc: 0.883\n",
      "\n",
      "weight before\t[-0.84286381 -0.14124746]\n",
      "gradient\t[-1.14469423e-07  1.45945108e-08]\n",
      "weight after\t[-0.84286393 -0.14124745]\n",
      "Progress: 2.5% ... Training loss: 0.476 ... Validation loss: 0.505 ... Training Acc: 0.886 ... Validation Acc: 0.886\n",
      "\n",
      "weight before\t[-0.84286393 -0.14124745]\n",
      "gradient\t[-1.46617016e-07  6.09708718e-07]\n",
      "weight after\t[-0.84286407 -0.14124684]\n",
      "Progress: 2.5% ... Training loss: 0.477 ... Validation loss: 0.506 ... Training Acc: 0.89 ... Validation Acc: 0.89\n",
      "\n",
      "weight before\t[-0.84286407 -0.14124684]\n",
      "gradient\t[-5.40247818e-07  2.80420174e-07]\n",
      "weight after\t[-0.84286461 -0.14124656]\n",
      "Progress: 2.5% ... Training loss: 0.478 ... Validation loss: 0.507 ... Training Acc: 0.893 ... Validation Acc: 0.893\n",
      "\n",
      "weight before\t[-0.84286461 -0.14124656]\n",
      "gradient\t[-1.13022021e-07  1.54290522e-08]\n",
      "weight after\t[-0.84286473 -0.14124654]\n",
      "Progress: 2.6% ... Training loss: 0.479 ... Validation loss: 0.508 ... Training Acc: 0.896 ... Validation Acc: 0.896\n",
      "\n",
      "weight before\t[-0.84286473 -0.14124654]\n",
      "gradient\t[-6.73080401e-08  1.08049044e-09]\n",
      "weight after\t[-0.84286479 -0.14124654]\n",
      "Progress: 2.6% ... Training loss: 0.481 ... Validation loss: 0.509 ... Training Acc: 0.9 ... Validation Acc: 0.9\n",
      "\n",
      "weight before\t[-0.84286479 -0.14124654]\n",
      "gradient\t[-2.91292569e-07  2.87891146e-07]\n",
      "weight after\t[-0.84286509 -0.14124625]\n",
      "Progress: 2.7% ... Training loss: 0.481 ... Validation loss: 0.509 ... Training Acc: 0.906 ... Validation Acc: 0.906\n",
      "\n",
      "weight before\t[-0.84286509 -0.14124625]\n",
      "gradient\t[-1.91842517e-07  6.67555859e-07]\n",
      "weight after\t[-0.84286528 -0.14124559]\n",
      "Progress: 2.8% ... Training loss: 0.482 ... Validation loss: 0.510 ... Training Acc: 0.906 ... Validation Acc: 0.906\n",
      "\n",
      "weight before\t[-0.84286528 -0.14124559]\n",
      "gradient\t[-2.0622441e-07  1.0202563e-07]\n",
      "weight after\t[-0.84286548 -0.14124548]\n",
      "Progress: 2.8% ... Training loss: 0.483 ... Validation loss: 0.510 ... Training Acc: 0.91 ... Validation Acc: 0.91\n",
      "\n",
      "weight before\t[-0.84286548 -0.14124548]\n",
      "gradient\t[-1.60852766e-07  1.35379550e-06]\n",
      "weight after\t[-0.84286564 -0.14124413]\n",
      "Progress: 2.9% ... Training loss: 0.484 ... Validation loss: 0.511 ... Training Acc: 0.91 ... Validation Acc: 0.91\n",
      "\n",
      "weight before\t[-0.84286564 -0.14124413]\n",
      "gradient\t[-9.45465520e-08  2.81174263e-08]\n",
      "weight after\t[-0.84286574 -0.1412441 ]\n",
      "Progress: 2.9% ... Training loss: 0.484 ... Validation loss: 0.510 ... Training Acc: 0.913 ... Validation Acc: 0.913\n",
      "\n",
      "weight before\t[-0.84286574 -0.1412441 ]\n",
      "gradient\t[-2.81221231e-07  1.01679996e-07]\n",
      "weight after\t[-0.84286602 -0.141244  ]\n",
      "Progress: 3.0% ... Training loss: 0.485 ... Validation loss: 0.511 ... Training Acc: 0.913 ... Validation Acc: 0.913\n",
      "\n",
      "weight before\t[-0.84286602 -0.141244  ]\n",
      "gradient\t[-1.49244496e-07  1.07771811e-07]\n",
      "weight after\t[-0.84286617 -0.14124389]\n",
      "Progress: 3.0% ... Training loss: 0.486 ... Validation loss: 0.511 ... Training Acc: 0.913 ... Validation Acc: 0.913\n",
      "\n",
      "weight before\t[-0.84286617 -0.14124389]\n",
      "gradient\t[-5.58556635e-07  1.93585957e-07]\n",
      "weight after\t[-0.84286673 -0.1412437 ]\n",
      "Progress: 3.0% ... Training loss: 0.486 ... Validation loss: 0.511 ... Training Acc: 0.913 ... Validation Acc: 0.913\n",
      "\n",
      "weight before\t[-0.84286673 -0.1412437 ]\n",
      "gradient\t[-1.73663780e-07  9.30926733e-08]\n",
      "weight after\t[-0.8428669  -0.14124361]\n",
      "Progress: 3.1% ... Training loss: 0.487 ... Validation loss: 0.512 ... Training Acc: 0.913 ... Validation Acc: 0.913\n",
      "\n",
      "weight before\t[-0.8428669  -0.14124361]\n",
      "gradient\t[-8.73207396e-08  8.03147406e-07]\n",
      "weight after\t[-0.84286699 -0.1412428 ]\n",
      "Progress: 3.1% ... Training loss: 0.487 ... Validation loss: 0.512 ... Training Acc: 0.913 ... Validation Acc: 0.913\n",
      "\n",
      "weight before\t[-0.84286699 -0.1412428 ]\n",
      "gradient\t[-2.78342893e-07  1.09395307e-07]\n",
      "weight after\t[-0.84286727 -0.14124269]\n",
      "Progress: 3.2% ... Training loss: 0.488 ... Validation loss: 0.512 ... Training Acc: 0.913 ... Validation Acc: 0.913\n",
      "\n",
      "weight before\t[-0.84286727 -0.14124269]\n",
      "gradient\t[-2.51305678e-07  1.27316186e-07]\n",
      "weight after\t[-0.84286752 -0.14124257]\n",
      "Progress: 3.2% ... Training loss: 0.489 ... Validation loss: 0.513 ... Training Acc: 0.916 ... Validation Acc: 0.916\n",
      "\n",
      "weight before\t[-0.84286752 -0.14124257]\n",
      "gradient\t[-1.79121170e-07  1.41482306e-07]\n",
      "weight after\t[-0.8428677  -0.14124243]\n",
      "Progress: 3.3% ... Training loss: 0.490 ... Validation loss: 0.514 ... Training Acc: 0.92 ... Validation Acc: 0.92\n",
      "\n",
      "weight before\t[-0.8428677  -0.14124243]\n",
      "gradient\t[-1.19165254e-07  9.82016574e-08]\n",
      "weight after\t[-0.84286782 -0.14124233]\n",
      "Progress: 3.4% ... Training loss: 0.491 ... Validation loss: 0.514 ... Training Acc: 0.92 ... Validation Acc: 0.92\n",
      "\n",
      "weight before\t[-0.84286782 -0.14124233]\n",
      "gradient\t[-2.45216067e-07  9.41711682e-08]\n",
      "weight after\t[-0.84286806 -0.14124223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 3.4% ... Training loss: 0.491 ... Validation loss: 0.514 ... Training Acc: 0.92 ... Validation Acc: 0.92\n",
      "\n",
      "weight before\t[-0.84286806 -0.14124223]\n",
      "gradient\t[-1.87369032e-07  1.07584690e-07]\n",
      "weight after\t[-0.84286825 -0.14124213]\n",
      "Progress: 3.5% ... Training loss: 0.491 ... Validation loss: 0.514 ... Training Acc: 0.92 ... Validation Acc: 0.92\n",
      "\n",
      "weight before\t[-0.84286825 -0.14124213]\n",
      "gradient\t[-1.39644163e-07  2.14523581e-07]\n",
      "weight after\t[-0.84286839 -0.14124191]\n",
      "Progress: 3.5% ... Training loss: 0.491 ... Validation loss: 0.514 ... Training Acc: 0.923 ... Validation Acc: 0.923\n",
      "\n",
      "weight before\t[-0.84286839 -0.14124191]\n",
      "gradient\t[-9.45024620e-08  3.49042934e-07]\n",
      "weight after\t[-0.84286848 -0.14124156]\n",
      "Progress: 3.5% ... Training loss: 0.492 ... Validation loss: 0.514 ... Training Acc: 0.926 ... Validation Acc: 0.926\n",
      "\n",
      "weight before\t[-0.84286848 -0.14124156]\n",
      "gradient\t[-7.26511782e-08  1.77450495e-07]\n",
      "weight after\t[-0.84286856 -0.14124138]\n",
      "Progress: 3.6% ... Training loss: 0.492 ... Validation loss: 0.514 ... Training Acc: 0.926 ... Validation Acc: 0.926\n",
      "\n",
      "weight before\t[-0.84286856 -0.14124138]\n",
      "gradient\t[-2.72730630e-07  1.64131614e-07]\n",
      "weight after\t[-0.84286883 -0.14124122]\n",
      "Progress: 3.6% ... Training loss: 0.493 ... Validation loss: 0.515 ... Training Acc: 0.93 ... Validation Acc: 0.93\n",
      "\n",
      "weight before\t[-0.84286883 -0.14124122]\n",
      "gradient\t[-6.93088271e-08  6.22564193e-08]\n",
      "weight after\t[-0.8428689  -0.14124116]\n",
      "Progress: 3.7% ... Training loss: 0.494 ... Validation loss: 0.515 ... Training Acc: 0.93 ... Validation Acc: 0.93\n",
      "\n",
      "weight before\t[-0.8428689  -0.14124116]\n",
      "gradient\t[-2.51838607e-07  2.53604386e-07]\n",
      "weight after\t[-0.84286915 -0.1412409 ]\n",
      "Progress: 3.8% ... Training loss: 0.494 ... Validation loss: 0.515 ... Training Acc: 0.93 ... Validation Acc: 0.93\n",
      "\n",
      "weight before\t[-0.84286915 -0.1412409 ]\n",
      "gradient\t[-5.44523582e-08  1.05162460e-06]\n",
      "weight after\t[-0.8428692  -0.14123985]\n",
      "Progress: 3.8% ... Training loss: 0.494 ... Validation loss: 0.515 ... Training Acc: 0.93 ... Validation Acc: 0.93\n",
      "\n",
      "weight before\t[-0.8428692  -0.14123985]\n",
      "gradient\t[-2.75108200e-07  5.74521515e-07]\n",
      "weight after\t[-0.84286948 -0.14123928]\n",
      "Progress: 3.9% ... Training loss: 0.495 ... Validation loss: 0.515 ... Training Acc: 0.93 ... Validation Acc: 0.93\n",
      "\n",
      "weight before\t[-0.84286948 -0.14123928]\n",
      "gradient\t[-1.21432529e-08  7.80165801e-09]\n",
      "weight after\t[-0.84286949 -0.14123927]\n",
      "Progress: 3.9% ... Training loss: 0.494 ... Validation loss: 0.514 ... Training Acc: 0.93 ... Validation Acc: 0.93\n",
      "\n",
      "weight before\t[-0.84286949 -0.14123927]\n",
      "gradient\t[-1.51855823e-07  1.88203400e-07]\n",
      "weight after\t[-0.84286964 -0.14123908]\n",
      "Progress: 4.0% ... Training loss: 0.493 ... Validation loss: 0.513 ... Training Acc: 0.93 ... Validation Acc: 0.93\n",
      "\n",
      "weight before\t[-0.84286964 -0.14123908]\n",
      "gradient\t[-6.47366900e-08  4.65782168e-07]\n",
      "weight after\t[-0.84286971 -0.14123862]\n",
      "Progress: 4.0% ... Training loss: 0.493 ... Validation loss: 0.512 ... Training Acc: 0.936 ... Validation Acc: 0.936\n",
      "\n",
      "weight before\t[-0.84286971 -0.14123862]\n",
      "gradient\t[-4.39271872e-08  3.34715625e-08]\n",
      "weight after\t[-0.84286975 -0.14123858]\n",
      "Progress: 4.0% ... Training loss: 0.493 ... Validation loss: 0.512 ... Training Acc: 0.94 ... Validation Acc: 0.94\n",
      "\n",
      "weight before\t[-0.84286975 -0.14123858]\n",
      "gradient\t[-1.24895506e-07  5.15858247e-07]\n",
      "weight after\t[-0.84286988 -0.14123807]\n",
      "Progress: 4.1% ... Training loss: 0.493 ... Validation loss: 0.512 ... Training Acc: 0.943 ... Validation Acc: 0.943\n",
      "\n",
      "weight before\t[-0.84286988 -0.14123807]\n",
      "gradient\t[-2.90709450e-07  3.72136905e-07]\n",
      "weight after\t[-0.84287017 -0.1412377 ]\n",
      "Progress: 4.2% ... Training loss: 0.493 ... Validation loss: 0.512 ... Training Acc: 0.943 ... Validation Acc: 0.943\n",
      "\n",
      "weight before\t[-0.84287017 -0.1412377 ]\n",
      "gradient\t[-4.40167312e-08  4.87404958e-07]\n",
      "weight after\t[-0.84287021 -0.14123721]\n",
      "Progress: 4.2% ... Training loss: 0.493 ... Validation loss: 0.511 ... Training Acc: 0.943 ... Validation Acc: 0.943\n",
      "\n",
      "weight before\t[-0.84287021 -0.14123721]\n",
      "gradient\t[-1.61901087e-07  8.12241969e-07]\n",
      "weight after\t[-0.84287037 -0.1412364 ]\n",
      "Progress: 4.2% ... Training loss: 0.493 ... Validation loss: 0.511 ... Training Acc: 0.943 ... Validation Acc: 0.943\n",
      "\n",
      "weight before\t[-0.84287037 -0.1412364 ]\n",
      "gradient\t[-6.55979862e-08  1.74607391e-06]\n",
      "weight after\t[-0.84287044 -0.14123465]\n",
      "Progress: 4.3% ... Training loss: 0.493 ... Validation loss: 0.511 ... Training Acc: 0.943 ... Validation Acc: 0.943\n",
      "\n",
      "weight before\t[-0.84287044 -0.14123465]\n",
      "gradient\t[-2.24476775e-07  1.44883914e-06]\n",
      "weight after\t[-0.84287066 -0.1412332 ]\n",
      "Progress: 4.3% ... Training loss: 0.494 ... Validation loss: 0.511 ... Training Acc: 0.943 ... Validation Acc: 0.943\n",
      "\n",
      "weight before\t[-0.84287066 -0.1412332 ]\n",
      "gradient\t[-8.54251739e-08  1.49771426e-07]\n",
      "weight after\t[-0.84287075 -0.14123305]\n",
      "Progress: 4.4% ... Training loss: 0.494 ... Validation loss: 0.511 ... Training Acc: 0.946 ... Validation Acc: 0.946\n",
      "\n",
      "weight before\t[-0.84287075 -0.14123305]\n",
      "gradient\t[-1.67926936e-07  1.46945766e-06]\n",
      "weight after\t[-0.84287092 -0.14123158]\n",
      "Progress: 4.5% ... Training loss: 0.495 ... Validation loss: 0.511 ... Training Acc: 0.946 ... Validation Acc: 0.946\n",
      "\n",
      "weight before\t[-0.84287092 -0.14123158]\n",
      "gradient\t[-1.91937892e-07  4.49358063e-07]\n",
      "weight after\t[-0.84287111 -0.14123113]\n",
      "Progress: 4.5% ... Training loss: 0.494 ... Validation loss: 0.511 ... Training Acc: 0.946 ... Validation Acc: 0.946\n",
      "\n",
      "weight before\t[-0.84287111 -0.14123113]\n",
      "gradient\t[-2.06162144e-07  2.45850433e-07]\n",
      "weight after\t[-0.84287132 -0.14123089]\n",
      "Progress: 4.5% ... Training loss: 0.495 ... Validation loss: 0.511 ... Training Acc: 0.95 ... Validation Acc: 0.95\n",
      "\n",
      "weight before\t[-0.84287132 -0.14123089]\n",
      "gradient\t[-1.27134133e-07  1.79709478e-07]\n",
      "weight after\t[-0.84287144 -0.14123071]\n",
      "Progress: 4.6% ... Training loss: 0.495 ... Validation loss: 0.511 ... Training Acc: 0.95 ... Validation Acc: 0.95\n",
      "\n",
      "weight before\t[-0.84287144 -0.14123071]\n",
      "gradient\t[-2.72851288e-08  2.11813199e-09]\n",
      "weight after\t[-0.84287147 -0.1412307 ]\n",
      "Progress: 4.7% ... Training loss: 0.494 ... Validation loss: 0.510 ... Training Acc: 0.95 ... Validation Acc: 0.95\n",
      "\n",
      "weight before\t[-0.84287147 -0.1412307 ]\n",
      "gradient\t[-1.48820881e-07  2.17865547e-07]\n",
      "weight after\t[-0.84287162 -0.14123049]\n",
      "Progress: 4.7% ... Training loss: 0.495 ... Validation loss: 0.510 ... Training Acc: 0.95 ... Validation Acc: 0.95\n",
      "\n",
      "weight before\t[-0.84287162 -0.14123049]\n",
      "gradient\t[-1.83246800e-07  1.73204606e-06]\n",
      "weight after\t[-0.8428718  -0.14122875]\n",
      "Progress: 4.8% ... Training loss: 0.496 ... Validation loss: 0.511 ... Training Acc: 0.95 ... Validation Acc: 0.95\n",
      "\n",
      "weight before\t[-0.8428718  -0.14122875]\n",
      "gradient\t[-1.85493654e-07  3.73999690e-07]\n",
      "weight after\t[-0.84287199 -0.14122838]\n",
      "Progress: 4.8% ... Training loss: 0.496 ... Validation loss: 0.511 ... Training Acc: 0.95 ... Validation Acc: 0.95\n",
      "\n",
      "weight before\t[-0.84287199 -0.14122838]\n",
      "gradient\t[-2.02901899e-08  1.26699429e-07]\n",
      "weight after\t[-0.84287201 -0.14122825]\n",
      "Progress: 4.8% ... Training loss: 0.496 ... Validation loss: 0.510 ... Training Acc: 0.953 ... Validation Acc: 0.953\n",
      "\n",
      "weight before\t[-0.84287201 -0.14122825]\n",
      "gradient\t[-1.86741532e-07  1.64400809e-06]\n",
      "weight after\t[-0.84287219 -0.14122661]\n",
      "Progress: 4.9% ... Training loss: 0.496 ... Validation loss: 0.510 ... Training Acc: 0.953 ... Validation Acc: 0.953\n",
      "\n",
      "weight before\t[-0.84287219 -0.14122661]\n",
      "gradient\t[-1.21371633e-07  1.35595456e-07]\n",
      "weight after\t[-0.84287232 -0.14122647]\n",
      "Progress: 5.0% ... Training loss: 0.496 ... Validation loss: 0.509 ... Training Acc: 0.953 ... Validation Acc: 0.953\n",
      "\n",
      "weight before\t[-0.84287232 -0.14122647]\n",
      "gradient\t[-2.27472048e-07  4.56455546e-07]\n",
      "weight after\t[-0.84287254 -0.14122602]\n",
      "Progress: 5.0% ... Training loss: 0.496 ... Validation loss: 0.509 ... Training Acc: 0.96 ... Validation Acc: 0.96\n",
      "\n",
      "weight before\t[-0.84287254 -0.14122602]\n",
      "gradient\t[-2.71459892e-07  5.22222932e-07]\n",
      "weight after\t[-0.84287281 -0.1412255 ]\n",
      "Progress: 5.0% ... Training loss: 0.496 ... Validation loss: 0.509 ... Training Acc: 0.963 ... Validation Acc: 0.963\n",
      "\n",
      "weight before\t[-0.84287281 -0.1412255 ]\n",
      "gradient\t[-1.46165888e-08  4.40040546e-09]\n",
      "weight after\t[-0.84287283 -0.14122549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 5.1% ... Training loss: 0.496 ... Validation loss: 0.509 ... Training Acc: 0.963 ... Validation Acc: 0.963\n",
      "\n",
      "weight before\t[-0.84287283 -0.14122549]\n",
      "gradient\t[-1.36830305e-08  1.82416916e-08]\n",
      "weight after\t[-0.84287284 -0.14122547]\n",
      "Progress: 5.2% ... Training loss: 0.496 ... Validation loss: 0.509 ... Training Acc: 0.963 ... Validation Acc: 0.963\n",
      "\n",
      "weight before\t[-0.84287284 -0.14122547]\n",
      "gradient\t[-1.94168160e-07  4.36417814e-07]\n",
      "weight after\t[-0.84287304 -0.14122504]\n",
      "Progress: 5.2% ... Training loss: 0.496 ... Validation loss: 0.509 ... Training Acc: 0.963 ... Validation Acc: 0.963\n",
      "\n",
      "weight before\t[-0.84287304 -0.14122504]\n",
      "gradient\t[-8.78304170e-08  2.03671025e-07]\n",
      "weight after\t[-0.84287313 -0.14122483]\n",
      "Progress: 5.2% ... Training loss: 0.496 ... Validation loss: 0.508 ... Training Acc: 0.963 ... Validation Acc: 0.963\n",
      "\n",
      "weight before\t[-0.84287313 -0.14122483]\n",
      "gradient\t[-1.82967967e-07  4.07276743e-06]\n",
      "weight after\t[-0.84287331 -0.14122076]\n",
      "Progress: 5.3% ... Training loss: 0.496 ... Validation loss: 0.507 ... Training Acc: 0.963 ... Validation Acc: 0.963\n",
      "\n",
      "weight before\t[-0.84287331 -0.14122076]\n",
      "gradient\t[-4.45170411e-08  8.09995313e-07]\n",
      "weight after\t[-0.84287335 -0.14121995]\n",
      "Progress: 5.3% ... Training loss: 0.496 ... Validation loss: 0.508 ... Training Acc: 0.963 ... Validation Acc: 0.963\n",
      "\n",
      "weight before\t[-0.84287335 -0.14121995]\n",
      "gradient\t[-2.21637305e-07  3.71032979e-06]\n",
      "weight after\t[-0.84287357 -0.14121624]\n",
      "Progress: 5.4% ... Training loss: 0.496 ... Validation loss: 0.507 ... Training Acc: 0.963 ... Validation Acc: 0.963\n",
      "\n",
      "weight before\t[-0.84287357 -0.14121624]\n",
      "gradient\t[-1.14991175e-07  3.28018946e-07]\n",
      "weight after\t[-0.84287369 -0.14121591]\n",
      "Progress: 5.5% ... Training loss: 0.496 ... Validation loss: 0.506 ... Training Acc: 0.966 ... Validation Acc: 0.966\n",
      "\n",
      "weight before\t[-0.84287369 -0.14121591]\n",
      "gradient\t[-2.48663474e-08  7.91222685e-07]\n",
      "weight after\t[-0.84287371 -0.14121512]\n",
      "Progress: 5.5% ... Training loss: 0.495 ... Validation loss: 0.506 ... Training Acc: 0.966 ... Validation Acc: 0.966\n",
      "\n",
      "weight before\t[-0.84287371 -0.14121512]\n",
      "gradient\t[-4.32236192e-08  2.89647311e-07]\n",
      "weight after\t[-0.84287376 -0.14121483]\n",
      "Progress: 5.5% ... Training loss: 0.495 ... Validation loss: 0.506 ... Training Acc: 0.966 ... Validation Acc: 0.966\n",
      "\n",
      "weight before\t[-0.84287376 -0.14121483]\n",
      "gradient\t[-1.24105292e-07  2.37006910e-07]\n",
      "weight after\t[-0.84287388 -0.14121459]\n",
      "Progress: 5.6% ... Training loss: 0.495 ... Validation loss: 0.506 ... Training Acc: 0.966 ... Validation Acc: 0.966\n",
      "\n",
      "weight before\t[-0.84287388 -0.14121459]\n",
      "gradient\t[-5.07722031e-08  8.95812457e-07]\n",
      "weight after\t[-0.84287393 -0.1412137 ]\n",
      "Progress: 5.7% ... Training loss: 0.496 ... Validation loss: 0.505 ... Training Acc: 0.966 ... Validation Acc: 0.966\n",
      "\n",
      "weight before\t[-0.84287393 -0.1412137 ]\n",
      "gradient\t[-7.89939401e-08  2.03971796e-06]\n",
      "weight after\t[-0.84287401 -0.14121166]\n",
      "Progress: 5.7% ... Training loss: 0.495 ... Validation loss: 0.505 ... Training Acc: 0.97 ... Validation Acc: 0.97\n",
      "\n",
      "weight before\t[-0.84287401 -0.14121166]\n",
      "gradient\t[-2.86873090e-08  2.36613109e-07]\n",
      "weight after\t[-0.84287404 -0.14121142]\n",
      "Progress: 5.8% ... Training loss: 0.495 ... Validation loss: 0.505 ... Training Acc: 0.97 ... Validation Acc: 0.97\n",
      "\n",
      "weight before\t[-0.84287404 -0.14121142]\n",
      "gradient\t[-1.39827398e-07  4.61609085e-07]\n",
      "weight after\t[-0.84287418 -0.14121096]\n",
      "Progress: 5.8% ... Training loss: 0.496 ... Validation loss: 0.505 ... Training Acc: 0.97 ... Validation Acc: 0.97\n",
      "\n",
      "weight before\t[-0.84287418 -0.14121096]\n",
      "gradient\t[-1.78530299e-07  6.88491059e-07]\n",
      "weight after\t[-0.84287436 -0.14121027]\n",
      "Progress: 5.8% ... Training loss: 0.496 ... Validation loss: 0.505 ... Training Acc: 0.97 ... Validation Acc: 0.97\n",
      "\n",
      "weight before\t[-0.84287436 -0.14121027]\n",
      "gradient\t[-3.53436943e-08  2.84106422e-07]\n",
      "weight after\t[-0.84287439 -0.14120999]\n",
      "Progress: 5.9% ... Training loss: 0.496 ... Validation loss: 0.504 ... Training Acc: 0.97 ... Validation Acc: 0.97\n",
      "\n",
      "weight before\t[-0.84287439 -0.14120999]\n",
      "gradient\t[-7.48570495e-08  2.08148053e-06]\n",
      "weight after\t[-0.84287447 -0.14120791]\n",
      "Progress: 6.0% ... Training loss: 0.495 ... Validation loss: 0.504 ... Training Acc: 0.97 ... Validation Acc: 0.97\n",
      "\n",
      "weight before\t[-0.84287447 -0.14120791]\n",
      "gradient\t[-6.24105279e-08  2.02746890e-06]\n",
      "weight after\t[-0.84287453 -0.14120588]\n",
      "Progress: 6.0% ... Training loss: 0.495 ... Validation loss: 0.503 ... Training Acc: 0.973 ... Validation Acc: 0.973\n",
      "\n",
      "weight before\t[-0.84287453 -0.14120588]\n",
      "gradient\t[-1.15253734e-07  2.80224272e-06]\n",
      "weight after\t[-0.84287465 -0.14120308]\n",
      "Progress: 6.0% ... Training loss: 0.495 ... Validation loss: 0.503 ... Training Acc: 0.973 ... Validation Acc: 0.973\n",
      "\n",
      "weight before\t[-0.84287465 -0.14120308]\n",
      "gradient\t[-1.20819398e-08  2.53260862e-09]\n",
      "weight after\t[-0.84287466 -0.14120307]\n",
      "Progress: 6.1% ... Training loss: 0.495 ... Validation loss: 0.502 ... Training Acc: 0.973 ... Validation Acc: 0.973\n",
      "\n",
      "weight before\t[-0.84287466 -0.14120307]\n",
      "gradient\t[-1.30162873e-08  5.30194686e-09]\n",
      "weight after\t[-0.84287467 -0.14120307]\n",
      "Progress: 6.2% ... Training loss: 0.494 ... Validation loss: 0.501 ... Training Acc: 0.973 ... Validation Acc: 0.973\n",
      "\n",
      "weight before\t[-0.84287467 -0.14120307]\n",
      "gradient\t[-1.24508950e-07  7.94335192e-07]\n",
      "weight after\t[-0.8428748  -0.14120227]\n",
      "Progress: 6.2% ... Training loss: 0.494 ... Validation loss: 0.501 ... Training Acc: 0.973 ... Validation Acc: 0.973\n",
      "\n",
      "weight before\t[-0.8428748  -0.14120227]\n",
      "gradient\t[-1.55520965e-07  1.56658121e-06]\n",
      "weight after\t[-0.84287495 -0.14120071]\n",
      "Progress: 6.2% ... Training loss: 0.494 ... Validation loss: 0.501 ... Training Acc: 0.973 ... Validation Acc: 0.973\n",
      "\n",
      "weight before\t[-0.84287495 -0.14120071]\n",
      "gradient\t[-6.92029024e-09  7.95743170e-08]\n",
      "weight after\t[-0.84287496 -0.14120063]\n",
      "Progress: 6.3% ... Training loss: 0.494 ... Validation loss: 0.500 ... Training Acc: 0.973 ... Validation Acc: 0.973\n",
      "\n",
      "weight before\t[-0.84287496 -0.14120063]\n",
      "gradient\t[-6.67368153e-08  3.01744243e-06]\n",
      "weight after\t[-0.84287502 -0.14119761]\n",
      "Progress: 6.3% ... Training loss: 0.493 ... Validation loss: 0.499 ... Training Acc: 0.973 ... Validation Acc: 0.973\n",
      "\n",
      "weight before\t[-0.84287502 -0.14119761]\n",
      "gradient\t[-5.92309823e-08  3.59626759e-07]\n",
      "weight after\t[-0.84287508 -0.14119725]\n",
      "Progress: 6.4% ... Training loss: 0.493 ... Validation loss: 0.499 ... Training Acc: 0.973 ... Validation Acc: 0.973\n",
      "\n",
      "weight before\t[-0.84287508 -0.14119725]\n",
      "gradient\t[-8.35143051e-08  4.52793975e-07]\n",
      "weight after\t[-0.84287517 -0.1411968 ]\n",
      "Progress: 6.5% ... Training loss: 0.493 ... Validation loss: 0.498 ... Training Acc: 0.973 ... Validation Acc: 0.973\n",
      "\n",
      "weight before\t[-0.84287517 -0.1411968 ]\n",
      "gradient\t[-2.60402941e-08  1.24743927e-07]\n",
      "weight after\t[-0.84287519 -0.14119667]\n",
      "Progress: 6.5% ... Training loss: 0.493 ... Validation loss: 0.498 ... Training Acc: 0.973 ... Validation Acc: 0.973\n",
      "\n",
      "weight before\t[-0.84287519 -0.14119667]\n",
      "gradient\t[-1.06999424e-07  3.21856612e-07]\n",
      "weight after\t[-0.8428753  -0.14119635]\n",
      "Progress: 6.5% ... Training loss: 0.493 ... Validation loss: 0.498 ... Training Acc: 0.973 ... Validation Acc: 0.973\n",
      "\n",
      "weight before\t[-0.8428753  -0.14119635]\n",
      "gradient\t[-8.87355495e-08  7.76377954e-07]\n",
      "weight after\t[-0.84287539 -0.14119557]\n",
      "Progress: 6.6% ... Training loss: 0.493 ... Validation loss: 0.497 ... Training Acc: 0.973 ... Validation Acc: 0.973\n",
      "\n",
      "weight before\t[-0.84287539 -0.14119557]\n",
      "gradient\t[-1.93243893e-07  2.86782091e-06]\n",
      "weight after\t[-0.84287558 -0.14119271]\n",
      "Progress: 6.7% ... Training loss: 0.492 ... Validation loss: 0.497 ... Training Acc: 0.973 ... Validation Acc: 0.973\n",
      "\n",
      "weight before\t[-0.84287558 -0.14119271]\n",
      "gradient\t[-3.61309483e-08  1.07908096e-07]\n",
      "weight after\t[-0.84287562 -0.1411926 ]\n",
      "Progress: 6.7% ... Training loss: 0.492 ... Validation loss: 0.496 ... Training Acc: 0.976 ... Validation Acc: 0.976\n",
      "\n",
      "weight before\t[-0.84287562 -0.1411926 ]\n",
      "gradient\t[-1.31228566e-07  4.04276296e-07]\n",
      "weight after\t[-0.84287575 -0.14119219]\n",
      "Progress: 6.8% ... Training loss: 0.492 ... Validation loss: 0.496 ... Training Acc: 0.976 ... Validation Acc: 0.976\n",
      "\n",
      "weight before\t[-0.84287575 -0.14119219]\n",
      "gradient\t[-3.68492907e-08  1.50186021e-06]\n",
      "weight after\t[-0.84287579 -0.14119069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 6.8% ... Training loss: 0.492 ... Validation loss: 0.496 ... Training Acc: 0.976 ... Validation Acc: 0.976\n",
      "\n",
      "weight before\t[-0.84287579 -0.14119069]\n",
      "gradient\t[-1.16861502e-08  4.25288711e-08]\n",
      "weight after\t[-0.8428758  -0.14119065]\n",
      "Progress: 6.8% ... Training loss: 0.492 ... Validation loss: 0.495 ... Training Acc: 0.976 ... Validation Acc: 0.976\n",
      "\n",
      "weight before\t[-0.8428758  -0.14119065]\n",
      "gradient\t[-1.24677159e-07  4.47264663e-07]\n",
      "weight after\t[-0.84287592 -0.1411902 ]\n",
      "Progress: 6.9% ... Training loss: 0.492 ... Validation loss: 0.495 ... Training Acc: 0.976 ... Validation Acc: 0.976\n",
      "\n",
      "weight before\t[-0.84287592 -0.1411902 ]\n",
      "gradient\t[-8.57602800e-09  1.45762869e-08]\n",
      "weight after\t[-0.84287593 -0.14119019]\n",
      "Progress: 7.0% ... Training loss: 0.492 ... Validation loss: 0.495 ... Training Acc: 0.976 ... Validation Acc: 0.976\n",
      "\n",
      "weight before\t[-0.84287593 -0.14119019]\n",
      "gradient\t[-5.79583451e-08  4.50354337e-06]\n",
      "weight after\t[-0.84287599 -0.14118569]\n",
      "Progress: 7.0% ... Training loss: 0.492 ... Validation loss: 0.495 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287599 -0.14118569]\n",
      "gradient\t[-4.06100365e-08  2.40070023e-06]\n",
      "weight after\t[-0.84287603 -0.14118328]\n",
      "Progress: 7.0% ... Training loss: 0.491 ... Validation loss: 0.494 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287603 -0.14118328]\n",
      "gradient\t[-1.29707786e-07  7.28604026e-07]\n",
      "weight after\t[-0.84287616 -0.14118256]\n",
      "Progress: 7.1% ... Training loss: 0.491 ... Validation loss: 0.494 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287616 -0.14118256]\n",
      "gradient\t[-6.54111926e-08  6.71752308e-07]\n",
      "weight after\t[-0.84287623 -0.14118188]\n",
      "Progress: 7.2% ... Training loss: 0.491 ... Validation loss: 0.494 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287623 -0.14118188]\n",
      "gradient\t[-5.04537675e-08  3.02387748e-07]\n",
      "weight after\t[-0.84287628 -0.14118158]\n",
      "Progress: 7.2% ... Training loss: 0.491 ... Validation loss: 0.494 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287628 -0.14118158]\n",
      "gradient\t[-1.21053998e-07  4.63137878e-07]\n",
      "weight after\t[-0.8428764  -0.14118112]\n",
      "Progress: 7.2% ... Training loss: 0.491 ... Validation loss: 0.494 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.8428764  -0.14118112]\n",
      "gradient\t[-1.78376810e-08  1.18038374e-06]\n",
      "weight after\t[-0.84287641 -0.14117994]\n",
      "Progress: 7.3% ... Training loss: 0.491 ... Validation loss: 0.493 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287641 -0.14117994]\n",
      "gradient\t[-9.85524867e-08  1.81746287e-06]\n",
      "weight after\t[-0.84287651 -0.14117812]\n",
      "Progress: 7.3% ... Training loss: 0.491 ... Validation loss: 0.493 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287651 -0.14117812]\n",
      "gradient\t[-1.18566309e-08  1.20367847e-06]\n",
      "weight after\t[-0.84287653 -0.14117692]\n",
      "Progress: 7.4% ... Training loss: 0.491 ... Validation loss: 0.493 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287653 -0.14117692]\n",
      "gradient\t[-1.71150480e-07  4.13492208e-06]\n",
      "weight after\t[-0.8428767  -0.14117278]\n",
      "Progress: 7.5% ... Training loss: 0.491 ... Validation loss: 0.493 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.8428767  -0.14117278]\n",
      "gradient\t[-3.68776112e-08  4.17396955e-07]\n",
      "weight after\t[-0.84287673 -0.14117236]\n",
      "Progress: 7.5% ... Training loss: 0.491 ... Validation loss: 0.492 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287673 -0.14117236]\n",
      "gradient\t[-1.30721815e-07  6.51160577e-07]\n",
      "weight after\t[-0.84287686 -0.14117171]\n",
      "Progress: 7.5% ... Training loss: 0.491 ... Validation loss: 0.492 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287686 -0.14117171]\n",
      "gradient\t[-4.28599697e-08  2.53203952e-06]\n",
      "weight after\t[-0.84287691 -0.14116918]\n",
      "Progress: 7.6% ... Training loss: 0.491 ... Validation loss: 0.492 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287691 -0.14116918]\n",
      "gradient\t[-1.19306036e-07  5.70207037e-07]\n",
      "weight after\t[-0.84287703 -0.14116861]\n",
      "Progress: 7.7% ... Training loss: 0.490 ... Validation loss: 0.491 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287703 -0.14116861]\n",
      "gradient\t[-4.25221350e-08  6.60402772e-07]\n",
      "weight after\t[-0.84287707 -0.14116795]\n",
      "Progress: 7.7% ... Training loss: 0.490 ... Validation loss: 0.491 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287707 -0.14116795]\n",
      "gradient\t[-1.06501662e-07  2.13200146e-06]\n",
      "weight after\t[-0.84287718 -0.14116582]\n",
      "Progress: 7.8% ... Training loss: 0.490 ... Validation loss: 0.491 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287718 -0.14116582]\n",
      "gradient\t[-2.99445849e-08  1.64400160e-06]\n",
      "weight after\t[-0.84287721 -0.14116417]\n",
      "Progress: 7.8% ... Training loss: 0.490 ... Validation loss: 0.491 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287721 -0.14116417]\n",
      "gradient\t[-1.03708138e-08  4.05812929e-08]\n",
      "weight after\t[-0.84287722 -0.14116413]\n",
      "Progress: 7.8% ... Training loss: 0.490 ... Validation loss: 0.490 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287722 -0.14116413]\n",
      "gradient\t[-1.27237958e-07  6.79019703e-07]\n",
      "weight after\t[-0.84287734 -0.14116346]\n",
      "Progress: 7.9% ... Training loss: 0.490 ... Validation loss: 0.490 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287734 -0.14116346]\n",
      "gradient\t[-7.39904134e-08  5.45370391e-07]\n",
      "weight after\t[-0.84287742 -0.14116291]\n",
      "Progress: 8.0% ... Training loss: 0.490 ... Validation loss: 0.490 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287742 -0.14116291]\n",
      "gradient\t[-4.66937464e-08  3.47983261e-07]\n",
      "weight after\t[-0.84287746 -0.14116256]\n",
      "Progress: 8.0% ... Training loss: 0.490 ... Validation loss: 0.490 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287746 -0.14116256]\n",
      "gradient\t[-3.13123437e-08  2.02527406e-06]\n",
      "weight after\t[-0.84287749 -0.14116054]\n",
      "Progress: 8.1% ... Training loss: 0.490 ... Validation loss: 0.490 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287749 -0.14116054]\n",
      "gradient\t[-1.41607451e-08  4.83364866e-07]\n",
      "weight after\t[-0.84287751 -0.14116005]\n",
      "Progress: 8.1% ... Training loss: 0.490 ... Validation loss: 0.490 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287751 -0.14116005]\n",
      "gradient\t[-9.56664023e-08  7.89049786e-07]\n",
      "weight after\t[-0.8428776  -0.14115926]\n",
      "Progress: 8.2% ... Training loss: 0.490 ... Validation loss: 0.490 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.8428776  -0.14115926]\n",
      "gradient\t[-1.90303877e-08  2.63285028e-06]\n",
      "weight after\t[-0.84287762 -0.14115663]\n",
      "Progress: 8.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287762 -0.14115663]\n",
      "gradient\t[-6.15083811e-08  1.22470630e-06]\n",
      "weight after\t[-0.84287769 -0.14115541]\n",
      "Progress: 8.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287769 -0.14115541]\n",
      "gradient\t[-4.23889556e-08  2.83594316e-06]\n",
      "weight after\t[-0.84287773 -0.14115257]\n",
      "Progress: 8.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287773 -0.14115257]\n",
      "gradient\t[-1.98004891e-07  6.35880208e-06]\n",
      "weight after\t[-0.84287793 -0.14114621]\n",
      "Progress: 8.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287793 -0.14114621]\n",
      "gradient\t[-1.04350973e-07  8.73770648e-07]\n",
      "weight after\t[-0.84287803 -0.14114534]\n",
      "Progress: 8.4% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287803 -0.14114534]\n",
      "gradient\t[-1.65614606e-07  8.82896645e-07]\n",
      "weight after\t[-0.8428782  -0.14114446]\n",
      "Progress: 8.4% ... Training loss: 0.489 ... Validation loss: 0.489 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.8428782  -0.14114446]\n",
      "gradient\t[-1.09408059e-07  3.25667979e-06]\n",
      "weight after\t[-0.8428783 -0.1411412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 8.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.8428783 -0.1411412]\n",
      "gradient\t[-1.48375717e-07  1.50268008e-06]\n",
      "weight after\t[-0.84287845 -0.1411397 ]\n",
      "Progress: 8.6% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287845 -0.1411397 ]\n",
      "gradient\t[-5.41429227e-08  2.90747172e-06]\n",
      "weight after\t[-0.84287851 -0.14113679]\n",
      "Progress: 8.6% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287851 -0.14113679]\n",
      "gradient\t[-7.19262027e-08  4.41580505e-07]\n",
      "weight after\t[-0.84287858 -0.14113635]\n",
      "Progress: 8.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287858 -0.14113635]\n",
      "gradient\t[-3.13194668e-08  3.43543633e-07]\n",
      "weight after\t[-0.84287861 -0.141136  ]\n",
      "Progress: 8.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287861 -0.141136  ]\n",
      "gradient\t[-8.22004552e-08  6.58719276e-07]\n",
      "weight after\t[-0.84287869 -0.14113534]\n",
      "Progress: 8.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287869 -0.14113534]\n",
      "gradient\t[-1.69077757e-07  5.02089018e-06]\n",
      "weight after\t[-0.84287886 -0.14113032]\n",
      "Progress: 8.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287886 -0.14113032]\n",
      "gradient\t[-1.52530823e-08  3.16890775e-07]\n",
      "weight after\t[-0.84287888 -0.14113001]\n",
      "Progress: 8.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287888 -0.14113001]\n",
      "gradient\t[-1.65055887e-07  3.71320357e-06]\n",
      "weight after\t[-0.84287904 -0.14112629]\n",
      "Progress: 8.9% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 0.98 ... Validation Acc: 0.98\n",
      "\n",
      "weight before\t[-0.84287904 -0.14112629]\n",
      "gradient\t[-4.40797000e-08  5.84172496e-07]\n",
      "weight after\t[-0.84287909 -0.14112571]\n",
      "Progress: 8.9% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.84287909 -0.14112571]\n",
      "gradient\t[-1.05961372e-07  9.60948506e-07]\n",
      "weight after\t[-0.84287919 -0.14112475]\n",
      "Progress: 9.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.84287919 -0.14112475]\n",
      "gradient\t[-4.40884201e-08  2.15271726e-06]\n",
      "weight after\t[-0.84287924 -0.1411226 ]\n",
      "Progress: 9.1% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.84287924 -0.1411226 ]\n",
      "gradient\t[-1.04100396e-07  9.16506436e-07]\n",
      "weight after\t[-0.84287934 -0.14112168]\n",
      "Progress: 9.1% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.84287934 -0.14112168]\n",
      "gradient\t[-1.90385227e-07  2.10738046e-06]\n",
      "weight after\t[-0.84287953 -0.14111957]\n",
      "Progress: 9.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.84287953 -0.14111957]\n",
      "gradient\t[-5.81505491e-08  5.04558953e-07]\n",
      "weight after\t[-0.84287959 -0.14111907]\n",
      "Progress: 9.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.84287959 -0.14111907]\n",
      "gradient\t[-7.02145726e-08  8.33485174e-07]\n",
      "weight after\t[-0.84287966 -0.14111823]\n",
      "Progress: 9.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.84287966 -0.14111823]\n",
      "gradient\t[-4.53982632e-08  8.09633400e-07]\n",
      "weight after\t[-0.8428797  -0.14111742]\n",
      "Progress: 9.3% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.8428797  -0.14111742]\n",
      "gradient\t[-1.90062036e-08  9.19700098e-07]\n",
      "weight after\t[-0.84287972 -0.1411165 ]\n",
      "Progress: 9.3% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.84287972 -0.1411165 ]\n",
      "gradient\t[-5.64585225e-08  1.82813295e-06]\n",
      "weight after\t[-0.84287978 -0.14111468]\n",
      "Progress: 9.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.84287978 -0.14111468]\n",
      "gradient\t[-8.97908797e-08  7.69287031e-07]\n",
      "weight after\t[-0.84287987 -0.14111391]\n",
      "Progress: 9.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.84287987 -0.14111391]\n",
      "gradient\t[-1.1074039e-07  1.3850960e-06]\n",
      "weight after\t[-0.84287998 -0.14111252]\n",
      "Progress: 9.5% ... Training loss: 0.488 ... Validation loss: 0.485 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.84287998 -0.14111252]\n",
      "gradient\t[-2.59883899e-09  1.92660935e-09]\n",
      "weight after\t[-0.84287998 -0.14111252]\n",
      "Progress: 9.6% ... Training loss: 0.488 ... Validation loss: 0.485 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.84287998 -0.14111252]\n",
      "gradient\t[-7.83716732e-08  5.34941712e-07]\n",
      "weight after\t[-0.84288006 -0.14111199]\n",
      "Progress: 9.6% ... Training loss: 0.488 ... Validation loss: 0.485 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.84288006 -0.14111199]\n",
      "gradient\t[-2.96485339e-08  2.71128954e-06]\n",
      "weight after\t[-0.84288009 -0.14110927]\n",
      "Progress: 9.7% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 0.983 ... Validation Acc: 0.983\n",
      "\n",
      "weight before\t[-0.84288009 -0.14110927]\n",
      "gradient\t[-6.83718992e-08  2.10968455e-06]\n",
      "weight after\t[-0.84288016 -0.14110716]\n",
      "Progress: 9.7% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288016 -0.14110716]\n",
      "gradient\t[-1.39707644e-07  3.99705633e-06]\n",
      "weight after\t[-0.8428803  -0.14110317]\n",
      "Progress: 9.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.8428803  -0.14110317]\n",
      "gradient\t[-1.30416187e-07  2.67741155e-06]\n",
      "weight after\t[-0.84288043 -0.14110049]\n",
      "Progress: 9.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288043 -0.14110049]\n",
      "gradient\t[-1.18480525e-07  3.43643488e-06]\n",
      "weight after\t[-0.84288055 -0.14109705]\n",
      "Progress: 9.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288055 -0.14109705]\n",
      "gradient\t[-4.41394613e-08  9.00805769e-07]\n",
      "weight after\t[-0.84288059 -0.14109615]\n",
      "Progress: 9.9% ... Training loss: 0.488 ... Validation loss: 0.485 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288059 -0.14109615]\n",
      "gradient\t[-6.47090170e-08  4.13776735e-07]\n",
      "weight after\t[-0.84288066 -0.14109574]\n",
      "Progress: 9.9% ... Training loss: 0.488 ... Validation loss: 0.485 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288066 -0.14109574]\n",
      "gradient\t[-8.17542405e-08  1.13764039e-06]\n",
      "weight after\t[-0.84288074 -0.1410946 ]\n",
      "Progress: 10.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288074 -0.1410946 ]\n",
      "gradient\t[-7.01836306e-08  1.35460184e-06]\n",
      "weight after\t[-0.84288081 -0.14109325]\n",
      "Progress: 10.1% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288081 -0.14109325]\n",
      "gradient\t[-6.29099344e-08  3.28448880e-06]\n",
      "weight after\t[-0.84288087 -0.14108996]\n",
      "Progress: 10.1% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288087 -0.14108996]\n",
      "gradient\t[-4.46510334e-08  8.91080727e-06]\n",
      "weight after\t[-0.84288092 -0.14108105]\n",
      "Progress: 10.2% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288092 -0.14108105]\n",
      "gradient\t[-6.98726032e-08  2.44039061e-06]\n",
      "weight after\t[-0.84288099 -0.14107861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10.2% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288099 -0.14107861]\n",
      "gradient\t[-2.07477181e-08  9.99796619e-07]\n",
      "weight after\t[-0.84288101 -0.14107761]\n",
      "Progress: 10.2% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288101 -0.14107761]\n",
      "gradient\t[-2.11245718e-08  4.11463923e-07]\n",
      "weight after\t[-0.84288103 -0.1410772 ]\n",
      "Progress: 10.3% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288103 -0.1410772 ]\n",
      "gradient\t[-1.55795035e-08  2.51575144e-07]\n",
      "weight after\t[-0.84288104 -0.14107695]\n",
      "Progress: 10.3% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288104 -0.14107695]\n",
      "gradient\t[-5.62223353e-08  4.92872627e-07]\n",
      "weight after\t[-0.8428811  -0.14107646]\n",
      "Progress: 10.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.8428811  -0.14107646]\n",
      "gradient\t[-2.27914526e-08  4.09316035e-07]\n",
      "weight after\t[-0.84288112 -0.14107605]\n",
      "Progress: 10.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288112 -0.14107605]\n",
      "gradient\t[-7.34762562e-08  5.18233138e-07]\n",
      "weight after\t[-0.8428812  -0.14107553]\n",
      "Progress: 10.5% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.8428812  -0.14107553]\n",
      "gradient\t[-1.1181072e-08  2.1193147e-06]\n",
      "weight after\t[-0.84288121 -0.14107341]\n",
      "Progress: 10.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288121 -0.14107341]\n",
      "gradient\t[-1.36437449e-07  1.45568768e-06]\n",
      "weight after\t[-0.84288134 -0.14107195]\n",
      "Progress: 10.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288134 -0.14107195]\n",
      "gradient\t[-7.63205948e-08  2.56315420e-06]\n",
      "weight after\t[-0.84288142 -0.14106939]\n",
      "Progress: 10.7% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288142 -0.14106939]\n",
      "gradient\t[-4.22941094e-08  1.12309847e-06]\n",
      "weight after\t[-0.84288146 -0.14106827]\n",
      "Progress: 10.7% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288146 -0.14106827]\n",
      "gradient\t[-5.68347472e-08  5.30745184e-07]\n",
      "weight after\t[-0.84288152 -0.14106774]\n",
      "Progress: 10.8% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288152 -0.14106774]\n",
      "gradient\t[-1.50105839e-07  1.77910538e-06]\n",
      "weight after\t[-0.84288167 -0.14106596]\n",
      "Progress: 10.8% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288167 -0.14106596]\n",
      "gradient\t[-2.03671925e-08  2.02991357e-07]\n",
      "weight after\t[-0.84288169 -0.14106575]\n",
      "Progress: 10.8% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 0.986 ... Validation Acc: 0.986\n",
      "\n",
      "weight before\t[-0.84288169 -0.14106575]\n",
      "gradient\t[-1.20632005e-07  5.81416921e-06]\n",
      "weight after\t[-0.84288181 -0.14105994]\n",
      "Progress: 10.9% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288181 -0.14105994]\n",
      "gradient\t[-1.86687557e-08  6.79298236e-07]\n",
      "weight after\t[-0.84288183 -0.14105926]\n",
      "Progress: 10.9% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288183 -0.14105926]\n",
      "gradient\t[-5.65906070e-08  3.10563557e-06]\n",
      "weight after\t[-0.84288189 -0.14105615]\n",
      "Progress: 11.0% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288189 -0.14105615]\n",
      "gradient\t[-4.79893120e-09  2.12919243e-07]\n",
      "weight after\t[-0.84288189 -0.14105594]\n",
      "Progress: 11.1% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288189 -0.14105594]\n",
      "gradient\t[-7.92308388e-08  3.95681715e-06]\n",
      "weight after\t[-0.84288197 -0.14105198]\n",
      "Progress: 11.1% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288197 -0.14105198]\n",
      "gradient\t[-8.67844578e-08  1.39090395e-06]\n",
      "weight after\t[-0.84288206 -0.14105059]\n",
      "Progress: 11.2% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288206 -0.14105059]\n",
      "gradient\t[-1.01217519e-07  5.14384568e-06]\n",
      "weight after\t[-0.84288216 -0.14104545]\n",
      "Progress: 11.2% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288216 -0.14104545]\n",
      "gradient\t[-8.33560966e-08  1.19260874e-06]\n",
      "weight after\t[-0.84288224 -0.14104426]\n",
      "Progress: 11.2% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288224 -0.14104426]\n",
      "gradient\t[-1.51925987e-08  8.58739728e-07]\n",
      "weight after\t[-0.84288226 -0.1410434 ]\n",
      "Progress: 11.3% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288226 -0.1410434 ]\n",
      "gradient\t[-2.30204974e-07  2.82503473e-06]\n",
      "weight after\t[-0.84288249 -0.14104057]\n",
      "Progress: 11.3% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288249 -0.14104057]\n",
      "gradient\t[-2.74517614e-08  3.51670412e-07]\n",
      "weight after\t[-0.84288251 -0.14104022]\n",
      "Progress: 11.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288251 -0.14104022]\n",
      "gradient\t[-5.59153192e-08  2.76675581e-06]\n",
      "weight after\t[-0.84288257 -0.14103745]\n",
      "Progress: 11.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288257 -0.14103745]\n",
      "gradient\t[-1.06502533e-07  4.22033620e-06]\n",
      "weight after\t[-0.84288268 -0.14103323]\n",
      "Progress: 11.5% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288268 -0.14103323]\n",
      "gradient\t[-5.08621195e-08  7.30154052e-07]\n",
      "weight after\t[-0.84288273 -0.1410325 ]\n",
      "Progress: 11.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288273 -0.1410325 ]\n",
      "gradient\t[-5.54948195e-08  2.35972433e-06]\n",
      "weight after\t[-0.84288278 -0.14103014]\n",
      "Progress: 11.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288278 -0.14103014]\n",
      "gradient\t[-5.51931159e-08  4.87165250e-07]\n",
      "weight after\t[-0.84288284 -0.14102966]\n",
      "Progress: 11.7% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288284 -0.14102966]\n",
      "gradient\t[-1.35009182e-08  3.23720687e-06]\n",
      "weight after\t[-0.84288285 -0.14102642]\n",
      "Progress: 11.7% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288285 -0.14102642]\n",
      "gradient\t[-1.12321232e-07  1.11265421e-06]\n",
      "weight after\t[-0.84288296 -0.14102531]\n",
      "Progress: 11.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288296 -0.14102531]\n",
      "gradient\t[-3.70541481e-08  6.99535112e-07]\n",
      "weight after\t[-0.842883   -0.14102461]\n",
      "Progress: 11.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.842883   -0.14102461]\n",
      "gradient\t[-4.51854824e-08  6.27145414e-06]\n",
      "weight after\t[-0.84288305 -0.14101834]\n",
      "Progress: 11.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288305 -0.14101834]\n",
      "gradient\t[-5.79900868e-08  7.91187564e-07]\n",
      "weight after\t[-0.8428831  -0.14101755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 11.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.8428831  -0.14101755]\n",
      "gradient\t[-1.08090798e-07  1.61149141e-06]\n",
      "weight after\t[-0.84288321 -0.14101593]\n",
      "Progress: 11.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288321 -0.14101593]\n",
      "gradient\t[-2.03604743e-08  3.11446121e-06]\n",
      "weight after\t[-0.84288323 -0.14101282]\n",
      "Progress: 12.0% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288323 -0.14101282]\n",
      "gradient\t[-4.63143116e-08  5.99167486e-07]\n",
      "weight after\t[-0.84288328 -0.14101222]\n",
      "Progress: 12.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288328 -0.14101222]\n",
      "gradient\t[-5.10057559e-08  5.55492691e-07]\n",
      "weight after\t[-0.84288333 -0.14101166]\n",
      "Progress: 12.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288333 -0.14101166]\n",
      "gradient\t[-1.57631767e-07  2.39146469e-06]\n",
      "weight after\t[-0.84288349 -0.14100927]\n",
      "Progress: 12.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288349 -0.14100927]\n",
      "gradient\t[-6.34536216e-08  6.21255790e-06]\n",
      "weight after\t[-0.84288355 -0.14100306]\n",
      "Progress: 12.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288355 -0.14100306]\n",
      "gradient\t[-4.24969481e-08  1.16918292e-06]\n",
      "weight after\t[-0.84288359 -0.14100189]\n",
      "Progress: 12.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.99 ... Validation Acc: 0.99\n",
      "\n",
      "weight before\t[-0.84288359 -0.14100189]\n",
      "gradient\t[-3.35275061e-08  1.62909502e-06]\n",
      "weight after\t[-0.84288363 -0.14100026]\n",
      "Progress: 12.3% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.993 ... Validation Acc: 0.993\n",
      "\n",
      "weight before\t[-0.84288363 -0.14100026]\n",
      "gradient\t[-9.12164686e-08  1.81919263e-06]\n",
      "weight after\t[-0.84288372 -0.14099844]\n",
      "Progress: 12.3% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.993 ... Validation Acc: 0.993\n",
      "\n",
      "weight before\t[-0.84288372 -0.14099844]\n",
      "gradient\t[-7.44718414e-09  2.62501888e-06]\n",
      "weight after\t[-0.84288373 -0.14099582]\n",
      "Progress: 12.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.993 ... Validation Acc: 0.993\n",
      "\n",
      "weight before\t[-0.84288373 -0.14099582]\n",
      "gradient\t[-1.20878818e-07  1.75563651e-06]\n",
      "weight after\t[-0.84288385 -0.14099406]\n",
      "Progress: 12.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.993 ... Validation Acc: 0.993\n",
      "\n",
      "weight before\t[-0.84288385 -0.14099406]\n",
      "gradient\t[-1.14360798e-07  1.04116069e-06]\n",
      "weight after\t[-0.84288396 -0.14099302]\n",
      "Progress: 12.5% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.993 ... Validation Acc: 0.993\n",
      "\n",
      "weight before\t[-0.84288396 -0.14099302]\n",
      "gradient\t[-9.70682711e-09  2.76296976e-06]\n",
      "weight after\t[-0.84288397 -0.14099026]\n",
      "Progress: 12.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.993 ... Validation Acc: 0.993\n",
      "\n",
      "weight before\t[-0.84288397 -0.14099026]\n",
      "gradient\t[-6.16233110e-08  1.50295846e-06]\n",
      "weight after\t[-0.84288403 -0.14098876]\n",
      "Progress: 12.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.993 ... Validation Acc: 0.993\n",
      "\n",
      "weight before\t[-0.84288403 -0.14098876]\n",
      "gradient\t[-1.16946894e-08  2.05222756e-06]\n",
      "weight after\t[-0.84288404 -0.1409867 ]\n",
      "Progress: 12.7% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.993 ... Validation Acc: 0.993\n",
      "\n",
      "weight before\t[-0.84288404 -0.1409867 ]\n",
      "gradient\t[-8.35032370e-08  1.19847315e-06]\n",
      "weight after\t[-0.84288413 -0.1409855 ]\n",
      "Progress: 12.7% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.993 ... Validation Acc: 0.993\n",
      "\n",
      "weight before\t[-0.84288413 -0.1409855 ]\n",
      "gradient\t[-2.89908924e-09  4.53118870e-09]\n",
      "weight after\t[-0.84288413 -0.1409855 ]\n",
      "Progress: 12.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288413 -0.1409855 ]\n",
      "gradient\t[-1.80981426e-08  5.01827523e-06]\n",
      "weight after\t[-0.84288415 -0.14098048]\n",
      "Progress: 12.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288415 -0.14098048]\n",
      "gradient\t[-5.25255410e-08  7.50841209e-07]\n",
      "weight after\t[-0.8428842  -0.14097973]\n",
      "Progress: 12.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.8428842  -0.14097973]\n",
      "gradient\t[-6.59203392e-08  4.77459977e-06]\n",
      "weight after\t[-0.84288427 -0.14097496]\n",
      "Progress: 12.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288427 -0.14097496]\n",
      "gradient\t[-4.01576829e-09  1.28913450e-08]\n",
      "weight after\t[-0.84288427 -0.14097494]\n",
      "Progress: 12.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288427 -0.14097494]\n",
      "gradient\t[-6.00092971e-08  3.02817681e-06]\n",
      "weight after\t[-0.84288433 -0.14097192]\n",
      "Progress: 13.0% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288433 -0.14097192]\n",
      "gradient\t[-1.33249714e-07  3.20483403e-06]\n",
      "weight after\t[-0.84288446 -0.14096871]\n",
      "Progress: 13.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288446 -0.14096871]\n",
      "gradient\t[-8.87774596e-08  1.61718387e-06]\n",
      "weight after\t[-0.84288455 -0.14096709]\n",
      "Progress: 13.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288455 -0.14096709]\n",
      "gradient\t[-9.80954916e-09  3.24017833e-07]\n",
      "weight after\t[-0.84288456 -0.14096677]\n",
      "Progress: 13.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288456 -0.14096677]\n",
      "gradient\t[-1.16417354e-08  1.95296253e-06]\n",
      "weight after\t[-0.84288457 -0.14096482]\n",
      "Progress: 13.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288457 -0.14096482]\n",
      "gradient\t[-8.50706239e-08  1.68164055e-06]\n",
      "weight after\t[-0.84288466 -0.14096314]\n",
      "Progress: 13.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288466 -0.14096314]\n",
      "gradient\t[-1.61558506e-07  2.48071691e-06]\n",
      "weight after\t[-0.84288482 -0.14096065]\n",
      "Progress: 13.3% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288482 -0.14096065]\n",
      "gradient\t[-6.21737055e-08  7.94831970e-07]\n",
      "weight after\t[-0.84288488 -0.14095986]\n",
      "Progress: 13.3% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288488 -0.14095986]\n",
      "gradient\t[-5.19217830e-08  7.14334563e-07]\n",
      "weight after\t[-0.84288493 -0.14095915]\n",
      "Progress: 13.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288493 -0.14095915]\n",
      "gradient\t[-1.66525770e-08  6.21040765e-07]\n",
      "weight after\t[-0.84288495 -0.14095852]\n",
      "Progress: 13.4% ... Training loss: 0.484 ... Validation loss: 0.481 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288495 -0.14095852]\n",
      "gradient\t[-2.14199259e-08  1.13730282e-06]\n",
      "weight after\t[-0.84288497 -0.14095739]\n",
      "Progress: 13.5% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288497 -0.14095739]\n",
      "gradient\t[-1.16467962e-07  4.76229884e-06]\n",
      "weight after\t[-0.84288509 -0.14095262]\n",
      "Progress: 13.6% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288509 -0.14095262]\n",
      "gradient\t[-5.44300538e-08  2.57672131e-06]\n",
      "weight after\t[-0.84288514 -0.14095005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 13.6% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288514 -0.14095005]\n",
      "gradient\t[-4.59343616e-09  2.29145588e-08]\n",
      "weight after\t[-0.84288515 -0.14095002]\n",
      "Progress: 13.7% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288515 -0.14095002]\n",
      "gradient\t[-2.6047907e-08  3.1011701e-06]\n",
      "weight after\t[-0.84288517 -0.14094692]\n",
      "Progress: 13.7% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288517 -0.14094692]\n",
      "gradient\t[-1.11353500e-08  2.36654562e-06]\n",
      "weight after\t[-0.84288519 -0.14094456]\n",
      "Progress: 13.8% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288519 -0.14094456]\n",
      "gradient\t[-2.68100602e-08  4.21766089e-07]\n",
      "weight after\t[-0.84288521 -0.14094414]\n",
      "Progress: 13.8% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288521 -0.14094414]\n",
      "gradient\t[-4.70472608e-08  3.52408461e-06]\n",
      "weight after\t[-0.84288526 -0.14094061]\n",
      "Progress: 13.8% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288526 -0.14094061]\n",
      "gradient\t[-1.17099097e-08  2.73534119e-07]\n",
      "weight after\t[-0.84288527 -0.14094034]\n",
      "Progress: 13.9% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288527 -0.14094034]\n",
      "gradient\t[-1.53083910e-08  5.56600364e-06]\n",
      "weight after\t[-0.84288529 -0.14093477]\n",
      "Progress: 13.9% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288529 -0.14093477]\n",
      "gradient\t[-1.06443482e-07  3.83023342e-06]\n",
      "weight after\t[-0.84288539 -0.14093094]\n",
      "Progress: 14.0% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288539 -0.14093094]\n",
      "gradient\t[-5.87876438e-08  2.52877393e-06]\n",
      "weight after\t[-0.84288545 -0.14092841]\n",
      "Progress: 14.1% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288545 -0.14092841]\n",
      "gradient\t[-5.32700005e-08  1.21912169e-06]\n",
      "weight after\t[-0.84288551 -0.14092719]\n",
      "Progress: 14.1% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288551 -0.14092719]\n",
      "gradient\t[-7.79141406e-08  1.18757435e-06]\n",
      "weight after\t[-0.84288558 -0.14092601]\n",
      "Progress: 14.2% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288558 -0.14092601]\n",
      "gradient\t[-7.08671144e-08  2.53608611e-06]\n",
      "weight after\t[-0.84288565 -0.14092347]\n",
      "Progress: 14.2% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288565 -0.14092347]\n",
      "gradient\t[-5.64267955e-08  3.28589473e-06]\n",
      "weight after\t[-0.84288571 -0.14092018]\n",
      "Progress: 14.2% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288571 -0.14092018]\n",
      "gradient\t[-1.0288155e-08  1.7998980e-06]\n",
      "weight after\t[-0.84288572 -0.14091838]\n",
      "Progress: 14.3% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288572 -0.14091838]\n",
      "gradient\t[-3.71073809e-08  8.87490120e-07]\n",
      "weight after\t[-0.84288576 -0.1409175 ]\n",
      "Progress: 14.3% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288576 -0.1409175 ]\n",
      "gradient\t[-1.00196715e-08  2.15452804e-07]\n",
      "weight after\t[-0.84288577 -0.14091728]\n",
      "Progress: 14.4% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288577 -0.14091728]\n",
      "gradient\t[-8.09960902e-08  1.27100247e-06]\n",
      "weight after\t[-0.84288585 -0.14091601]\n",
      "Progress: 14.4% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288585 -0.14091601]\n",
      "gradient\t[-2.51972501e-08  3.73097855e-07]\n",
      "weight after\t[-0.84288587 -0.14091564]\n",
      "Progress: 14.5% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288587 -0.14091564]\n",
      "gradient\t[-5.72350352e-08  1.73318941e-06]\n",
      "weight after\t[-0.84288593 -0.1409139 ]\n",
      "Progress: 14.6% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288593 -0.1409139 ]\n",
      "gradient\t[-2.79580627e-08  3.25420016e-07]\n",
      "weight after\t[-0.84288596 -0.14091358]\n",
      "Progress: 14.6% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288596 -0.14091358]\n",
      "gradient\t[-7.63709713e-08  1.67351836e-06]\n",
      "weight after\t[-0.84288604 -0.14091191]\n",
      "Progress: 14.7% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288604 -0.14091191]\n",
      "gradient\t[-5.70179537e-08  9.32678728e-07]\n",
      "weight after\t[-0.84288609 -0.14091097]\n",
      "Progress: 14.7% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288609 -0.14091097]\n",
      "gradient\t[-8.57575375e-09  4.17253247e-07]\n",
      "weight after\t[-0.8428861  -0.14091056]\n",
      "Progress: 14.8% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.8428861  -0.14091056]\n",
      "gradient\t[-5.63224897e-08  2.54045689e-06]\n",
      "weight after\t[-0.84288616 -0.14090801]\n",
      "Progress: 14.8% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288616 -0.14090801]\n",
      "gradient\t[-5.36148970e-08  7.17855395e-07]\n",
      "weight after\t[-0.84288621 -0.1409073 ]\n",
      "Progress: 14.8% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288621 -0.1409073 ]\n",
      "gradient\t[-4.26628890e-08  9.37578289e-07]\n",
      "weight after\t[-0.84288625 -0.14090636]\n",
      "Progress: 14.9% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288625 -0.14090636]\n",
      "gradient\t[-5.68045610e-08  3.85591077e-06]\n",
      "weight after\t[-0.84288631 -0.1409025 ]\n",
      "Progress: 14.9% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288631 -0.1409025 ]\n",
      "gradient\t[-8.85018534e-09  2.33844747e-06]\n",
      "weight after\t[-0.84288632 -0.14090016]\n",
      "Progress: 15.0% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288632 -0.14090016]\n",
      "gradient\t[-6.26028862e-08  5.16164132e-06]\n",
      "weight after\t[-0.84288638 -0.140895  ]\n",
      "Progress: 15.1% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288638 -0.140895  ]\n",
      "gradient\t[-3.13462650e-08  6.28506548e-07]\n",
      "weight after\t[-0.84288641 -0.14089437]\n",
      "Progress: 15.1% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288641 -0.14089437]\n",
      "gradient\t[-8.72355351e-08  5.27115099e-06]\n",
      "weight after\t[-0.8428865 -0.1408891]\n",
      "Progress: 15.2% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.8428865 -0.1408891]\n",
      "gradient\t[-3.25546436e-08  3.54513057e-06]\n",
      "weight after\t[-0.84288653 -0.14088556]\n",
      "Progress: 15.2% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288653 -0.14088556]\n",
      "gradient\t[-1.80938661e-08  5.16714361e-07]\n",
      "weight after\t[-0.84288655 -0.14088504]\n",
      "Progress: 15.2% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288655 -0.14088504]\n",
      "gradient\t[-8.15616529e-09  1.76289799e-07]\n",
      "weight after\t[-0.84288656 -0.14088487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 15.3% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288656 -0.14088487]\n",
      "gradient\t[-9.75369069e-09  1.89803640e-06]\n",
      "weight after\t[-0.84288657 -0.14088297]\n",
      "Progress: 15.3% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288657 -0.14088297]\n",
      "gradient\t[-5.11191251e-08  2.62063516e-06]\n",
      "weight after\t[-0.84288662 -0.14088035]\n",
      "Progress: 15.4% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 0.996 ... Validation Acc: 0.996\n",
      "\n",
      "weight before\t[-0.84288662 -0.14088035]\n",
      "gradient\t[-1.90038841e-08  1.07778414e-06]\n",
      "weight after\t[-0.84288664 -0.14087927]\n",
      "Progress: 15.4% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288664 -0.14087927]\n",
      "gradient\t[-1.28248446e-07  3.25214903e-06]\n",
      "weight after\t[-0.84288677 -0.14087602]\n",
      "Progress: 15.5% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288677 -0.14087602]\n",
      "gradient\t[-7.42441423e-09  2.65778704e-06]\n",
      "weight after\t[-0.84288677 -0.14087336]\n",
      "Progress: 15.6% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288677 -0.14087336]\n",
      "gradient\t[-9.99281954e-08  1.90538812e-06]\n",
      "weight after\t[-0.84288687 -0.14087145]\n",
      "Progress: 15.6% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288687 -0.14087145]\n",
      "gradient\t[-6.11867308e-08  1.26058704e-06]\n",
      "weight after\t[-0.84288694 -0.14087019]\n",
      "Progress: 15.7% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288694 -0.14087019]\n",
      "gradient\t[-2.34919124e-08  2.89682430e-06]\n",
      "weight after\t[-0.84288696 -0.1408673 ]\n",
      "Progress: 15.7% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288696 -0.1408673 ]\n",
      "gradient\t[-5.12126996e-08  2.29201061e-06]\n",
      "weight after\t[-0.84288701 -0.140865  ]\n",
      "Progress: 15.8% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288701 -0.140865  ]\n",
      "gradient\t[-4.77391574e-09  6.17264696e-08]\n",
      "weight after\t[-0.84288702 -0.14086494]\n",
      "Progress: 15.8% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288702 -0.14086494]\n",
      "gradient\t[-9.51384352e-08  1.89108096e-06]\n",
      "weight after\t[-0.84288711 -0.14086305]\n",
      "Progress: 15.8% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288711 -0.14086305]\n",
      "gradient\t[-4.10137484e-08  1.17340499e-06]\n",
      "weight after\t[-0.84288715 -0.14086188]\n",
      "Progress: 15.9% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288715 -0.14086188]\n",
      "gradient\t[-2.54406878e-08  5.96445697e-06]\n",
      "weight after\t[-0.84288718 -0.14085591]\n",
      "Progress: 15.9% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288718 -0.14085591]\n",
      "gradient\t[-2.53426988e-08  2.16432896e-06]\n",
      "weight after\t[-0.8428872  -0.14085375]\n",
      "Progress: 16.0% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428872  -0.14085375]\n",
      "gradient\t[-3.99440247e-08  6.89568539e-07]\n",
      "weight after\t[-0.84288724 -0.14085306]\n",
      "Progress: 16.1% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288724 -0.14085306]\n",
      "gradient\t[-1.31824521e-07  2.65486293e-06]\n",
      "weight after\t[-0.84288737 -0.1408504 ]\n",
      "Progress: 16.1% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288737 -0.1408504 ]\n",
      "gradient\t[-5.26477972e-08  2.33229636e-06]\n",
      "weight after\t[-0.84288743 -0.14084807]\n",
      "Progress: 16.1% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288743 -0.14084807]\n",
      "gradient\t[-1.85357526e-08  4.95171921e-07]\n",
      "weight after\t[-0.84288745 -0.14084758]\n",
      "Progress: 16.2% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288745 -0.14084758]\n",
      "gradient\t[-1.70965038e-08  8.05574915e-07]\n",
      "weight after\t[-0.84288746 -0.14084677]\n",
      "Progress: 16.2% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288746 -0.14084677]\n",
      "gradient\t[-2.31633731e-08  6.81851045e-07]\n",
      "weight after\t[-0.84288749 -0.14084609]\n",
      "Progress: 16.3% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288749 -0.14084609]\n",
      "gradient\t[-1.94727553e-08  1.00312057e-06]\n",
      "weight after\t[-0.84288751 -0.14084509]\n",
      "Progress: 16.4% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288751 -0.14084509]\n",
      "gradient\t[-2.38914409e-08  5.51280270e-07]\n",
      "weight after\t[-0.84288753 -0.14084454]\n",
      "Progress: 16.4% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288753 -0.14084454]\n",
      "gradient\t[-3.98652688e-08  3.18970893e-06]\n",
      "weight after\t[-0.84288757 -0.14084135]\n",
      "Progress: 16.4% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288757 -0.14084135]\n",
      "gradient\t[-3.80778968e-08  2.25351102e-06]\n",
      "weight after\t[-0.84288761 -0.14083909]\n",
      "Progress: 16.5% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288761 -0.14083909]\n",
      "gradient\t[-2.00914364e-08  3.73066037e-07]\n",
      "weight after\t[-0.84288763 -0.14083872]\n",
      "Progress: 16.6% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288763 -0.14083872]\n",
      "gradient\t[-1.28331775e-08  2.97763403e-06]\n",
      "weight after\t[-0.84288764 -0.14083574]\n",
      "Progress: 16.6% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288764 -0.14083574]\n",
      "gradient\t[-1.82345001e-08  3.38101438e-07]\n",
      "weight after\t[-0.84288766 -0.1408354 ]\n",
      "Progress: 16.6% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288766 -0.1408354 ]\n",
      "gradient\t[-1.75345570e-07  2.78031306e-06]\n",
      "weight after\t[-0.84288783 -0.14083262]\n",
      "Progress: 16.7% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288783 -0.14083262]\n",
      "gradient\t[-2.24447016e-08  5.96635528e-07]\n",
      "weight after\t[-0.84288786 -0.14083203]\n",
      "Progress: 16.8% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288786 -0.14083203]\n",
      "gradient\t[-2.78733613e-08  6.50592284e-07]\n",
      "weight after\t[-0.84288788 -0.14083138]\n",
      "Progress: 16.8% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288788 -0.14083138]\n",
      "gradient\t[-4.19709709e-09  1.93748842e-07]\n",
      "weight after\t[-0.84288789 -0.14083118]\n",
      "Progress: 16.9% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288789 -0.14083118]\n",
      "gradient\t[-1.00664192e-07  2.56418494e-06]\n",
      "weight after\t[-0.84288799 -0.14082862]\n",
      "Progress: 16.9% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288799 -0.14082862]\n",
      "gradient\t[-3.24683821e-08  8.47485795e-07]\n",
      "weight after\t[-0.84288802 -0.14082777]\n",
      "Progress: 16.9% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288802 -0.14082777]\n",
      "gradient\t[-5.36599246e-08  1.52802260e-06]\n",
      "weight after\t[-0.84288807 -0.14082624]\n",
      "Progress: 17.0% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288807 -0.14082624]\n",
      "gradient\t[-1.02416449e-08  1.87179208e-06]\n",
      "weight after\t[-0.84288808 -0.14082437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 17.1% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288808 -0.14082437]\n",
      "gradient\t[-2.98247602e-08  2.94941373e-06]\n",
      "weight after\t[-0.84288811 -0.14082142]\n",
      "Progress: 17.1% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288811 -0.14082142]\n",
      "gradient\t[-3.39579070e-08  7.08107012e-07]\n",
      "weight after\t[-0.84288815 -0.14082071]\n",
      "Progress: 17.1% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288815 -0.14082071]\n",
      "gradient\t[-2.45776146e-08  2.43699531e-07]\n",
      "weight after\t[-0.84288817 -0.14082047]\n",
      "Progress: 17.2% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288817 -0.14082047]\n",
      "gradient\t[-2.82733949e-08  2.69416008e-06]\n",
      "weight after\t[-0.8428882  -0.14081778]\n",
      "Progress: 17.2% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428882  -0.14081778]\n",
      "gradient\t[-1.48821323e-08  9.24064775e-07]\n",
      "weight after\t[-0.84288822 -0.14081685]\n",
      "Progress: 17.3% ... Training loss: 0.484 ... Validation loss: 0.480 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288822 -0.14081685]\n",
      "gradient\t[-5.63048614e-08  3.46831269e-06]\n",
      "weight after\t[-0.84288827 -0.14081338]\n",
      "Progress: 17.4% ... Training loss: 0.484 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288827 -0.14081338]\n",
      "gradient\t[-4.09772384e-08  1.31920752e-06]\n",
      "weight after\t[-0.84288831 -0.14081206]\n",
      "Progress: 17.4% ... Training loss: 0.484 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288831 -0.14081206]\n",
      "gradient\t[-1.17580486e-07  2.08605704e-06]\n",
      "weight after\t[-0.84288843 -0.14080998]\n",
      "Progress: 17.4% ... Training loss: 0.484 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288843 -0.14080998]\n",
      "gradient\t[-1.65446888e-08  2.69203564e-07]\n",
      "weight after\t[-0.84288845 -0.14080971]\n",
      "Progress: 17.5% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288845 -0.14080971]\n",
      "gradient\t[-8.02464247e-08  1.04662000e-06]\n",
      "weight after\t[-0.84288853 -0.14080866]\n",
      "Progress: 17.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288853 -0.14080866]\n",
      "gradient\t[-6.16152601e-08  3.18518594e-06]\n",
      "weight after\t[-0.84288859 -0.14080548]\n",
      "Progress: 17.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288859 -0.14080548]\n",
      "gradient\t[-8.01962377e-09  3.23307762e-07]\n",
      "weight after\t[-0.8428886  -0.14080515]\n",
      "Progress: 17.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428886  -0.14080515]\n",
      "gradient\t[-1.79651834e-08  1.04027064e-06]\n",
      "weight after\t[-0.84288862 -0.14080411]\n",
      "Progress: 17.7% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288862 -0.14080411]\n",
      "gradient\t[-3.23050179e-08  5.03167420e-07]\n",
      "weight after\t[-0.84288865 -0.14080361]\n",
      "Progress: 17.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288865 -0.14080361]\n",
      "gradient\t[-6.95833832e-08  1.32903866e-06]\n",
      "weight after\t[-0.84288872 -0.14080228]\n",
      "Progress: 17.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288872 -0.14080228]\n",
      "gradient\t[-4.38972701e-08  6.70601866e-07]\n",
      "weight after\t[-0.84288876 -0.14080161]\n",
      "Progress: 17.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288876 -0.14080161]\n",
      "gradient\t[-5.02637858e-08  1.48172980e-06]\n",
      "weight after\t[-0.84288881 -0.14080013]\n",
      "Progress: 17.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288881 -0.14080013]\n",
      "gradient\t[-6.80621743e-08  9.54810939e-07]\n",
      "weight after\t[-0.84288888 -0.14079917]\n",
      "Progress: 17.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288888 -0.14079917]\n",
      "gradient\t[-9.69276406e-08  3.71898215e-06]\n",
      "weight after\t[-0.84288898 -0.14079545]\n",
      "Progress: 18.0% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288898 -0.14079545]\n",
      "gradient\t[-3.52260230e-08  9.01657678e-07]\n",
      "weight after\t[-0.84288901 -0.14079455]\n",
      "Progress: 18.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288901 -0.14079455]\n",
      "gradient\t[-4.81370019e-08  9.52706064e-07]\n",
      "weight after\t[-0.84288906 -0.1407936 ]\n",
      "Progress: 18.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288906 -0.1407936 ]\n",
      "gradient\t[-5.17911835e-08  6.88424668e-07]\n",
      "weight after\t[-0.84288911 -0.14079291]\n",
      "Progress: 18.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288911 -0.14079291]\n",
      "gradient\t[-3.05494512e-09  2.41712117e-06]\n",
      "weight after\t[-0.84288911 -0.14079049]\n",
      "Progress: 18.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288911 -0.14079049]\n",
      "gradient\t[-2.87587449e-08  2.95487853e-06]\n",
      "weight after\t[-0.84288914 -0.14078754]\n",
      "Progress: 18.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288914 -0.14078754]\n",
      "gradient\t[-1.85252132e-08  9.39606344e-07]\n",
      "weight after\t[-0.84288916 -0.1407866 ]\n",
      "Progress: 18.3% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288916 -0.1407866 ]\n",
      "gradient\t[-3.12951577e-08  7.19118202e-07]\n",
      "weight after\t[-0.84288919 -0.14078588]\n",
      "Progress: 18.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288919 -0.14078588]\n",
      "gradient\t[-4.25006040e-08  1.88030394e-06]\n",
      "weight after\t[-0.84288924 -0.140784  ]\n",
      "Progress: 18.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288924 -0.140784  ]\n",
      "gradient\t[-2.57809999e-08  2.83346606e-06]\n",
      "weight after\t[-0.84288926 -0.14078117]\n",
      "Progress: 18.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288926 -0.14078117]\n",
      "gradient\t[-4.78982985e-08  7.15679818e-07]\n",
      "weight after\t[-0.84288931 -0.14078045]\n",
      "Progress: 18.5% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288931 -0.14078045]\n",
      "gradient\t[-8.49001629e-08  9.10566345e-07]\n",
      "weight after\t[-0.84288939 -0.14077954]\n",
      "Progress: 18.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288939 -0.14077954]\n",
      "gradient\t[-5.7212448e-08  1.0228832e-06]\n",
      "weight after\t[-0.84288945 -0.14077852]\n",
      "Progress: 18.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288945 -0.14077852]\n",
      "gradient\t[-4.80998001e-08  6.33605249e-07]\n",
      "weight after\t[-0.8428895  -0.14077788]\n",
      "Progress: 18.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428895  -0.14077788]\n",
      "gradient\t[-3.45398020e-09  6.18796003e-08]\n",
      "weight after\t[-0.8428895  -0.14077782]\n",
      "Progress: 18.7% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428895  -0.14077782]\n",
      "gradient\t[-9.52096842e-08  1.19278626e-06]\n",
      "weight after\t[-0.8428896  -0.14077663]\n",
      "Progress: 18.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428896  -0.14077663]\n",
      "gradient\t[-4.88945107e-09  1.15500131e-07]\n",
      "weight after\t[-0.8428896  -0.14077651]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 18.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428896  -0.14077651]\n",
      "gradient\t[-2.12638918e-08  2.70069493e-06]\n",
      "weight after\t[-0.84288962 -0.14077381]\n",
      "Progress: 18.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288962 -0.14077381]\n",
      "gradient\t[-3.37334910e-08  4.37676247e-06]\n",
      "weight after\t[-0.84288966 -0.14076944]\n",
      "Progress: 18.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288966 -0.14076944]\n",
      "gradient\t[-9.14987666e-09  3.38458533e-07]\n",
      "weight after\t[-0.84288967 -0.1407691 ]\n",
      "Progress: 18.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288967 -0.1407691 ]\n",
      "gradient\t[-2.51258454e-08  5.52496859e-07]\n",
      "weight after\t[-0.84288969 -0.14076855]\n",
      "Progress: 19.0% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288969 -0.14076855]\n",
      "gradient\t[-4.02244123e-08  1.20974053e-06]\n",
      "weight after\t[-0.84288973 -0.14076734]\n",
      "Progress: 19.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288973 -0.14076734]\n",
      "gradient\t[-1.28887028e-08  3.78994922e-06]\n",
      "weight after\t[-0.84288975 -0.14076355]\n",
      "Progress: 19.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288975 -0.14076355]\n",
      "gradient\t[-5.85845517e-08  7.68846981e-07]\n",
      "weight after\t[-0.8428898  -0.14076278]\n",
      "Progress: 19.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428898  -0.14076278]\n",
      "gradient\t[-4.17881388e-08  2.63488563e-06]\n",
      "weight after\t[-0.84288985 -0.14076014]\n",
      "Progress: 19.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288985 -0.14076014]\n",
      "gradient\t[-6.30033959e-09  3.43504626e-07]\n",
      "weight after\t[-0.84288985 -0.1407598 ]\n",
      "Progress: 19.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288985 -0.1407598 ]\n",
      "gradient\t[-2.82578527e-08  2.56236012e-06]\n",
      "weight after\t[-0.84288988 -0.14075724]\n",
      "Progress: 19.3% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288988 -0.14075724]\n",
      "gradient\t[-4.80108106e-08  9.33446852e-07]\n",
      "weight after\t[-0.84288993 -0.1407563 ]\n",
      "Progress: 19.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288993 -0.1407563 ]\n",
      "gradient\t[-5.44979772e-08  5.56576589e-07]\n",
      "weight after\t[-0.84288998 -0.14075575]\n",
      "Progress: 19.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84288998 -0.14075575]\n",
      "gradient\t[-1.74409034e-08  2.54903559e-06]\n",
      "weight after\t[-0.84289   -0.1407532]\n",
      "Progress: 19.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289   -0.1407532]\n",
      "gradient\t[-5.33589984e-08  1.83783627e-06]\n",
      "weight after\t[-0.84289005 -0.14075136]\n",
      "Progress: 19.5% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289005 -0.14075136]\n",
      "gradient\t[-5.69452926e-08  9.19678120e-07]\n",
      "weight after\t[-0.84289011 -0.14075044]\n",
      "Progress: 19.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289011 -0.14075044]\n",
      "gradient\t[-2.56468336e-08  1.48561228e-06]\n",
      "weight after\t[-0.84289014 -0.14074895]\n",
      "Progress: 19.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289014 -0.14074895]\n",
      "gradient\t[-1.31045043e-08  4.49263719e-07]\n",
      "weight after\t[-0.84289015 -0.14074851]\n",
      "Progress: 19.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289015 -0.14074851]\n",
      "gradient\t[-1.88013806e-08  4.74459296e-07]\n",
      "weight after\t[-0.84289017 -0.14074803]\n",
      "Progress: 19.7% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289017 -0.14074803]\n",
      "gradient\t[-3.96283393e-08  4.53249286e-07]\n",
      "weight after\t[-0.84289021 -0.14074758]\n",
      "Progress: 19.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289021 -0.14074758]\n",
      "gradient\t[-5.17030647e-08  2.92230046e-06]\n",
      "weight after\t[-0.84289026 -0.14074466]\n",
      "Progress: 19.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289026 -0.14074466]\n",
      "gradient\t[-4.83619435e-09  1.65391414e-07]\n",
      "weight after\t[-0.84289026 -0.14074449]\n",
      "Progress: 19.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289026 -0.14074449]\n",
      "gradient\t[-5.05727310e-09  2.47775785e-08]\n",
      "weight after\t[-0.84289027 -0.14074447]\n",
      "Progress: 19.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289027 -0.14074447]\n",
      "gradient\t[-1.95445709e-08  4.47044783e-07]\n",
      "weight after\t[-0.84289029 -0.14074402]\n",
      "Progress: 19.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289029 -0.14074402]\n",
      "gradient\t[-1.79306136e-08  8.51766533e-07]\n",
      "weight after\t[-0.84289031 -0.14074317]\n",
      "Progress: 20.0% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289031 -0.14074317]\n",
      "gradient\t[-2.48805548e-09  4.35925832e-08]\n",
      "weight after\t[-0.84289031 -0.14074312]\n",
      "Progress: 20.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289031 -0.14074312]\n",
      "gradient\t[-2.44845849e-08  7.03858917e-07]\n",
      "weight after\t[-0.84289033 -0.14074242]\n",
      "Progress: 20.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289033 -0.14074242]\n",
      "gradient\t[-9.82286207e-08  2.49228269e-06]\n",
      "weight after\t[-0.84289043 -0.14073993]\n",
      "Progress: 20.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289043 -0.14073993]\n",
      "gradient\t[-7.30256492e-08  1.12846251e-06]\n",
      "weight after\t[-0.84289051 -0.1407388 ]\n",
      "Progress: 20.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289051 -0.1407388 ]\n",
      "gradient\t[-4.30544821e-08  6.64854176e-07]\n",
      "weight after\t[-0.84289055 -0.14073813]\n",
      "Progress: 20.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289055 -0.14073813]\n",
      "gradient\t[-1.58652639e-08  3.15898325e-07]\n",
      "weight after\t[-0.84289056 -0.14073782]\n",
      "Progress: 20.3% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289056 -0.14073782]\n",
      "gradient\t[-2.82562294e-09  1.31606838e-07]\n",
      "weight after\t[-0.84289057 -0.14073769]\n",
      "Progress: 20.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289057 -0.14073769]\n",
      "gradient\t[-1.61563903e-08  3.77771667e-06]\n",
      "weight after\t[-0.84289058 -0.14073391]\n",
      "Progress: 20.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289058 -0.14073391]\n",
      "gradient\t[-4.05239585e-09  2.82557441e-07]\n",
      "weight after\t[-0.84289059 -0.14073363]\n",
      "Progress: 20.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289059 -0.14073363]\n",
      "gradient\t[-2.13113293e-08  7.05086602e-07]\n",
      "weight after\t[-0.84289061 -0.14073292]\n",
      "Progress: 20.5% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289061 -0.14073292]\n",
      "gradient\t[-7.99455261e-09  3.01209172e-07]\n",
      "weight after\t[-0.84289062 -0.14073262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 20.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289062 -0.14073262]\n",
      "gradient\t[-6.72137747e-08  3.07648092e-06]\n",
      "weight after\t[-0.84289068 -0.14072954]\n",
      "Progress: 20.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289068 -0.14072954]\n",
      "gradient\t[-2.56723356e-08  7.09150922e-07]\n",
      "weight after\t[-0.84289071 -0.14072883]\n",
      "Progress: 20.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289071 -0.14072883]\n",
      "gradient\t[-4.29643274e-08  7.06626820e-07]\n",
      "weight after\t[-0.84289075 -0.14072813]\n",
      "Progress: 20.7% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289075 -0.14072813]\n",
      "gradient\t[-3.86085590e-08  5.88420875e-07]\n",
      "weight after\t[-0.84289079 -0.14072754]\n",
      "Progress: 20.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289079 -0.14072754]\n",
      "gradient\t[-3.78793508e-08  2.55979191e-06]\n",
      "weight after\t[-0.84289083 -0.14072498]\n",
      "Progress: 20.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289083 -0.14072498]\n",
      "gradient\t[-3.58768729e-08  4.87288583e-07]\n",
      "weight after\t[-0.84289087 -0.14072449]\n",
      "Progress: 20.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289087 -0.14072449]\n",
      "gradient\t[-5.81969010e-08  8.17890013e-07]\n",
      "weight after\t[-0.84289092 -0.14072367]\n",
      "Progress: 20.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289092 -0.14072367]\n",
      "gradient\t[-1.31443716e-08  4.23125483e-07]\n",
      "weight after\t[-0.84289094 -0.14072325]\n",
      "Progress: 20.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289094 -0.14072325]\n",
      "gradient\t[-3.72364774e-08  3.90255222e-07]\n",
      "weight after\t[-0.84289097 -0.14072286]\n",
      "Progress: 21.0% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289097 -0.14072286]\n",
      "gradient\t[-3.50924978e-08  5.26554832e-07]\n",
      "weight after\t[-0.84289101 -0.14072233]\n",
      "Progress: 21.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289101 -0.14072233]\n",
      "gradient\t[-5.67109844e-09  1.47751251e-07]\n",
      "weight after\t[-0.84289101 -0.14072219]\n",
      "Progress: 21.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289101 -0.14072219]\n",
      "gradient\t[-1.97225245e-08  2.66805115e-07]\n",
      "weight after\t[-0.84289103 -0.14072192]\n",
      "Progress: 21.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289103 -0.14072192]\n",
      "gradient\t[-6.50068893e-08  1.30773729e-06]\n",
      "weight after\t[-0.8428911  -0.14072061]\n",
      "Progress: 21.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428911  -0.14072061]\n",
      "gradient\t[-1.66515382e-08  1.56998715e-06]\n",
      "weight after\t[-0.84289112 -0.14071904]\n",
      "Progress: 21.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289112 -0.14071904]\n",
      "gradient\t[-7.73734016e-09  2.33268796e-06]\n",
      "weight after\t[-0.84289112 -0.14071671]\n",
      "Progress: 21.3% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289112 -0.14071671]\n",
      "gradient\t[-5.52545909e-08  1.13549406e-06]\n",
      "weight after\t[-0.84289118 -0.14071557]\n",
      "Progress: 21.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289118 -0.14071557]\n",
      "gradient\t[-4.21896411e-08  4.98962483e-06]\n",
      "weight after\t[-0.84289122 -0.14071058]\n",
      "Progress: 21.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289122 -0.14071058]\n",
      "gradient\t[-1.86657176e-08  2.64695976e-07]\n",
      "weight after\t[-0.84289124 -0.14071032]\n",
      "Progress: 21.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289124 -0.14071032]\n",
      "gradient\t[-9.61845332e-08  2.04792882e-06]\n",
      "weight after\t[-0.84289134 -0.14070827]\n",
      "Progress: 21.5% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289134 -0.14070827]\n",
      "gradient\t[-2.34532090e-08  6.49186226e-07]\n",
      "weight after\t[-0.84289136 -0.14070762]\n",
      "Progress: 21.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289136 -0.14070762]\n",
      "gradient\t[-3.79454708e-08  7.55271429e-07]\n",
      "weight after\t[-0.8428914  -0.14070687]\n",
      "Progress: 21.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428914  -0.14070687]\n",
      "gradient\t[-3.19662908e-08  6.08862945e-07]\n",
      "weight after\t[-0.84289143 -0.14070626]\n",
      "Progress: 21.6% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289143 -0.14070626]\n",
      "gradient\t[-1.20017365e-08  2.65443640e-07]\n",
      "weight after\t[-0.84289144 -0.14070599]\n",
      "Progress: 21.7% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289144 -0.14070599]\n",
      "gradient\t[-2.32393054e-09  1.24094724e-07]\n",
      "weight after\t[-0.84289144 -0.14070587]\n",
      "Progress: 21.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289144 -0.14070587]\n",
      "gradient\t[-5.03696899e-08  8.04618965e-07]\n",
      "weight after\t[-0.84289149 -0.14070506]\n",
      "Progress: 21.8% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289149 -0.14070506]\n",
      "gradient\t[-7.05281933e-08  2.82466202e-06]\n",
      "weight after\t[-0.84289156 -0.14070224]\n",
      "Progress: 21.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289156 -0.14070224]\n",
      "gradient\t[-7.21691173e-08  2.22917573e-06]\n",
      "weight after\t[-0.84289164 -0.14070001]\n",
      "Progress: 21.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289164 -0.14070001]\n",
      "gradient\t[-1.35298644e-08  2.98385619e-07]\n",
      "weight after\t[-0.84289165 -0.14069971]\n",
      "Progress: 21.9% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289165 -0.14069971]\n",
      "gradient\t[-8.10556479e-08  1.30710791e-06]\n",
      "weight after\t[-0.84289173 -0.1406984 ]\n",
      "Progress: 22.0% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289173 -0.1406984 ]\n",
      "gradient\t[-5.19531820e-08  7.98766392e-07]\n",
      "weight after\t[-0.84289178 -0.14069761]\n",
      "Progress: 22.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289178 -0.14069761]\n",
      "gradient\t[-4.03927264e-08  3.79063319e-06]\n",
      "weight after\t[-0.84289182 -0.14069381]\n",
      "Progress: 22.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289182 -0.14069381]\n",
      "gradient\t[-1.37511162e-07  3.94838821e-06]\n",
      "weight after\t[-0.84289196 -0.14068987]\n",
      "Progress: 22.1% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289196 -0.14068987]\n",
      "gradient\t[-6.57565520e-08  8.85044976e-07]\n",
      "weight after\t[-0.84289203 -0.14068898]\n",
      "Progress: 22.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289203 -0.14068898]\n",
      "gradient\t[-7.06746783e-08  7.30043317e-07]\n",
      "weight after\t[-0.8428921  -0.14068825]\n",
      "Progress: 22.2% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428921  -0.14068825]\n",
      "gradient\t[-1.32978183e-09  3.79794759e-09]\n",
      "weight after\t[-0.8428921  -0.14068825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 22.3% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428921  -0.14068825]\n",
      "gradient\t[-3.08974623e-10  6.70470855e-11]\n",
      "weight after\t[-0.8428921  -0.14068825]\n",
      "Progress: 22.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428921  -0.14068825]\n",
      "gradient\t[-1.36480904e-08  3.15991600e-07]\n",
      "weight after\t[-0.84289211 -0.14068793]\n",
      "Progress: 22.4% ... Training loss: 0.485 ... Validation loss: 0.481 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289211 -0.14068793]\n",
      "gradient\t[-1.28089434e-08  1.46746308e-07]\n",
      "weight after\t[-0.84289213 -0.14068778]\n",
      "Progress: 22.4% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289213 -0.14068778]\n",
      "gradient\t[-1.81834622e-08  3.35958783e-07]\n",
      "weight after\t[-0.84289214 -0.14068745]\n",
      "Progress: 22.5% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289214 -0.14068745]\n",
      "gradient\t[-2.43512122e-08  4.90698604e-07]\n",
      "weight after\t[-0.84289217 -0.14068696]\n",
      "Progress: 22.6% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289217 -0.14068696]\n",
      "gradient\t[-2.32838807e-08  3.26201346e-06]\n",
      "weight after\t[-0.84289219 -0.1406837 ]\n",
      "Progress: 22.6% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289219 -0.1406837 ]\n",
      "gradient\t[-8.86195058e-08  1.23372380e-06]\n",
      "weight after\t[-0.84289228 -0.14068246]\n",
      "Progress: 22.6% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289228 -0.14068246]\n",
      "gradient\t[-3.79129231e-08  6.00833792e-07]\n",
      "weight after\t[-0.84289232 -0.14068186]\n",
      "Progress: 22.7% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289232 -0.14068186]\n",
      "gradient\t[-3.01314212e-08  6.02803746e-07]\n",
      "weight after\t[-0.84289235 -0.14068126]\n",
      "Progress: 22.8% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289235 -0.14068126]\n",
      "gradient\t[-2.52120781e-09  1.21940869e-08]\n",
      "weight after\t[-0.84289235 -0.14068125]\n",
      "Progress: 22.8% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289235 -0.14068125]\n",
      "gradient\t[-7.20312581e-08  2.21338462e-06]\n",
      "weight after\t[-0.84289242 -0.14067903]\n",
      "Progress: 22.9% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289242 -0.14067903]\n",
      "gradient\t[-1.39531204e-08  2.21157741e-07]\n",
      "weight after\t[-0.84289244 -0.14067881]\n",
      "Progress: 22.9% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289244 -0.14067881]\n",
      "gradient\t[-5.97450175e-08  4.67181743e-06]\n",
      "weight after\t[-0.8428925  -0.14067414]\n",
      "Progress: 22.9% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428925  -0.14067414]\n",
      "gradient\t[-8.98644128e-09  1.79741195e-07]\n",
      "weight after\t[-0.84289251 -0.14067396]\n",
      "Progress: 23.0% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289251 -0.14067396]\n",
      "gradient\t[-3.02474021e-09  2.24401381e-08]\n",
      "weight after\t[-0.84289251 -0.14067394]\n",
      "Progress: 23.1% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289251 -0.14067394]\n",
      "gradient\t[-4.42237741e-08  2.64415218e-06]\n",
      "weight after\t[-0.84289255 -0.14067129]\n",
      "Progress: 23.1% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289255 -0.14067129]\n",
      "gradient\t[-2.03380354e-09  7.57218400e-09]\n",
      "weight after\t[-0.84289255 -0.14067129]\n",
      "Progress: 23.1% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289255 -0.14067129]\n",
      "gradient\t[-2.31094136e-08  2.20618906e-06]\n",
      "weight after\t[-0.84289258 -0.14066908]\n",
      "Progress: 23.2% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289258 -0.14066908]\n",
      "gradient\t[-8.30575797e-09  2.08873100e-06]\n",
      "weight after\t[-0.84289259 -0.14066699]\n",
      "Progress: 23.2% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289259 -0.14066699]\n",
      "gradient\t[-4.84522047e-08  3.41170088e-06]\n",
      "weight after\t[-0.84289263 -0.14066358]\n",
      "Progress: 23.3% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289263 -0.14066358]\n",
      "gradient\t[-1.48455076e-08  2.18698524e-07]\n",
      "weight after\t[-0.84289265 -0.14066336]\n",
      "Progress: 23.4% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289265 -0.14066336]\n",
      "gradient\t[-4.09140093e-09  8.44999420e-08]\n",
      "weight after\t[-0.84289265 -0.14066328]\n",
      "Progress: 23.4% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289265 -0.14066328]\n",
      "gradient\t[-5.54700773e-08  6.72638171e-07]\n",
      "weight after\t[-0.84289271 -0.1406626 ]\n",
      "Progress: 23.4% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289271 -0.1406626 ]\n",
      "gradient\t[-5.00845293e-08  9.97212066e-07]\n",
      "weight after\t[-0.84289276 -0.14066161]\n",
      "Progress: 23.5% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289276 -0.14066161]\n",
      "gradient\t[-3.71363115e-08  5.86969326e-07]\n",
      "weight after\t[-0.8428928  -0.14066102]\n",
      "Progress: 23.6% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428928  -0.14066102]\n",
      "gradient\t[-4.54780021e-08  4.73387868e-07]\n",
      "weight after\t[-0.84289284 -0.14066055]\n",
      "Progress: 23.6% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289284 -0.14066055]\n",
      "gradient\t[-3.48435860e-08  7.53707432e-07]\n",
      "weight after\t[-0.84289288 -0.14065979]\n",
      "Progress: 23.6% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289288 -0.14065979]\n",
      "gradient\t[-2.89188901e-08  5.05710645e-07]\n",
      "weight after\t[-0.84289291 -0.14065929]\n",
      "Progress: 23.7% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289291 -0.14065929]\n",
      "gradient\t[-4.54225632e-08  7.10999078e-07]\n",
      "weight after\t[-0.84289295 -0.14065858]\n",
      "Progress: 23.8% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289295 -0.14065858]\n",
      "gradient\t[-2.86116088e-09  2.15455367e-07]\n",
      "weight after\t[-0.84289295 -0.14065836]\n",
      "Progress: 23.8% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289295 -0.14065836]\n",
      "gradient\t[-3.54445929e-08  3.71191024e-07]\n",
      "weight after\t[-0.84289299 -0.14065799]\n",
      "Progress: 23.9% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289299 -0.14065799]\n",
      "gradient\t[-2.10108533e-08  3.12807529e-06]\n",
      "weight after\t[-0.84289301 -0.14065486]\n",
      "Progress: 23.9% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289301 -0.14065486]\n",
      "gradient\t[-2.82284401e-08  6.14768260e-07]\n",
      "weight after\t[-0.84289304 -0.14065425]\n",
      "Progress: 23.9% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289304 -0.14065425]\n",
      "gradient\t[-1.41852575e-08  2.00295820e-06]\n",
      "weight after\t[-0.84289305 -0.14065224]\n",
      "Progress: 24.0% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289305 -0.14065224]\n",
      "gradient\t[-2.00319900e-08  2.03010241e-06]\n",
      "weight after\t[-0.84289307 -0.14065021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 24.1% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289307 -0.14065021]\n",
      "gradient\t[-6.89021075e-08  1.14024021e-06]\n",
      "weight after\t[-0.84289314 -0.14064907]\n",
      "Progress: 24.1% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289314 -0.14064907]\n",
      "gradient\t[-2.52752458e-08  5.07271102e-07]\n",
      "weight after\t[-0.84289317 -0.14064857]\n",
      "Progress: 24.1% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289317 -0.14064857]\n",
      "gradient\t[-2.64655164e-08  4.29069572e-07]\n",
      "weight after\t[-0.84289319 -0.14064814]\n",
      "Progress: 24.2% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289319 -0.14064814]\n",
      "gradient\t[-7.51377173e-09  2.22457456e-07]\n",
      "weight after\t[-0.8428932  -0.14064791]\n",
      "Progress: 24.2% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428932  -0.14064791]\n",
      "gradient\t[-5.15940469e-08  2.60230635e-06]\n",
      "weight after\t[-0.84289325 -0.14064531]\n",
      "Progress: 24.3% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289325 -0.14064531]\n",
      "gradient\t[-2.92701581e-08  7.69603063e-07]\n",
      "weight after\t[-0.84289328 -0.14064454]\n",
      "Progress: 24.4% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289328 -0.14064454]\n",
      "gradient\t[-5.59746648e-08  7.57784725e-07]\n",
      "weight after\t[-0.84289334 -0.14064378]\n",
      "Progress: 24.4% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289334 -0.14064378]\n",
      "gradient\t[-3.49530655e-08  3.50575611e-07]\n",
      "weight after\t[-0.84289337 -0.14064343]\n",
      "Progress: 24.4% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289337 -0.14064343]\n",
      "gradient\t[-1.09355334e-08  5.09900429e-07]\n",
      "weight after\t[-0.84289338 -0.14064292]\n",
      "Progress: 24.5% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289338 -0.14064292]\n",
      "gradient\t[-3.72570570e-08  6.54276298e-07]\n",
      "weight after\t[-0.84289342 -0.14064227]\n",
      "Progress: 24.6% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289342 -0.14064227]\n",
      "gradient\t[-1.90790054e-09  8.11615654e-08]\n",
      "weight after\t[-0.84289342 -0.14064219]\n",
      "Progress: 24.6% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289342 -0.14064219]\n",
      "gradient\t[-1.98737064e-08  2.45344672e-07]\n",
      "weight after\t[-0.84289344 -0.14064194]\n",
      "Progress: 24.6% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289344 -0.14064194]\n",
      "gradient\t[-9.15465160e-08  1.22191911e-06]\n",
      "weight after\t[-0.84289353 -0.14064072]\n",
      "Progress: 24.7% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289353 -0.14064072]\n",
      "gradient\t[-1.87443678e-08  3.06625935e-07]\n",
      "weight after\t[-0.84289355 -0.14064041]\n",
      "Progress: 24.8% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289355 -0.14064041]\n",
      "gradient\t[-7.24929309e-08  1.05324500e-06]\n",
      "weight after\t[-0.84289363 -0.14063936]\n",
      "Progress: 24.8% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289363 -0.14063936]\n",
      "gradient\t[-7.06327701e-08  1.03470493e-06]\n",
      "weight after\t[-0.8428937  -0.14063833]\n",
      "Progress: 24.9% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428937  -0.14063833]\n",
      "gradient\t[-6.13385049e-08  1.83714818e-06]\n",
      "weight after\t[-0.84289376 -0.14063649]\n",
      "Progress: 24.9% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289376 -0.14063649]\n",
      "gradient\t[-5.93370022e-08  7.97417484e-07]\n",
      "weight after\t[-0.84289382 -0.14063569]\n",
      "Progress: 24.9% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289382 -0.14063569]\n",
      "gradient\t[-3.91843791e-08  2.82107501e-06]\n",
      "weight after\t[-0.84289386 -0.14063287]\n",
      "Progress: 25.0% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289386 -0.14063287]\n",
      "gradient\t[-8.03946102e-09  4.98400405e-07]\n",
      "weight after\t[-0.84289386 -0.14063237]\n",
      "Progress: 25.1% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289386 -0.14063237]\n",
      "gradient\t[-1.05228337e-08  2.07148909e-06]\n",
      "weight after\t[-0.84289387 -0.1406303 ]\n",
      "Progress: 25.1% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289387 -0.1406303 ]\n",
      "gradient\t[-1.41709494e-08  2.01779106e-06]\n",
      "weight after\t[-0.84289389 -0.14062828]\n",
      "Progress: 25.1% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289389 -0.14062828]\n",
      "gradient\t[-1.93431351e-08  4.09250784e-06]\n",
      "weight after\t[-0.84289391 -0.14062419]\n",
      "Progress: 25.2% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289391 -0.14062419]\n",
      "gradient\t[-3.33842192e-08  1.59157536e-06]\n",
      "weight after\t[-0.84289394 -0.1406226 ]\n",
      "Progress: 25.2% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289394 -0.1406226 ]\n",
      "gradient\t[-4.53122049e-08  1.43425902e-06]\n",
      "weight after\t[-0.84289399 -0.14062117]\n",
      "Progress: 25.3% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289399 -0.14062117]\n",
      "gradient\t[-6.22606892e-09  2.91777801e-07]\n",
      "weight after\t[-0.84289399 -0.14062087]\n",
      "Progress: 25.4% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289399 -0.14062087]\n",
      "gradient\t[-6.30670080e-08  7.86248672e-07]\n",
      "weight after\t[-0.84289406 -0.14062009]\n",
      "Progress: 25.4% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289406 -0.14062009]\n",
      "gradient\t[-1.07155963e-08  2.29532278e-07]\n",
      "weight after\t[-0.84289407 -0.14061986]\n",
      "Progress: 25.4% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289407 -0.14061986]\n",
      "gradient\t[-9.17187182e-09  3.77851408e-07]\n",
      "weight after\t[-0.84289408 -0.14061948]\n",
      "Progress: 25.5% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289408 -0.14061948]\n",
      "gradient\t[-6.60293517e-08  1.03100772e-06]\n",
      "weight after\t[-0.84289414 -0.14061845]\n",
      "Progress: 25.6% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289414 -0.14061845]\n",
      "gradient\t[-3.55207666e-08  4.03315490e-07]\n",
      "weight after\t[-0.84289418 -0.14061805]\n",
      "Progress: 25.6% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289418 -0.14061805]\n",
      "gradient\t[-4.17582034e-08  5.63377826e-07]\n",
      "weight after\t[-0.84289422 -0.14061748]\n",
      "Progress: 25.6% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289422 -0.14061748]\n",
      "gradient\t[-1.76082393e-09  6.66075123e-08]\n",
      "weight after\t[-0.84289422 -0.14061742]\n",
      "Progress: 25.7% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289422 -0.14061742]\n",
      "gradient\t[-2.11276106e-09  6.00066890e-09]\n",
      "weight after\t[-0.84289422 -0.14061741]\n",
      "Progress: 25.8% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289422 -0.14061741]\n",
      "gradient\t[-1.63229328e-08  2.50586860e-07]\n",
      "weight after\t[-0.84289424 -0.14061716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 25.8% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289424 -0.14061716]\n",
      "gradient\t[-3.95988230e-08  4.18681967e-06]\n",
      "weight after\t[-0.84289428 -0.14061297]\n",
      "Progress: 25.9% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289428 -0.14061297]\n",
      "gradient\t[-2.33588581e-08  3.75798710e-06]\n",
      "weight after\t[-0.8428943  -0.14060921]\n",
      "Progress: 25.9% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428943  -0.14060921]\n",
      "gradient\t[-3.30670618e-08  4.22224604e-07]\n",
      "weight after\t[-0.84289434 -0.14060879]\n",
      "Progress: 25.9% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289434 -0.14060879]\n",
      "gradient\t[-9.93216338e-09  1.18752397e-06]\n",
      "weight after\t[-0.84289435 -0.1406076 ]\n",
      "Progress: 26.0% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289435 -0.1406076 ]\n",
      "gradient\t[-3.54827099e-08  1.16356216e-06]\n",
      "weight after\t[-0.84289438 -0.14060644]\n",
      "Progress: 26.1% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289438 -0.14060644]\n",
      "gradient\t[-2.65710844e-08  6.04124476e-07]\n",
      "weight after\t[-0.84289441 -0.14060584]\n",
      "Progress: 26.1% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289441 -0.14060584]\n",
      "gradient\t[-1.83999013e-08  2.07885289e-07]\n",
      "weight after\t[-0.84289443 -0.14060563]\n",
      "Progress: 26.1% ... Training loss: 0.485 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289443 -0.14060563]\n",
      "gradient\t[-3.04638557e-08  6.57440172e-07]\n",
      "weight after\t[-0.84289446 -0.14060497]\n",
      "Progress: 26.2% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289446 -0.14060497]\n",
      "gradient\t[-2.08401372e-08  2.16033782e-07]\n",
      "weight after\t[-0.84289448 -0.14060476]\n",
      "Progress: 26.2% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289448 -0.14060476]\n",
      "gradient\t[-3.31917928e-08  1.42753565e-06]\n",
      "weight after\t[-0.84289451 -0.14060333]\n",
      "Progress: 26.3% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289451 -0.14060333]\n",
      "gradient\t[-1.37031410e-08  2.77455308e-07]\n",
      "weight after\t[-0.84289452 -0.14060305]\n",
      "Progress: 26.4% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289452 -0.14060305]\n",
      "gradient\t[-3.81290347e-08  2.16158152e-06]\n",
      "weight after\t[-0.84289456 -0.14060089]\n",
      "Progress: 26.4% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289456 -0.14060089]\n",
      "gradient\t[-2.98206755e-08  2.27686344e-06]\n",
      "weight after\t[-0.84289459 -0.14059861]\n",
      "Progress: 26.4% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289459 -0.14059861]\n",
      "gradient\t[-8.39870484e-09  3.50029986e-07]\n",
      "weight after\t[-0.8428946  -0.14059826]\n",
      "Progress: 26.5% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428946  -0.14059826]\n",
      "gradient\t[-7.73836137e-09  1.57052620e-07]\n",
      "weight after\t[-0.84289461 -0.1405981 ]\n",
      "Progress: 26.6% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289461 -0.1405981 ]\n",
      "gradient\t[-4.98933093e-10  5.80167947e-08]\n",
      "weight after\t[-0.84289461 -0.14059805]\n",
      "Progress: 26.6% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289461 -0.14059805]\n",
      "gradient\t[-9.85606323e-09  9.00340142e-07]\n",
      "weight after\t[-0.84289462 -0.14059715]\n",
      "Progress: 26.6% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289462 -0.14059715]\n",
      "gradient\t[-2.22553131e-08  2.33342385e-07]\n",
      "weight after\t[-0.84289464 -0.14059691]\n",
      "Progress: 26.7% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289464 -0.14059691]\n",
      "gradient\t[-2.70530780e-08  3.79617422e-07]\n",
      "weight after\t[-0.84289467 -0.14059653]\n",
      "Progress: 26.8% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289467 -0.14059653]\n",
      "gradient\t[-2.78022336e-08  4.08659260e-07]\n",
      "weight after\t[-0.8428947  -0.14059612]\n",
      "Progress: 26.8% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428947  -0.14059612]\n",
      "gradient\t[-5.51594766e-08  5.80377499e-07]\n",
      "weight after\t[-0.84289475 -0.14059554]\n",
      "Progress: 26.9% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289475 -0.14059554]\n",
      "gradient\t[-5.25760361e-08  6.03249792e-07]\n",
      "weight after\t[-0.8428948  -0.14059494]\n",
      "Progress: 26.9% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428948  -0.14059494]\n",
      "gradient\t[-2.50767627e-08  3.11023154e-07]\n",
      "weight after\t[-0.84289483 -0.14059463]\n",
      "Progress: 26.9% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289483 -0.14059463]\n",
      "gradient\t[-3.57266730e-08  1.04878943e-06]\n",
      "weight after\t[-0.84289486 -0.14059358]\n",
      "Progress: 27.0% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289486 -0.14059358]\n",
      "gradient\t[-7.75854350e-09  3.48084263e-07]\n",
      "weight after\t[-0.84289487 -0.14059323]\n",
      "Progress: 27.1% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289487 -0.14059323]\n",
      "gradient\t[-5.39999911e-08  7.82265718e-07]\n",
      "weight after\t[-0.84289493 -0.14059245]\n",
      "Progress: 27.1% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289493 -0.14059245]\n",
      "gradient\t[-3.70132085e-08  2.27127345e-06]\n",
      "weight after\t[-0.84289496 -0.14059018]\n",
      "Progress: 27.1% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289496 -0.14059018]\n",
      "gradient\t[-1.26827542e-08  1.85187180e-06]\n",
      "weight after\t[-0.84289498 -0.14058833]\n",
      "Progress: 27.2% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289498 -0.14058833]\n",
      "gradient\t[-1.35806545e-07  1.45773845e-06]\n",
      "weight after\t[-0.84289511 -0.14058687]\n",
      "Progress: 27.2% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289511 -0.14058687]\n",
      "gradient\t[-4.25249645e-09  1.85234148e-06]\n",
      "weight after\t[-0.84289512 -0.14058502]\n",
      "Progress: 27.3% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289512 -0.14058502]\n",
      "gradient\t[-1.38875243e-08  1.92724039e-07]\n",
      "weight after\t[-0.84289513 -0.14058482]\n",
      "Progress: 27.4% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289513 -0.14058482]\n",
      "gradient\t[-4.65966310e-08  4.60087645e-07]\n",
      "weight after\t[-0.84289518 -0.14058436]\n",
      "Progress: 27.4% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289518 -0.14058436]\n",
      "gradient\t[-1.23514218e-08  2.54211906e-07]\n",
      "weight after\t[-0.84289519 -0.14058411]\n",
      "Progress: 27.4% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289519 -0.14058411]\n",
      "gradient\t[-1.63052723e-09  1.96250702e-08]\n",
      "weight after\t[-0.84289519 -0.14058409]\n",
      "Progress: 27.5% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289519 -0.14058409]\n",
      "gradient\t[-2.29178554e-08  1.92826798e-06]\n",
      "weight after\t[-0.84289521 -0.14058216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 27.6% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289521 -0.14058216]\n",
      "gradient\t[-1.80423553e-08  1.85645575e-06]\n",
      "weight after\t[-0.84289523 -0.14058031]\n",
      "Progress: 27.6% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289523 -0.14058031]\n",
      "gradient\t[-7.71732124e-09  1.66100731e-06]\n",
      "weight after\t[-0.84289524 -0.14057865]\n",
      "Progress: 27.6% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289524 -0.14057865]\n",
      "gradient\t[-1.38002945e-08  3.28101374e-07]\n",
      "weight after\t[-0.84289525 -0.14057832]\n",
      "Progress: 27.7% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289525 -0.14057832]\n",
      "gradient\t[-5.02348420e-08  4.27397366e-06]\n",
      "weight after\t[-0.8428953  -0.14057404]\n",
      "Progress: 27.8% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428953  -0.14057404]\n",
      "gradient\t[-4.18034430e-09  2.58171124e-07]\n",
      "weight after\t[-0.84289531 -0.14057379]\n",
      "Progress: 27.8% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289531 -0.14057379]\n",
      "gradient\t[-7.17690196e-09  1.69066362e-06]\n",
      "weight after\t[-0.84289531 -0.14057209]\n",
      "Progress: 27.9% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289531 -0.14057209]\n",
      "gradient\t[-1.95595370e-08  1.75808255e-06]\n",
      "weight after\t[-0.84289533 -0.14057034]\n",
      "Progress: 27.9% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289533 -0.14057034]\n",
      "gradient\t[-2.45911073e-09  5.24240912e-08]\n",
      "weight after\t[-0.84289534 -0.14057028]\n",
      "Progress: 27.9% ... Training loss: 0.486 ... Validation loss: 0.482 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289534 -0.14057028]\n",
      "gradient\t[-3.18419364e-08  3.34256971e-06]\n",
      "weight after\t[-0.84289537 -0.14056694]\n",
      "Progress: 28.0% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289537 -0.14056694]\n",
      "gradient\t[-2.98195502e-08  3.47729711e-07]\n",
      "weight after\t[-0.8428954  -0.14056659]\n",
      "Progress: 28.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428954  -0.14056659]\n",
      "gradient\t[-4.16588724e-08  5.29350642e-07]\n",
      "weight after\t[-0.84289544 -0.14056606]\n",
      "Progress: 28.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289544 -0.14056606]\n",
      "gradient\t[-2.17363317e-09  5.14175650e-09]\n",
      "weight after\t[-0.84289544 -0.14056606]\n",
      "Progress: 28.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289544 -0.14056606]\n",
      "gradient\t[-5.17877035e-08  6.56505838e-07]\n",
      "weight after\t[-0.84289549 -0.1405654 ]\n",
      "Progress: 28.2% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289549 -0.1405654 ]\n",
      "gradient\t[-3.75858502e-08  3.79013256e-07]\n",
      "weight after\t[-0.84289553 -0.14056502]\n",
      "Progress: 28.2% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289553 -0.14056502]\n",
      "gradient\t[-6.56892304e-08  1.39986510e-06]\n",
      "weight after\t[-0.8428956  -0.14056362]\n",
      "Progress: 28.3% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428956  -0.14056362]\n",
      "gradient\t[-1.57227243e-08  2.22518966e-07]\n",
      "weight after\t[-0.84289561 -0.1405634 ]\n",
      "Progress: 28.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289561 -0.1405634 ]\n",
      "gradient\t[-6.78781629e-08  2.19308470e-06]\n",
      "weight after\t[-0.84289568 -0.14056121]\n",
      "Progress: 28.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289568 -0.14056121]\n",
      "gradient\t[-1.76346519e-09  5.20510398e-09]\n",
      "weight after\t[-0.84289568 -0.1405612 ]\n",
      "Progress: 28.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289568 -0.1405612 ]\n",
      "gradient\t[-1.29589370e-09  9.97430019e-10]\n",
      "weight after\t[-0.84289568 -0.1405612 ]\n",
      "Progress: 28.5% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289568 -0.1405612 ]\n",
      "gradient\t[-1.23453722e-08  1.36091290e-07]\n",
      "weight after\t[-0.8428957  -0.14056107]\n",
      "Progress: 28.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428957  -0.14056107]\n",
      "gradient\t[-1.59250841e-08  3.13865479e-07]\n",
      "weight after\t[-0.84289571 -0.14056075]\n",
      "Progress: 28.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289571 -0.14056075]\n",
      "gradient\t[-5.23689185e-09  1.35233877e-07]\n",
      "weight after\t[-0.84289572 -0.14056062]\n",
      "Progress: 28.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289572 -0.14056062]\n",
      "gradient\t[-4.60386001e-09  7.79475811e-07]\n",
      "weight after\t[-0.84289572 -0.14055984]\n",
      "Progress: 28.7% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289572 -0.14055984]\n",
      "gradient\t[-5.01763472e-09  1.52306578e-06]\n",
      "weight after\t[-0.84289573 -0.14055831]\n",
      "Progress: 28.8% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289573 -0.14055831]\n",
      "gradient\t[-5.61773685e-08  5.62184811e-07]\n",
      "weight after\t[-0.84289578 -0.14055775]\n",
      "Progress: 28.8% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289578 -0.14055775]\n",
      "gradient\t[-3.47873832e-08  1.81922019e-06]\n",
      "weight after\t[-0.84289582 -0.14055593]\n",
      "Progress: 28.9% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289582 -0.14055593]\n",
      "gradient\t[-2.26502076e-08  5.95305826e-07]\n",
      "weight after\t[-0.84289584 -0.14055534]\n",
      "Progress: 28.9% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289584 -0.14055534]\n",
      "gradient\t[-8.72472294e-09  7.21062845e-07]\n",
      "weight after\t[-0.84289585 -0.14055462]\n",
      "Progress: 28.9% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289585 -0.14055462]\n",
      "gradient\t[-1.77183690e-08  1.60952576e-06]\n",
      "weight after\t[-0.84289587 -0.14055301]\n",
      "Progress: 29.0% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289587 -0.14055301]\n",
      "gradient\t[-1.95422940e-08  1.45038726e-06]\n",
      "weight after\t[-0.84289589 -0.14055156]\n",
      "Progress: 29.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289589 -0.14055156]\n",
      "gradient\t[-6.88139028e-08  8.06705468e-07]\n",
      "weight after\t[-0.84289595 -0.14055075]\n",
      "Progress: 29.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289595 -0.14055075]\n",
      "gradient\t[-5.04376029e-08  1.08901653e-06]\n",
      "weight after\t[-0.84289601 -0.14054966]\n",
      "Progress: 29.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289601 -0.14054966]\n",
      "gradient\t[-2.58997832e-09  5.68592140e-09]\n",
      "weight after\t[-0.84289601 -0.14054966]\n",
      "Progress: 29.2% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289601 -0.14054966]\n",
      "gradient\t[-4.24621884e-08  3.74854755e-07]\n",
      "weight after\t[-0.84289605 -0.14054928]\n",
      "Progress: 29.2% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289605 -0.14054928]\n",
      "gradient\t[-8.76946020e-08  7.51137457e-07]\n",
      "weight after\t[-0.84289614 -0.14054853]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 29.3% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289614 -0.14054853]\n",
      "gradient\t[-2.65210541e-08  3.63516795e-07]\n",
      "weight after\t[-0.84289616 -0.14054817]\n",
      "Progress: 29.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289616 -0.14054817]\n",
      "gradient\t[-5.62739976e-08  1.02485877e-06]\n",
      "weight after\t[-0.84289622 -0.14054714]\n",
      "Progress: 29.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289622 -0.14054714]\n",
      "gradient\t[-3.79475257e-08  1.05558073e-06]\n",
      "weight after\t[-0.84289626 -0.14054609]\n",
      "Progress: 29.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289626 -0.14054609]\n",
      "gradient\t[-1.51846167e-09  6.88106289e-09]\n",
      "weight after\t[-0.84289626 -0.14054608]\n",
      "Progress: 29.5% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289626 -0.14054608]\n",
      "gradient\t[-2.33061047e-08  2.10004472e-06]\n",
      "weight after\t[-0.84289628 -0.14054398]\n",
      "Progress: 29.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289628 -0.14054398]\n",
      "gradient\t[-6.11284815e-08  1.20655861e-06]\n",
      "weight after\t[-0.84289634 -0.14054277]\n",
      "Progress: 29.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289634 -0.14054277]\n",
      "gradient\t[-3.39568550e-08  3.56824941e-07]\n",
      "weight after\t[-0.84289638 -0.14054241]\n",
      "Progress: 29.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289638 -0.14054241]\n",
      "gradient\t[-2.25451596e-08  3.41930187e-07]\n",
      "weight after\t[-0.8428964  -0.14054207]\n",
      "Progress: 29.7% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428964  -0.14054207]\n",
      "gradient\t[-3.32473746e-08  1.68787532e-06]\n",
      "weight after\t[-0.84289643 -0.14054038]\n",
      "Progress: 29.8% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289643 -0.14054038]\n",
      "gradient\t[-5.20149061e-08  5.57527251e-07]\n",
      "weight after\t[-0.84289649 -0.14053983]\n",
      "Progress: 29.8% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289649 -0.14053983]\n",
      "gradient\t[-7.19770322e-09  1.49115965e-07]\n",
      "weight after\t[-0.84289649 -0.14053968]\n",
      "Progress: 29.9% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289649 -0.14053968]\n",
      "gradient\t[-6.95043262e-09  4.38302317e-06]\n",
      "weight after\t[-0.8428965 -0.1405353]\n",
      "Progress: 29.9% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428965 -0.1405353]\n",
      "gradient\t[-3.85095270e-08  4.07550629e-07]\n",
      "weight after\t[-0.84289654 -0.14053489]\n",
      "Progress: 29.9% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289654 -0.14053489]\n",
      "gradient\t[-1.97642150e-08  7.34755179e-07]\n",
      "weight after\t[-0.84289656 -0.14053415]\n",
      "Progress: 30.0% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289656 -0.14053415]\n",
      "gradient\t[-4.66657089e-08  1.48635935e-06]\n",
      "weight after\t[-0.84289661 -0.14053267]\n",
      "Progress: 30.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289661 -0.14053267]\n",
      "gradient\t[-8.82294367e-08  1.24818502e-06]\n",
      "weight after\t[-0.84289669 -0.14053142]\n",
      "Progress: 30.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289669 -0.14053142]\n",
      "gradient\t[-1.24045889e-09  5.75389628e-09]\n",
      "weight after\t[-0.84289669 -0.14053141]\n",
      "Progress: 30.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289669 -0.14053141]\n",
      "gradient\t[-2.02181122e-08  2.80178021e-07]\n",
      "weight after\t[-0.84289672 -0.14053113]\n",
      "Progress: 30.2% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289672 -0.14053113]\n",
      "gradient\t[-1.74160692e-08  1.39715964e-06]\n",
      "weight after\t[-0.84289673 -0.14052974]\n",
      "Progress: 30.2% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289673 -0.14052974]\n",
      "gradient\t[-5.22689294e-09  5.82390417e-08]\n",
      "weight after\t[-0.84289674 -0.14052968]\n",
      "Progress: 30.3% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289674 -0.14052968]\n",
      "gradient\t[-3.26929335e-08  3.20468308e-07]\n",
      "weight after\t[-0.84289677 -0.14052936]\n",
      "Progress: 30.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289677 -0.14052936]\n",
      "gradient\t[-4.42527049e-08  3.10180952e-07]\n",
      "weight after\t[-0.84289681 -0.14052905]\n",
      "Progress: 30.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289681 -0.14052905]\n",
      "gradient\t[-1.47427283e-09  1.19714728e-06]\n",
      "weight after\t[-0.84289682 -0.14052785]\n",
      "Progress: 30.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289682 -0.14052785]\n",
      "gradient\t[-1.1026237e-08  1.3856386e-06]\n",
      "weight after\t[-0.84289683 -0.14052646]\n",
      "Progress: 30.5% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289683 -0.14052646]\n",
      "gradient\t[-1.11009060e-08  1.49374274e-07]\n",
      "weight after\t[-0.84289684 -0.14052631]\n",
      "Progress: 30.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289684 -0.14052631]\n",
      "gradient\t[-1.56245643e-08  9.16497625e-08]\n",
      "weight after\t[-0.84289685 -0.14052622]\n",
      "Progress: 30.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289685 -0.14052622]\n",
      "gradient\t[-2.67316907e-09  1.27150064e-06]\n",
      "weight after\t[-0.84289686 -0.14052495]\n",
      "Progress: 30.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289686 -0.14052495]\n",
      "gradient\t[-2.80025716e-08  2.36320292e-07]\n",
      "weight after\t[-0.84289688 -0.14052471]\n",
      "Progress: 30.7% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289688 -0.14052471]\n",
      "gradient\t[-6.20881434e-08  5.23008290e-07]\n",
      "weight after\t[-0.84289695 -0.14052419]\n",
      "Progress: 30.8% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289695 -0.14052419]\n",
      "gradient\t[-3.89509567e-09  5.30519096e-08]\n",
      "weight after\t[-0.84289695 -0.14052414]\n",
      "Progress: 30.8% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289695 -0.14052414]\n",
      "gradient\t[-4.46352785e-08  8.78750260e-07]\n",
      "weight after\t[-0.842897   -0.14052326]\n",
      "Progress: 30.9% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.842897   -0.14052326]\n",
      "gradient\t[-2.63060086e-08  3.60127717e-07]\n",
      "weight after\t[-0.84289702 -0.1405229 ]\n",
      "Progress: 30.9% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289702 -0.1405229 ]\n",
      "gradient\t[-5.65796737e-08  5.04086465e-07]\n",
      "weight after\t[-0.84289708 -0.1405224 ]\n",
      "Progress: 30.9% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289708 -0.1405224 ]\n",
      "gradient\t[-3.66697307e-08  7.76482955e-07]\n",
      "weight after\t[-0.84289711 -0.14052162]\n",
      "Progress: 31.0% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289711 -0.14052162]\n",
      "gradient\t[-8.23328146e-09  5.40055489e-07]\n",
      "weight after\t[-0.84289712 -0.14052108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 31.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289712 -0.14052108]\n",
      "gradient\t[-2.01264538e-08  1.91824210e-07]\n",
      "weight after\t[-0.84289714 -0.14052089]\n",
      "Progress: 31.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289714 -0.14052089]\n",
      "gradient\t[-2.38920821e-09  9.43797565e-08]\n",
      "weight after\t[-0.84289715 -0.14052079]\n",
      "Progress: 31.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289715 -0.14052079]\n",
      "gradient\t[-2.75621294e-08  2.24884053e-07]\n",
      "weight after\t[-0.84289717 -0.14052057]\n",
      "Progress: 31.2% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289717 -0.14052057]\n",
      "gradient\t[-1.36133512e-08  1.88488286e-07]\n",
      "weight after\t[-0.84289719 -0.14052038]\n",
      "Progress: 31.2% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289719 -0.14052038]\n",
      "gradient\t[-1.85249371e-08  1.34190920e-06]\n",
      "weight after\t[-0.84289721 -0.14051904]\n",
      "Progress: 31.3% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289721 -0.14051904]\n",
      "gradient\t[-1.63620191e-08  2.45294617e-07]\n",
      "weight after\t[-0.84289722 -0.14051879]\n",
      "Progress: 31.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289722 -0.14051879]\n",
      "gradient\t[-1.42407018e-08  2.06451483e-07]\n",
      "weight after\t[-0.84289724 -0.14051859]\n",
      "Progress: 31.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289724 -0.14051859]\n",
      "gradient\t[-3.63009236e-08  1.34131870e-06]\n",
      "weight after\t[-0.84289727 -0.14051724]\n",
      "Progress: 31.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289727 -0.14051724]\n",
      "gradient\t[-4.18996270e-08  3.00477677e-07]\n",
      "weight after\t[-0.84289731 -0.14051694]\n",
      "Progress: 31.5% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289731 -0.14051694]\n",
      "gradient\t[-5.18561292e-08  6.25902206e-07]\n",
      "weight after\t[-0.84289737 -0.14051632]\n",
      "Progress: 31.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289737 -0.14051632]\n",
      "gradient\t[-2.33567899e-08  7.17592702e-07]\n",
      "weight after\t[-0.84289739 -0.1405156 ]\n",
      "Progress: 31.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289739 -0.1405156 ]\n",
      "gradient\t[-1.16352578e-08  1.41334103e-07]\n",
      "weight after\t[-0.8428974  -0.14051546]\n",
      "Progress: 31.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428974  -0.14051546]\n",
      "gradient\t[-3.13709419e-08  3.03861636e-07]\n",
      "weight after\t[-0.84289743 -0.14051516]\n",
      "Progress: 31.7% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289743 -0.14051516]\n",
      "gradient\t[-3.09575450e-08  2.68009082e-07]\n",
      "weight after\t[-0.84289746 -0.14051489]\n",
      "Progress: 31.8% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289746 -0.14051489]\n",
      "gradient\t[-3.17540007e-08  3.17298625e-07]\n",
      "weight after\t[-0.84289749 -0.14051457]\n",
      "Progress: 31.8% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289749 -0.14051457]\n",
      "gradient\t[-1.38226023e-08  1.22870893e-07]\n",
      "weight after\t[-0.84289751 -0.14051445]\n",
      "Progress: 31.9% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289751 -0.14051445]\n",
      "gradient\t[-2.70023775e-08  2.23167501e-07]\n",
      "weight after\t[-0.84289754 -0.14051422]\n",
      "Progress: 31.9% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289754 -0.14051422]\n",
      "gradient\t[-5.00842483e-09  9.55053890e-08]\n",
      "weight after\t[-0.84289754 -0.14051413]\n",
      "Progress: 31.9% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289754 -0.14051413]\n",
      "gradient\t[-5.11808580e-08  4.54279063e-07]\n",
      "weight after\t[-0.84289759 -0.14051367]\n",
      "Progress: 32.0% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289759 -0.14051367]\n",
      "gradient\t[-2.71245934e-08  2.25912999e-07]\n",
      "weight after\t[-0.84289762 -0.14051345]\n",
      "Progress: 32.0% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289762 -0.14051345]\n",
      "gradient\t[-5.95044094e-09  1.16914194e-06]\n",
      "weight after\t[-0.84289762 -0.14051228]\n",
      "Progress: 32.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289762 -0.14051228]\n",
      "gradient\t[-1.46878591e-08  1.19522192e-07]\n",
      "weight after\t[-0.84289764 -0.14051216]\n",
      "Progress: 32.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289764 -0.14051216]\n",
      "gradient\t[-1.09022847e-08  1.89461940e-07]\n",
      "weight after\t[-0.84289765 -0.14051197]\n",
      "Progress: 32.2% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289765 -0.14051197]\n",
      "gradient\t[-2.09688921e-08  1.97576083e-07]\n",
      "weight after\t[-0.84289767 -0.14051177]\n",
      "Progress: 32.2% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289767 -0.14051177]\n",
      "gradient\t[-6.52767436e-08  5.13523389e-07]\n",
      "weight after\t[-0.84289774 -0.14051126]\n",
      "Progress: 32.3% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289774 -0.14051126]\n",
      "gradient\t[-5.48514548e-08  4.63402906e-07]\n",
      "weight after\t[-0.84289779 -0.1405108 ]\n",
      "Progress: 32.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289779 -0.1405108 ]\n",
      "gradient\t[-6.33852648e-09  4.85221661e-07]\n",
      "weight after\t[-0.8428978  -0.14051031]\n",
      "Progress: 32.4% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428978  -0.14051031]\n",
      "gradient\t[-3.16133313e-08  5.90565058e-07]\n",
      "weight after\t[-0.84289783 -0.14050972]\n",
      "Progress: 32.5% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289783 -0.14050972]\n",
      "gradient\t[-5.8647299e-09  8.3944935e-08]\n",
      "weight after\t[-0.84289784 -0.14050964]\n",
      "Progress: 32.5% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289784 -0.14050964]\n",
      "gradient\t[-1.30470887e-08  5.37287766e-07]\n",
      "weight after\t[-0.84289785 -0.1405091 ]\n",
      "Progress: 32.5% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289785 -0.1405091 ]\n",
      "gradient\t[-4.34103274e-09  8.18732467e-08]\n",
      "weight after\t[-0.84289785 -0.14050902]\n",
      "Progress: 32.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289785 -0.14050902]\n",
      "gradient\t[-3.15288715e-08  2.20575335e-07]\n",
      "weight after\t[-0.84289788 -0.1405088 ]\n",
      "Progress: 32.6% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289788 -0.1405088 ]\n",
      "gradient\t[-5.51408166e-09  8.32589990e-08]\n",
      "weight after\t[-0.84289789 -0.14050871]\n",
      "Progress: 32.7% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289789 -0.14050871]\n",
      "gradient\t[-6.29462714e-09  6.90774357e-08]\n",
      "weight after\t[-0.8428979  -0.14050864]\n",
      "Progress: 32.8% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428979  -0.14050864]\n",
      "gradient\t[-1.50585198e-08  1.95158026e-07]\n",
      "weight after\t[-0.84289791 -0.14050845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 32.8% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289791 -0.14050845]\n",
      "gradient\t[-2.58534044e-09  8.15449632e-08]\n",
      "weight after\t[-0.84289791 -0.14050837]\n",
      "Progress: 32.9% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289791 -0.14050837]\n",
      "gradient\t[-4.81783536e-09  4.45993051e-08]\n",
      "weight after\t[-0.84289792 -0.14050832]\n",
      "Progress: 32.9% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289792 -0.14050832]\n",
      "gradient\t[-3.19626188e-08  3.83628399e-07]\n",
      "weight after\t[-0.84289795 -0.14050794]\n",
      "Progress: 33.0% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289795 -0.14050794]\n",
      "gradient\t[-3.35908050e-08  1.27250854e-06]\n",
      "weight after\t[-0.84289798 -0.14050667]\n",
      "Progress: 33.0% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289798 -0.14050667]\n",
      "gradient\t[-1.51422005e-08  7.97853949e-08]\n",
      "weight after\t[-0.842898   -0.14050659]\n",
      "Progress: 33.0% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.842898   -0.14050659]\n",
      "gradient\t[-6.68455066e-09  1.94201328e-07]\n",
      "weight after\t[-0.84289801 -0.14050639]\n",
      "Progress: 33.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289801 -0.14050639]\n",
      "gradient\t[-1.70520019e-08  2.14459254e-07]\n",
      "weight after\t[-0.84289802 -0.14050618]\n",
      "Progress: 33.1% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289802 -0.14050618]\n",
      "gradient\t[-3.06562698e-08  2.82849523e-07]\n",
      "weight after\t[-0.84289805 -0.1405059 ]\n",
      "Progress: 33.2% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289805 -0.1405059 ]\n",
      "gradient\t[-2.51904825e-08  2.64292610e-07]\n",
      "weight after\t[-0.84289808 -0.14050563]\n",
      "Progress: 33.2% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289808 -0.14050563]\n",
      "gradient\t[-7.61106414e-08  6.35873763e-07]\n",
      "weight after\t[-0.84289816 -0.140505  ]\n",
      "Progress: 33.3% ... Training loss: 0.486 ... Validation loss: 0.483 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289816 -0.140505  ]\n",
      "gradient\t[-6.31338883e-08  4.60639196e-07]\n",
      "weight after\t[-0.84289822 -0.14050453]\n",
      "Progress: 33.4% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289822 -0.14050453]\n",
      "gradient\t[-2.79718989e-09  1.02950175e-06]\n",
      "weight after\t[-0.84289822 -0.14050351]\n",
      "Progress: 33.4% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289822 -0.14050351]\n",
      "gradient\t[-1.19085616e-08  1.06719087e-06]\n",
      "weight after\t[-0.84289823 -0.14050244]\n",
      "Progress: 33.5% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289823 -0.14050244]\n",
      "gradient\t[-5.19278616e-08  1.41089330e-06]\n",
      "weight after\t[-0.84289828 -0.14050103]\n",
      "Progress: 33.5% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289828 -0.14050103]\n",
      "gradient\t[-1.79492998e-08  6.69430520e-07]\n",
      "weight after\t[-0.8428983  -0.14050036]\n",
      "Progress: 33.5% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428983  -0.14050036]\n",
      "gradient\t[-3.20711307e-08  2.27603116e-07]\n",
      "weight after\t[-0.84289833 -0.14050013]\n",
      "Progress: 33.6% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289833 -0.14050013]\n",
      "gradient\t[-2.37870112e-08  2.34713260e-07]\n",
      "weight after\t[-0.84289836 -0.1404999 ]\n",
      "Progress: 33.6% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289836 -0.1404999 ]\n",
      "gradient\t[-6.95056128e-08  9.48408031e-07]\n",
      "weight after\t[-0.84289843 -0.14049895]\n",
      "Progress: 33.7% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289843 -0.14049895]\n",
      "gradient\t[-2.30455513e-08  1.05617756e-06]\n",
      "weight after\t[-0.84289845 -0.14049789]\n",
      "Progress: 33.8% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289845 -0.14049789]\n",
      "gradient\t[-1.48069281e-08  1.02076339e-06]\n",
      "weight after\t[-0.84289847 -0.14049687]\n",
      "Progress: 33.8% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289847 -0.14049687]\n",
      "gradient\t[-1.26593124e-08  1.10401149e-06]\n",
      "weight after\t[-0.84289848 -0.14049577]\n",
      "Progress: 33.9% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289848 -0.14049577]\n",
      "gradient\t[-1.79636571e-08  5.19356290e-07]\n",
      "weight after\t[-0.8428985  -0.14049525]\n",
      "Progress: 33.9% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428985  -0.14049525]\n",
      "gradient\t[-3.39264375e-08  2.55835109e-07]\n",
      "weight after\t[-0.84289853 -0.14049499]\n",
      "Progress: 34.0% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289853 -0.14049499]\n",
      "gradient\t[-1.95504874e-08  1.66859163e-07]\n",
      "weight after\t[-0.84289855 -0.14049482]\n",
      "Progress: 34.0% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289855 -0.14049482]\n",
      "gradient\t[-6.34949901e-09  5.75170802e-08]\n",
      "weight after\t[-0.84289856 -0.14049477]\n",
      "Progress: 34.0% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289856 -0.14049477]\n",
      "gradient\t[-1.57889554e-08  1.52685149e-07]\n",
      "weight after\t[-0.84289857 -0.14049461]\n",
      "Progress: 34.1% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289857 -0.14049461]\n",
      "gradient\t[-3.03331535e-09  6.92308527e-08]\n",
      "weight after\t[-0.84289858 -0.14049454]\n",
      "Progress: 34.1% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289858 -0.14049454]\n",
      "gradient\t[-2.07246340e-09  1.19474289e-08]\n",
      "weight after\t[-0.84289858 -0.14049453]\n",
      "Progress: 34.2% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289858 -0.14049453]\n",
      "gradient\t[-4.38340287e-08  4.71199511e-07]\n",
      "weight after\t[-0.84289862 -0.14049406]\n",
      "Progress: 34.2% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289862 -0.14049406]\n",
      "gradient\t[-6.04658648e-09  7.01224670e-08]\n",
      "weight after\t[-0.84289863 -0.14049399]\n",
      "Progress: 34.3% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289863 -0.14049399]\n",
      "gradient\t[-5.40857781e-09  1.37854557e-07]\n",
      "weight after\t[-0.84289863 -0.14049385]\n",
      "Progress: 34.4% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289863 -0.14049385]\n",
      "gradient\t[-1.18942751e-09  2.00938429e-08]\n",
      "weight after\t[-0.84289863 -0.14049383]\n",
      "Progress: 34.4% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289863 -0.14049383]\n",
      "gradient\t[-3.35823865e-08  6.11796213e-07]\n",
      "weight after\t[-0.84289867 -0.14049322]\n",
      "Progress: 34.5% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289867 -0.14049322]\n",
      "gradient\t[-1.02567752e-09  3.58468540e-09]\n",
      "weight after\t[-0.84289867 -0.14049322]\n",
      "Progress: 34.5% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289867 -0.14049322]\n",
      "gradient\t[-3.92272244e-08  3.42567050e-07]\n",
      "weight after\t[-0.84289871 -0.14049288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 34.5% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289871 -0.14049288]\n",
      "gradient\t[-5.12629290e-09  1.41024441e-07]\n",
      "weight after\t[-0.84289871 -0.14049273]\n",
      "Progress: 34.6% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289871 -0.14049273]\n",
      "gradient\t[-3.64203623e-08  3.17406497e-07]\n",
      "weight after\t[-0.84289875 -0.14049242]\n",
      "Progress: 34.6% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289875 -0.14049242]\n",
      "gradient\t[-1.15841127e-08  4.33067789e-07]\n",
      "weight after\t[-0.84289876 -0.14049198]\n",
      "Progress: 34.7% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289876 -0.14049198]\n",
      "gradient\t[-1.46837259e-08  1.63380309e-07]\n",
      "weight after\t[-0.84289878 -0.14049182]\n",
      "Progress: 34.8% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289878 -0.14049182]\n",
      "gradient\t[-3.08893471e-08  5.26038655e-07]\n",
      "weight after\t[-0.84289881 -0.14049129]\n",
      "Progress: 34.8% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289881 -0.14049129]\n",
      "gradient\t[-5.78865784e-09  9.25513202e-08]\n",
      "weight after\t[-0.84289881 -0.1404912 ]\n",
      "Progress: 34.9% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289881 -0.1404912 ]\n",
      "gradient\t[-2.98499151e-08  5.15062885e-07]\n",
      "weight after\t[-0.84289884 -0.14049069]\n",
      "Progress: 34.9% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289884 -0.14049069]\n",
      "gradient\t[-1.66497171e-08  1.98065500e-07]\n",
      "weight after\t[-0.84289886 -0.14049049]\n",
      "Progress: 35.0% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289886 -0.14049049]\n",
      "gradient\t[-9.28063602e-09  1.44430029e-07]\n",
      "weight after\t[-0.84289887 -0.14049034]\n",
      "Progress: 35.0% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289887 -0.14049034]\n",
      "gradient\t[-3.70037563e-08  2.79473903e-07]\n",
      "weight after\t[-0.8428989  -0.14049006]\n",
      "Progress: 35.0% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428989  -0.14049006]\n",
      "gradient\t[-3.18410118e-08  2.55257754e-07]\n",
      "weight after\t[-0.84289894 -0.14048981]\n",
      "Progress: 35.1% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289894 -0.14048981]\n",
      "gradient\t[-1.72465467e-08  1.09410022e-07]\n",
      "weight after\t[-0.84289895 -0.1404897 ]\n",
      "Progress: 35.1% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289895 -0.1404897 ]\n",
      "gradient\t[-2.07198258e-08  4.91649193e-07]\n",
      "weight after\t[-0.84289897 -0.14048921]\n",
      "Progress: 35.2% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289897 -0.14048921]\n",
      "gradient\t[-3.43008458e-08  2.06263367e-07]\n",
      "weight after\t[-0.84289901 -0.140489  ]\n",
      "Progress: 35.2% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289901 -0.140489  ]\n",
      "gradient\t[-3.71700101e-08  3.73659483e-07]\n",
      "weight after\t[-0.84289905 -0.14048863]\n",
      "Progress: 35.3% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289905 -0.14048863]\n",
      "gradient\t[-1.59804568e-08  4.08684032e-07]\n",
      "weight after\t[-0.84289906 -0.14048822]\n",
      "Progress: 35.4% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289906 -0.14048822]\n",
      "gradient\t[-4.88556614e-08  3.68672221e-07]\n",
      "weight after\t[-0.84289911 -0.14048785]\n",
      "Progress: 35.4% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289911 -0.14048785]\n",
      "gradient\t[-2.84283441e-08  4.63251537e-07]\n",
      "weight after\t[-0.84289914 -0.14048739]\n",
      "Progress: 35.5% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289914 -0.14048739]\n",
      "gradient\t[-1.94769215e-08  4.89293334e-07]\n",
      "weight after\t[-0.84289916 -0.1404869 ]\n",
      "Progress: 35.5% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289916 -0.1404869 ]\n",
      "gradient\t[-4.91479958e-08  4.51825301e-07]\n",
      "weight after\t[-0.84289921 -0.14048645]\n",
      "Progress: 35.5% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289921 -0.14048645]\n",
      "gradient\t[-9.59115519e-09  8.32111936e-08]\n",
      "weight after\t[-0.84289922 -0.14048636]\n",
      "Progress: 35.6% ... Training loss: 0.486 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289922 -0.14048636]\n",
      "gradient\t[-5.37472277e-08  3.05511781e-07]\n",
      "weight after\t[-0.84289927 -0.14048606]\n",
      "Progress: 35.6% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289927 -0.14048606]\n",
      "gradient\t[-1.77473587e-09  1.76140855e-09]\n",
      "weight after\t[-0.84289927 -0.14048606]\n",
      "Progress: 35.7% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289927 -0.14048606]\n",
      "gradient\t[-1.59747587e-09  8.56787910e-09]\n",
      "weight after\t[-0.84289927 -0.14048605]\n",
      "Progress: 35.8% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289927 -0.14048605]\n",
      "gradient\t[-5.88461906e-09  6.13885086e-07]\n",
      "weight after\t[-0.84289928 -0.14048543]\n",
      "Progress: 35.8% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289928 -0.14048543]\n",
      "gradient\t[-2.19693643e-08  1.02030836e-06]\n",
      "weight after\t[-0.8428993  -0.14048441]\n",
      "Progress: 35.9% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428993  -0.14048441]\n",
      "gradient\t[-1.40481887e-08  6.35085828e-08]\n",
      "weight after\t[-0.84289932 -0.14048435]\n",
      "Progress: 35.9% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289932 -0.14048435]\n",
      "gradient\t[-3.11603637e-08  1.05673834e-06]\n",
      "weight after\t[-0.84289935 -0.14048329]\n",
      "Progress: 36.0% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289935 -0.14048329]\n",
      "gradient\t[-4.36420022e-08  6.49822090e-07]\n",
      "weight after\t[-0.84289939 -0.14048264]\n",
      "Progress: 36.0% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289939 -0.14048264]\n",
      "gradient\t[-2.26138139e-08  4.33863899e-07]\n",
      "weight after\t[-0.84289941 -0.14048221]\n",
      "Progress: 36.0% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289941 -0.14048221]\n",
      "gradient\t[-3.09854216e-09  4.33086004e-08]\n",
      "weight after\t[-0.84289942 -0.14048217]\n",
      "Progress: 36.1% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289942 -0.14048217]\n",
      "gradient\t[-2.23472035e-09  2.90557894e-09]\n",
      "weight after\t[-0.84289942 -0.14048216]\n",
      "Progress: 36.1% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289942 -0.14048216]\n",
      "gradient\t[-1.62975697e-08  1.50785177e-07]\n",
      "weight after\t[-0.84289944 -0.14048201]\n",
      "Progress: 36.2% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289944 -0.14048201]\n",
      "gradient\t[-4.03510076e-08  2.59200681e-07]\n",
      "weight after\t[-0.84289948 -0.14048175]\n",
      "Progress: 36.2% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289948 -0.14048175]\n",
      "gradient\t[-2.29799012e-09  2.05655196e-08]\n",
      "weight after\t[-0.84289948 -0.14048173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 36.3% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289948 -0.14048173]\n",
      "gradient\t[-1.58152295e-08  8.89931917e-08]\n",
      "weight after\t[-0.84289949 -0.14048164]\n",
      "Progress: 36.4% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289949 -0.14048164]\n",
      "gradient\t[-9.00199455e-09  1.32373123e-07]\n",
      "weight after\t[-0.8428995  -0.14048151]\n",
      "Progress: 36.4% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428995  -0.14048151]\n",
      "gradient\t[-9.44377427e-09  8.82119063e-07]\n",
      "weight after\t[-0.84289951 -0.14048063]\n",
      "Progress: 36.5% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289951 -0.14048063]\n",
      "gradient\t[-1.10956535e-08  1.18381127e-07]\n",
      "weight after\t[-0.84289952 -0.14048051]\n",
      "Progress: 36.5% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289952 -0.14048051]\n",
      "gradient\t[-5.05113177e-08  3.56122106e-07]\n",
      "weight after\t[-0.84289957 -0.14048015]\n",
      "Progress: 36.5% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289957 -0.14048015]\n",
      "gradient\t[-2.19313642e-09  5.65383439e-08]\n",
      "weight after\t[-0.84289958 -0.1404801 ]\n",
      "Progress: 36.6% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289958 -0.1404801 ]\n",
      "gradient\t[-6.36515229e-08  4.00883430e-07]\n",
      "weight after\t[-0.84289964 -0.1404797 ]\n",
      "Progress: 36.6% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289964 -0.1404797 ]\n",
      "gradient\t[-1.87122301e-08  1.23691752e-07]\n",
      "weight after\t[-0.84289966 -0.14047957]\n",
      "Progress: 36.7% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289966 -0.14047957]\n",
      "gradient\t[-1.61882966e-08  1.55256668e-07]\n",
      "weight after\t[-0.84289968 -0.14047942]\n",
      "Progress: 36.8% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289968 -0.14047942]\n",
      "gradient\t[-7.81843501e-09  1.16521054e-07]\n",
      "weight after\t[-0.84289968 -0.1404793 ]\n",
      "Progress: 36.8% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289968 -0.1404793 ]\n",
      "gradient\t[-1.13344305e-09  1.39593036e-08]\n",
      "weight after\t[-0.84289968 -0.14047929]\n",
      "Progress: 36.9% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289968 -0.14047929]\n",
      "gradient\t[-1.62573259e-08  1.12315056e-07]\n",
      "weight after\t[-0.8428997  -0.14047918]\n",
      "Progress: 36.9% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428997  -0.14047918]\n",
      "gradient\t[-2.81086832e-08  2.18418662e-07]\n",
      "weight after\t[-0.84289973 -0.14047896]\n",
      "Progress: 37.0% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289973 -0.14047896]\n",
      "gradient\t[-3.54629161e-08  2.10642528e-07]\n",
      "weight after\t[-0.84289976 -0.14047875]\n",
      "Progress: 37.0% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289976 -0.14047875]\n",
      "gradient\t[-1.70832018e-09  1.54068187e-06]\n",
      "weight after\t[-0.84289977 -0.14047721]\n",
      "Progress: 37.0% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289977 -0.14047721]\n",
      "gradient\t[-8.34496425e-09  1.64461625e-07]\n",
      "weight after\t[-0.84289977 -0.14047704]\n",
      "Progress: 37.1% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289977 -0.14047704]\n",
      "gradient\t[-7.74215939e-09  1.64973654e-07]\n",
      "weight after\t[-0.84289978 -0.14047688]\n",
      "Progress: 37.1% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289978 -0.14047688]\n",
      "gradient\t[-3.59788610e-08  2.57309985e-07]\n",
      "weight after\t[-0.84289982 -0.14047662]\n",
      "Progress: 37.2% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289982 -0.14047662]\n",
      "gradient\t[-2.12436386e-08  2.21169177e-07]\n",
      "weight after\t[-0.84289984 -0.1404764 ]\n",
      "Progress: 37.2% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289984 -0.1404764 ]\n",
      "gradient\t[-1.69839151e-08  1.03750454e-07]\n",
      "weight after\t[-0.84289986 -0.14047629]\n",
      "Progress: 37.3% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289986 -0.14047629]\n",
      "gradient\t[-2.88430807e-08  1.40653231e-07]\n",
      "weight after\t[-0.84289988 -0.14047615]\n",
      "Progress: 37.4% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289988 -0.14047615]\n",
      "gradient\t[-1.14597661e-08  9.16677848e-08]\n",
      "weight after\t[-0.8428999  -0.14047606]\n",
      "Progress: 37.4% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8428999  -0.14047606]\n",
      "gradient\t[-2.52327753e-08  1.21576629e-06]\n",
      "weight after\t[-0.84289992 -0.14047485]\n",
      "Progress: 37.5% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289992 -0.14047485]\n",
      "gradient\t[-4.40722807e-08  2.42068707e-07]\n",
      "weight after\t[-0.84289997 -0.1404746 ]\n",
      "Progress: 37.5% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289997 -0.1404746 ]\n",
      "gradient\t[-9.80244895e-10  2.75850835e-09]\n",
      "weight after\t[-0.84289997 -0.1404746 ]\n",
      "Progress: 37.5% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289997 -0.1404746 ]\n",
      "gradient\t[-4.10675649e-09  5.37595356e-08]\n",
      "weight after\t[-0.84289997 -0.14047455]\n",
      "Progress: 37.6% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289997 -0.14047455]\n",
      "gradient\t[-2.20867624e-09  2.65318505e-07]\n",
      "weight after\t[-0.84289997 -0.14047428]\n",
      "Progress: 37.6% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289997 -0.14047428]\n",
      "gradient\t[-1.97183978e-09  1.99418166e-09]\n",
      "weight after\t[-0.84289997 -0.14047428]\n",
      "Progress: 37.7% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84289997 -0.14047428]\n",
      "gradient\t[-4.50782514e-08  2.89502165e-07]\n",
      "weight after\t[-0.84290002 -0.14047399]\n",
      "Progress: 37.8% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290002 -0.14047399]\n",
      "gradient\t[-1.34950378e-09  4.83692957e-08]\n",
      "weight after\t[-0.84290002 -0.14047394]\n",
      "Progress: 37.8% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290002 -0.14047394]\n",
      "gradient\t[-5.79100768e-09  7.89078642e-07]\n",
      "weight after\t[-0.84290003 -0.14047315]\n",
      "Progress: 37.9% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290003 -0.14047315]\n",
      "gradient\t[-4.17084865e-08  4.97374071e-07]\n",
      "weight after\t[-0.84290007 -0.14047266]\n",
      "Progress: 37.9% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290007 -0.14047266]\n",
      "gradient\t[-2.84489019e-08  3.85932475e-07]\n",
      "weight after\t[-0.8429001  -0.14047227]\n",
      "Progress: 38.0% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429001  -0.14047227]\n",
      "gradient\t[-1.66864823e-08  3.33671350e-07]\n",
      "weight after\t[-0.84290011 -0.14047194]\n",
      "Progress: 38.0% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290011 -0.14047194]\n",
      "gradient\t[-2.55463039e-08  1.70831748e-07]\n",
      "weight after\t[-0.84290014 -0.14047177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 38.0% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290014 -0.14047177]\n",
      "gradient\t[-2.95239757e-08  1.83191828e-07]\n",
      "weight after\t[-0.84290017 -0.14047158]\n",
      "Progress: 38.1% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290017 -0.14047158]\n",
      "gradient\t[-2.73578378e-09  9.53583668e-07]\n",
      "weight after\t[-0.84290017 -0.14047063]\n",
      "Progress: 38.1% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290017 -0.14047063]\n",
      "gradient\t[-1.97716183e-09  4.69540717e-08]\n",
      "weight after\t[-0.84290017 -0.14047058]\n",
      "Progress: 38.2% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290017 -0.14047058]\n",
      "gradient\t[-5.16725928e-09  1.47005371e-06]\n",
      "weight after\t[-0.84290018 -0.14046911]\n",
      "Progress: 38.2% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290018 -0.14046911]\n",
      "gradient\t[-1.86298868e-08  3.49777605e-07]\n",
      "weight after\t[-0.8429002  -0.14046876]\n",
      "Progress: 38.3% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429002  -0.14046876]\n",
      "gradient\t[-3.89441964e-08  2.28737589e-07]\n",
      "weight after\t[-0.84290024 -0.14046853]\n",
      "Progress: 38.4% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290024 -0.14046853]\n",
      "gradient\t[-1.32652009e-08  7.76399420e-07]\n",
      "weight after\t[-0.84290025 -0.14046776]\n",
      "Progress: 38.4% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290025 -0.14046776]\n",
      "gradient\t[-8.40191975e-09  7.84100683e-08]\n",
      "weight after\t[-0.84290026 -0.14046768]\n",
      "Progress: 38.5% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290026 -0.14046768]\n",
      "gradient\t[-7.99748339e-09  3.65117550e-08]\n",
      "weight after\t[-0.84290027 -0.14046764]\n",
      "Progress: 38.5% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290027 -0.14046764]\n",
      "gradient\t[-2.69118804e-08  1.50909644e-07]\n",
      "weight after\t[-0.84290029 -0.14046749]\n",
      "Progress: 38.5% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290029 -0.14046749]\n",
      "gradient\t[-5.47866290e-09  5.05801124e-08]\n",
      "weight after\t[-0.8429003  -0.14046744]\n",
      "Progress: 38.6% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429003  -0.14046744]\n",
      "gradient\t[-6.27905971e-08  4.60102162e-07]\n",
      "weight after\t[-0.84290036 -0.14046698]\n",
      "Progress: 38.6% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290036 -0.14046698]\n",
      "gradient\t[-5.53088729e-09  1.00129602e-06]\n",
      "weight after\t[-0.84290037 -0.14046598]\n",
      "Progress: 38.7% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290037 -0.14046598]\n",
      "gradient\t[-1.62613234e-08  1.60786803e-07]\n",
      "weight after\t[-0.84290038 -0.14046582]\n",
      "Progress: 38.8% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290038 -0.14046582]\n",
      "gradient\t[-1.27426875e-08  1.29484329e-07]\n",
      "weight after\t[-0.8429004  -0.14046569]\n",
      "Progress: 38.8% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429004  -0.14046569]\n",
      "gradient\t[-1.69463713e-08  3.86083287e-07]\n",
      "weight after\t[-0.84290041 -0.1404653 ]\n",
      "Progress: 38.9% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290041 -0.1404653 ]\n",
      "gradient\t[-3.36458962e-09  3.24621723e-08]\n",
      "weight after\t[-0.84290042 -0.14046527]\n",
      "Progress: 38.9% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290042 -0.14046527]\n",
      "gradient\t[-1.77974661e-09  3.18987192e-08]\n",
      "weight after\t[-0.84290042 -0.14046524]\n",
      "Progress: 39.0% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290042 -0.14046524]\n",
      "gradient\t[-3.44079153e-08  2.16759699e-07]\n",
      "weight after\t[-0.84290045 -0.14046502]\n",
      "Progress: 39.0% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290045 -0.14046502]\n",
      "gradient\t[-1.70498252e-09  1.25298560e-09]\n",
      "weight after\t[-0.84290045 -0.14046502]\n",
      "Progress: 39.0% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290045 -0.14046502]\n",
      "gradient\t[-2.43968333e-09  2.82899699e-09]\n",
      "weight after\t[-0.84290046 -0.14046502]\n",
      "Progress: 39.1% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290046 -0.14046502]\n",
      "gradient\t[-1.56301822e-08  7.66055373e-07]\n",
      "weight after\t[-0.84290047 -0.14046425]\n",
      "Progress: 39.1% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290047 -0.14046425]\n",
      "gradient\t[-4.13251867e-08  2.36019711e-07]\n",
      "weight after\t[-0.84290051 -0.14046402]\n",
      "Progress: 39.2% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290051 -0.14046402]\n",
      "gradient\t[-2.00343662e-08  1.79950080e-07]\n",
      "weight after\t[-0.84290053 -0.14046384]\n",
      "Progress: 39.2% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290053 -0.14046384]\n",
      "gradient\t[-8.47109113e-09  8.53538889e-08]\n",
      "weight after\t[-0.84290054 -0.14046375]\n",
      "Progress: 39.3% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290054 -0.14046375]\n",
      "gradient\t[-6.30130613e-08  1.19588019e-06]\n",
      "weight after\t[-0.8429006  -0.14046255]\n",
      "Progress: 39.4% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429006  -0.14046255]\n",
      "gradient\t[-8.34699856e-09  1.20441592e-07]\n",
      "weight after\t[-0.84290061 -0.14046243]\n",
      "Progress: 39.4% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290061 -0.14046243]\n",
      "gradient\t[-7.17130332e-09  3.26665626e-08]\n",
      "weight after\t[-0.84290062 -0.1404624 ]\n",
      "Progress: 39.5% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290062 -0.1404624 ]\n",
      "gradient\t[-1.77590441e-08  9.25327571e-08]\n",
      "weight after\t[-0.84290064 -0.14046231]\n",
      "Progress: 39.5% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290064 -0.14046231]\n",
      "gradient\t[-1.61856586e-09  2.20638173e-08]\n",
      "weight after\t[-0.84290064 -0.14046229]\n",
      "Progress: 39.5% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290064 -0.14046229]\n",
      "gradient\t[-7.71472177e-08  1.07411065e-06]\n",
      "weight after\t[-0.84290072 -0.14046121]\n",
      "Progress: 39.6% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290072 -0.14046121]\n",
      "gradient\t[-2.83789649e-08  1.69662260e-07]\n",
      "weight after\t[-0.84290075 -0.14046104]\n",
      "Progress: 39.6% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290075 -0.14046104]\n",
      "gradient\t[-1.94850764e-08  3.83829953e-07]\n",
      "weight after\t[-0.84290076 -0.14046066]\n",
      "Progress: 39.7% ... Training loss: 0.487 ... Validation loss: 0.484 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290076 -0.14046066]\n",
      "gradient\t[-8.67103337e-09  4.67114193e-07]\n",
      "weight after\t[-0.84290077 -0.14046019]\n",
      "Progress: 39.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290077 -0.14046019]\n",
      "gradient\t[-5.28363860e-08  2.85596305e-07]\n",
      "weight after\t[-0.84290083 -0.14045991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 39.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290083 -0.14045991]\n",
      "gradient\t[-1.31982713e-08  1.48970753e-07]\n",
      "weight after\t[-0.84290084 -0.14045976]\n",
      "Progress: 39.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290084 -0.14045976]\n",
      "gradient\t[-1.79561738e-08  1.53539747e-07]\n",
      "weight after\t[-0.84290086 -0.1404596 ]\n",
      "Progress: 39.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290086 -0.1404596 ]\n",
      "gradient\t[-8.14309045e-09  3.60992417e-08]\n",
      "weight after\t[-0.84290087 -0.14045957]\n",
      "Progress: 40.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290087 -0.14045957]\n",
      "gradient\t[-2.07605096e-08  3.35052770e-07]\n",
      "weight after\t[-0.84290089 -0.14045923]\n",
      "Progress: 40.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290089 -0.14045923]\n",
      "gradient\t[-2.03054934e-09  1.79924413e-08]\n",
      "weight after\t[-0.84290089 -0.14045921]\n",
      "Progress: 40.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290089 -0.14045921]\n",
      "gradient\t[-1.38721234e-08  1.99530494e-07]\n",
      "weight after\t[-0.8429009  -0.14045901]\n",
      "Progress: 40.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429009  -0.14045901]\n",
      "gradient\t[-2.66053523e-08  3.40996862e-07]\n",
      "weight after\t[-0.84290093 -0.14045867]\n",
      "Progress: 40.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290093 -0.14045867]\n",
      "gradient\t[-2.46329888e-08  1.30864602e-06]\n",
      "weight after\t[-0.84290095 -0.14045737]\n",
      "Progress: 40.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290095 -0.14045737]\n",
      "gradient\t[-3.89303910e-08  8.58378948e-07]\n",
      "weight after\t[-0.84290099 -0.14045651]\n",
      "Progress: 40.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290099 -0.14045651]\n",
      "gradient\t[-1.67769538e-08  6.39497485e-07]\n",
      "weight after\t[-0.84290101 -0.14045587]\n",
      "Progress: 40.3% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290101 -0.14045587]\n",
      "gradient\t[-1.16814301e-08  1.06518829e-07]\n",
      "weight after\t[-0.84290102 -0.14045576]\n",
      "Progress: 40.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290102 -0.14045576]\n",
      "gradient\t[-1.90351030e-08  3.13781195e-07]\n",
      "weight after\t[-0.84290104 -0.14045545]\n",
      "Progress: 40.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290104 -0.14045545]\n",
      "gradient\t[-3.61307861e-08  2.03353664e-07]\n",
      "weight after\t[-0.84290108 -0.14045524]\n",
      "Progress: 40.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290108 -0.14045524]\n",
      "gradient\t[-1.93407814e-08  5.01452894e-07]\n",
      "weight after\t[-0.8429011  -0.14045474]\n",
      "Progress: 40.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429011  -0.14045474]\n",
      "gradient\t[-2.56909579e-08  1.82089308e-07]\n",
      "weight after\t[-0.84290112 -0.14045456]\n",
      "Progress: 40.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290112 -0.14045456]\n",
      "gradient\t[-5.50360966e-08  8.58878108e-07]\n",
      "weight after\t[-0.84290118 -0.1404537 ]\n",
      "Progress: 40.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290118 -0.1404537 ]\n",
      "gradient\t[-1.34705801e-09  6.07160542e-10]\n",
      "weight after\t[-0.84290118 -0.1404537 ]\n",
      "Progress: 40.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290118 -0.1404537 ]\n",
      "gradient\t[-4.35863014e-08  2.31042821e-07]\n",
      "weight after\t[-0.84290122 -0.14045347]\n",
      "Progress: 40.7% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290122 -0.14045347]\n",
      "gradient\t[-3.55884772e-09  7.22539576e-08]\n",
      "weight after\t[-0.84290122 -0.1404534 ]\n",
      "Progress: 40.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290122 -0.1404534 ]\n",
      "gradient\t[-3.12701086e-08  1.56584286e-07]\n",
      "weight after\t[-0.84290126 -0.14045324]\n",
      "Progress: 40.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290126 -0.14045324]\n",
      "gradient\t[-2.30027103e-09  4.87145878e-08]\n",
      "weight after\t[-0.84290126 -0.14045319]\n",
      "Progress: 40.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290126 -0.14045319]\n",
      "gradient\t[-2.63722408e-08  1.97056699e-07]\n",
      "weight after\t[-0.84290128 -0.140453  ]\n",
      "Progress: 40.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290128 -0.140453  ]\n",
      "gradient\t[-1.95227767e-08  1.63019481e-07]\n",
      "weight after\t[-0.8429013  -0.14045283]\n",
      "Progress: 41.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429013  -0.14045283]\n",
      "gradient\t[-1.24624195e-08  6.28086593e-08]\n",
      "weight after\t[-0.84290132 -0.14045277]\n",
      "Progress: 41.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290132 -0.14045277]\n",
      "gradient\t[-1.43022457e-08  4.71474628e-08]\n",
      "weight after\t[-0.84290133 -0.14045272]\n",
      "Progress: 41.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290133 -0.14045272]\n",
      "gradient\t[-1.63031365e-09  5.37042147e-07]\n",
      "weight after\t[-0.84290133 -0.14045219]\n",
      "Progress: 41.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290133 -0.14045219]\n",
      "gradient\t[-2.63950100e-08  7.00910703e-07]\n",
      "weight after\t[-0.84290136 -0.14045148]\n",
      "Progress: 41.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290136 -0.14045148]\n",
      "gradient\t[-2.32060075e-08  1.80831238e-07]\n",
      "weight after\t[-0.84290138 -0.1404513 ]\n",
      "Progress: 41.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290138 -0.1404513 ]\n",
      "gradient\t[-2.33460358e-08  8.38235250e-07]\n",
      "weight after\t[-0.84290141 -0.14045047]\n",
      "Progress: 41.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290141 -0.14045047]\n",
      "gradient\t[-3.45033069e-09  1.18097489e-08]\n",
      "weight after\t[-0.84290141 -0.14045045]\n",
      "Progress: 41.3% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290141 -0.14045045]\n",
      "gradient\t[-5.64303348e-09  5.81764524e-07]\n",
      "weight after\t[-0.84290141 -0.14044987]\n",
      "Progress: 41.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290141 -0.14044987]\n",
      "gradient\t[-3.63597574e-08  1.41962779e-06]\n",
      "weight after\t[-0.84290145 -0.14044845]\n",
      "Progress: 41.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290145 -0.14044845]\n",
      "gradient\t[-1.30242932e-08  7.05252946e-08]\n",
      "weight after\t[-0.84290146 -0.14044838]\n",
      "Progress: 41.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290146 -0.14044838]\n",
      "gradient\t[-1.29210733e-08  1.26785092e-07]\n",
      "weight after\t[-0.84290148 -0.14044825]\n",
      "Progress: 41.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290148 -0.14044825]\n",
      "gradient\t[-1.30791877e-08  1.21105434e-07]\n",
      "weight after\t[-0.84290149 -0.14044813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 41.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290149 -0.14044813]\n",
      "gradient\t[-2.17475915e-09  3.32804945e-08]\n",
      "weight after\t[-0.84290149 -0.1404481 ]\n",
      "Progress: 41.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290149 -0.1404481 ]\n",
      "gradient\t[-3.38009880e-08  2.10633554e-07]\n",
      "weight after\t[-0.84290153 -0.14044789]\n",
      "Progress: 41.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290153 -0.14044789]\n",
      "gradient\t[-2.76848768e-08  2.60354326e-07]\n",
      "weight after\t[-0.84290155 -0.14044763]\n",
      "Progress: 41.7% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290155 -0.14044763]\n",
      "gradient\t[-1.18988839e-08  1.14496909e-07]\n",
      "weight after\t[-0.84290157 -0.14044751]\n",
      "Progress: 41.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290157 -0.14044751]\n",
      "gradient\t[-2.8192291e-09  5.4174111e-07]\n",
      "weight after\t[-0.84290157 -0.14044697]\n",
      "Progress: 41.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290157 -0.14044697]\n",
      "gradient\t[-2.89739661e-08  1.30773457e-07]\n",
      "weight after\t[-0.8429016  -0.14044684]\n",
      "Progress: 41.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429016  -0.14044684]\n",
      "gradient\t[-4.95326047e-09  5.02227982e-08]\n",
      "weight after\t[-0.8429016  -0.14044679]\n",
      "Progress: 41.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429016  -0.14044679]\n",
      "gradient\t[-1.02826708e-09  3.44812854e-10]\n",
      "weight after\t[-0.8429016  -0.14044679]\n",
      "Progress: 42.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429016  -0.14044679]\n",
      "gradient\t[-2.49077240e-08  6.47880698e-07]\n",
      "weight after\t[-0.84290163 -0.14044614]\n",
      "Progress: 42.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290163 -0.14044614]\n",
      "gradient\t[-1.03577782e-08  2.57768817e-07]\n",
      "weight after\t[-0.84290164 -0.14044589]\n",
      "Progress: 42.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290164 -0.14044589]\n",
      "gradient\t[-1.40752538e-08  1.23651068e-07]\n",
      "weight after\t[-0.84290165 -0.14044576]\n",
      "Progress: 42.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290165 -0.14044576]\n",
      "gradient\t[-2.54664375e-08  6.21306053e-07]\n",
      "weight after\t[-0.84290168 -0.14044514]\n",
      "Progress: 42.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290168 -0.14044514]\n",
      "gradient\t[-2.26551837e-08  3.08961764e-07]\n",
      "weight after\t[-0.8429017  -0.14044483]\n",
      "Progress: 42.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429017  -0.14044483]\n",
      "gradient\t[-2.54733392e-08  8.80331461e-08]\n",
      "weight after\t[-0.84290173 -0.14044474]\n",
      "Progress: 42.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290173 -0.14044474]\n",
      "gradient\t[-1.38112469e-09  1.38878938e-08]\n",
      "weight after\t[-0.84290173 -0.14044473]\n",
      "Progress: 42.3% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290173 -0.14044473]\n",
      "gradient\t[-9.89259379e-10  2.10086846e-09]\n",
      "weight after\t[-0.84290173 -0.14044473]\n",
      "Progress: 42.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290173 -0.14044473]\n",
      "gradient\t[-2.17547767e-09  1.81666694e-07]\n",
      "weight after\t[-0.84290173 -0.14044455]\n",
      "Progress: 42.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290173 -0.14044455]\n",
      "gradient\t[-1.32024725e-08  1.19556023e-06]\n",
      "weight after\t[-0.84290174 -0.14044335]\n",
      "Progress: 42.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290174 -0.14044335]\n",
      "gradient\t[-6.87516474e-09  2.13258693e-07]\n",
      "weight after\t[-0.84290175 -0.14044314]\n",
      "Progress: 42.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290175 -0.14044314]\n",
      "gradient\t[-2.39282928e-08  4.47126289e-07]\n",
      "weight after\t[-0.84290177 -0.14044269]\n",
      "Progress: 42.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290177 -0.14044269]\n",
      "gradient\t[-1.63339654e-09  9.97756152e-07]\n",
      "weight after\t[-0.84290178 -0.14044169]\n",
      "Progress: 42.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290178 -0.14044169]\n",
      "gradient\t[-1.43074805e-08  6.90114829e-08]\n",
      "weight after\t[-0.84290179 -0.14044162]\n",
      "Progress: 42.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290179 -0.14044162]\n",
      "gradient\t[-1.80154729e-08  1.25463118e-07]\n",
      "weight after\t[-0.84290181 -0.1404415 ]\n",
      "Progress: 42.7% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290181 -0.1404415 ]\n",
      "gradient\t[-3.88303485e-08  3.41383910e-07]\n",
      "weight after\t[-0.84290185 -0.14044116]\n",
      "Progress: 42.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290185 -0.14044116]\n",
      "gradient\t[-1.05430434e-08  2.37174423e-07]\n",
      "weight after\t[-0.84290186 -0.14044092]\n",
      "Progress: 42.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290186 -0.14044092]\n",
      "gradient\t[-3.72659696e-08  5.20788658e-07]\n",
      "weight after\t[-0.8429019 -0.1404404]\n",
      "Progress: 42.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429019 -0.1404404]\n",
      "gradient\t[-4.51449448e-09  2.60494198e-08]\n",
      "weight after\t[-0.8429019  -0.14044037]\n",
      "Progress: 42.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429019  -0.14044037]\n",
      "gradient\t[-6.02948725e-08  2.46065316e-07]\n",
      "weight after\t[-0.84290196 -0.14044013]\n",
      "Progress: 43.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290196 -0.14044013]\n",
      "gradient\t[-2.44312505e-08  1.10068465e-07]\n",
      "weight after\t[-0.84290198 -0.14044002]\n",
      "Progress: 43.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290198 -0.14044002]\n",
      "gradient\t[-1.12916788e-07  4.92855004e-07]\n",
      "weight after\t[-0.8429021  -0.14043952]\n",
      "Progress: 43.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429021  -0.14043952]\n",
      "gradient\t[-4.91485060e-08  3.68995653e-07]\n",
      "weight after\t[-0.84290215 -0.14043915]\n",
      "Progress: 43.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290215 -0.14043915]\n",
      "gradient\t[-1.61011438e-08  1.13074390e-07]\n",
      "weight after\t[-0.84290216 -0.14043904]\n",
      "Progress: 43.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290216 -0.14043904]\n",
      "gradient\t[-5.00598256e-08  2.20083875e-07]\n",
      "weight after\t[-0.84290221 -0.14043882]\n",
      "Progress: 43.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290221 -0.14043882]\n",
      "gradient\t[-1.40361389e-08  2.47122861e-07]\n",
      "weight after\t[-0.84290223 -0.14043857]\n",
      "Progress: 43.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290223 -0.14043857]\n",
      "gradient\t[-5.23011649e-09  1.89355835e-07]\n",
      "weight after\t[-0.84290223 -0.14043839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 43.3% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290223 -0.14043839]\n",
      "gradient\t[-1.04277672e-08  9.26923731e-08]\n",
      "weight after\t[-0.84290224 -0.14043829]\n",
      "Progress: 43.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290224 -0.14043829]\n",
      "gradient\t[-1.58333931e-08  2.77197757e-07]\n",
      "weight after\t[-0.84290226 -0.14043802]\n",
      "Progress: 43.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290226 -0.14043802]\n",
      "gradient\t[-1.77753591e-08  1.45284469e-07]\n",
      "weight after\t[-0.84290228 -0.14043787]\n",
      "Progress: 43.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290228 -0.14043787]\n",
      "gradient\t[-4.15328801e-08  3.70147119e-07]\n",
      "weight after\t[-0.84290232 -0.1404375 ]\n",
      "Progress: 43.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290232 -0.1404375 ]\n",
      "gradient\t[-1.63820914e-08  7.93172819e-08]\n",
      "weight after\t[-0.84290233 -0.14043742]\n",
      "Progress: 43.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290233 -0.14043742]\n",
      "gradient\t[-1.37234119e-08  6.40843606e-08]\n",
      "weight after\t[-0.84290235 -0.14043736]\n",
      "Progress: 43.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290235 -0.14043736]\n",
      "gradient\t[-5.52886436e-08  6.98609091e-07]\n",
      "weight after\t[-0.8429024  -0.14043666]\n",
      "Progress: 43.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429024  -0.14043666]\n",
      "gradient\t[-3.44068374e-09  3.70979903e-08]\n",
      "weight after\t[-0.84290241 -0.14043662]\n",
      "Progress: 43.7% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290241 -0.14043662]\n",
      "gradient\t[-2.46628920e-08  1.00492821e-07]\n",
      "weight after\t[-0.84290243 -0.14043652]\n",
      "Progress: 43.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290243 -0.14043652]\n",
      "gradient\t[-1.49139740e-08  5.80093506e-08]\n",
      "weight after\t[-0.84290245 -0.14043646]\n",
      "Progress: 43.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290245 -0.14043646]\n",
      "gradient\t[-1.94606766e-09  1.12834868e-08]\n",
      "weight after\t[-0.84290245 -0.14043645]\n",
      "Progress: 43.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290245 -0.14043645]\n",
      "gradient\t[-2.49470583e-08  5.52688243e-07]\n",
      "weight after\t[-0.84290247 -0.1404359 ]\n",
      "Progress: 43.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290247 -0.1404359 ]\n",
      "gradient\t[-1.19700258e-08  1.25769866e-07]\n",
      "weight after\t[-0.84290248 -0.14043577]\n",
      "Progress: 44.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290248 -0.14043577]\n",
      "gradient\t[-6.40482784e-08  7.75761229e-07]\n",
      "weight after\t[-0.84290255 -0.140435  ]\n",
      "Progress: 44.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290255 -0.140435  ]\n",
      "gradient\t[-6.78318514e-09  4.13956120e-08]\n",
      "weight after\t[-0.84290256 -0.14043496]\n",
      "Progress: 44.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290256 -0.14043496]\n",
      "gradient\t[-1.29203507e-08  8.72791367e-08]\n",
      "weight after\t[-0.84290257 -0.14043487]\n",
      "Progress: 44.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290257 -0.14043487]\n",
      "gradient\t[-2.31340446e-08  1.28616127e-07]\n",
      "weight after\t[-0.84290259 -0.14043474]\n",
      "Progress: 44.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290259 -0.14043474]\n",
      "gradient\t[-2.39845958e-08  5.71392856e-07]\n",
      "weight after\t[-0.84290262 -0.14043417]\n",
      "Progress: 44.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290262 -0.14043417]\n",
      "gradient\t[-2.17117807e-08  3.00776214e-07]\n",
      "weight after\t[-0.84290264 -0.14043387]\n",
      "Progress: 44.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290264 -0.14043387]\n",
      "gradient\t[-1.93167668e-08  8.62348081e-08]\n",
      "weight after\t[-0.84290266 -0.14043378]\n",
      "Progress: 44.3% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290266 -0.14043378]\n",
      "gradient\t[-1.63389782e-09  2.76737682e-08]\n",
      "weight after\t[-0.84290266 -0.14043375]\n",
      "Progress: 44.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290266 -0.14043375]\n",
      "gradient\t[-9.40880430e-08  8.90788534e-07]\n",
      "weight after\t[-0.84290275 -0.14043286]\n",
      "Progress: 44.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290275 -0.14043286]\n",
      "gradient\t[-6.45446215e-09  5.06461943e-07]\n",
      "weight after\t[-0.84290276 -0.14043236]\n",
      "Progress: 44.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290276 -0.14043236]\n",
      "gradient\t[-6.43514380e-08  2.85330122e-07]\n",
      "weight after\t[-0.84290282 -0.14043207]\n",
      "Progress: 44.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290282 -0.14043207]\n",
      "gradient\t[-5.16131924e-08  2.72505871e-07]\n",
      "weight after\t[-0.84290287 -0.1404318 ]\n",
      "Progress: 44.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290287 -0.1404318 ]\n",
      "gradient\t[-3.06699077e-09  1.13309889e-08]\n",
      "weight after\t[-0.84290288 -0.14043179]\n",
      "Progress: 44.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290288 -0.14043179]\n",
      "gradient\t[-1.21991606e-08  6.60169696e-08]\n",
      "weight after\t[-0.84290289 -0.14043172]\n",
      "Progress: 44.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290289 -0.14043172]\n",
      "gradient\t[-1.13126807e-09  1.07676301e-09]\n",
      "weight after\t[-0.84290289 -0.14043172]\n",
      "Progress: 44.7% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290289 -0.14043172]\n",
      "gradient\t[-2.55160850e-08  7.01922292e-08]\n",
      "weight after\t[-0.84290292 -0.14043165]\n",
      "Progress: 44.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290292 -0.14043165]\n",
      "gradient\t[-4.69285154e-08  1.90690427e-07]\n",
      "weight after\t[-0.84290296 -0.14043146]\n",
      "Progress: 44.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290296 -0.14043146]\n",
      "gradient\t[-3.2094866e-08  1.2295722e-07]\n",
      "weight after\t[-0.842903   -0.14043134]\n",
      "Progress: 44.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.842903   -0.14043134]\n",
      "gradient\t[-4.67504175e-08  1.89069987e-07]\n",
      "weight after\t[-0.84290304 -0.14043115]\n",
      "Progress: 44.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290304 -0.14043115]\n",
      "gradient\t[-7.04864173e-08  7.52993449e-07]\n",
      "weight after\t[-0.84290311 -0.14043039]\n",
      "Progress: 45.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290311 -0.14043039]\n",
      "gradient\t[-6.08673604e-08  6.52882625e-07]\n",
      "weight after\t[-0.84290317 -0.14042974]\n",
      "Progress: 45.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290317 -0.14042974]\n",
      "gradient\t[-7.57482450e-10  9.82324462e-09]\n",
      "weight after\t[-0.84290317 -0.14042973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 45.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290317 -0.14042973]\n",
      "gradient\t[-1.21605848e-08  2.31087219e-07]\n",
      "weight after\t[-0.84290319 -0.1404295 ]\n",
      "Progress: 45.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290319 -0.1404295 ]\n",
      "gradient\t[-3.34399738e-08  6.77328747e-07]\n",
      "weight after\t[-0.84290322 -0.14042882]\n",
      "Progress: 45.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290322 -0.14042882]\n",
      "gradient\t[-1.60082048e-08  8.90968762e-08]\n",
      "weight after\t[-0.84290324 -0.14042873]\n",
      "Progress: 45.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290324 -0.14042873]\n",
      "gradient\t[-3.50062189e-08  2.06801990e-07]\n",
      "weight after\t[-0.84290327 -0.14042853]\n",
      "Progress: 45.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290327 -0.14042853]\n",
      "gradient\t[-9.87596591e-09  5.44821750e-08]\n",
      "weight after\t[-0.84290328 -0.14042847]\n",
      "Progress: 45.3% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290328 -0.14042847]\n",
      "gradient\t[-2.77618163e-08  5.32871734e-07]\n",
      "weight after\t[-0.84290331 -0.14042794]\n",
      "Progress: 45.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290331 -0.14042794]\n",
      "gradient\t[-3.83096183e-08  1.66783929e-07]\n",
      "weight after\t[-0.84290335 -0.14042777]\n",
      "Progress: 45.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290335 -0.14042777]\n",
      "gradient\t[-3.94721236e-08  2.55278490e-07]\n",
      "weight after\t[-0.84290339 -0.14042752]\n",
      "Progress: 45.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290339 -0.14042752]\n",
      "gradient\t[-3.27350243e-08  2.04081044e-07]\n",
      "weight after\t[-0.84290342 -0.14042731]\n",
      "Progress: 45.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290342 -0.14042731]\n",
      "gradient\t[-2.01096171e-08  1.66038009e-07]\n",
      "weight after\t[-0.84290344 -0.14042715]\n",
      "Progress: 45.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290344 -0.14042715]\n",
      "gradient\t[-2.64332814e-09  1.39923688e-07]\n",
      "weight after\t[-0.84290344 -0.14042701]\n",
      "Progress: 45.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290344 -0.14042701]\n",
      "gradient\t[-1.36417399e-08  4.81478829e-07]\n",
      "weight after\t[-0.84290346 -0.14042653]\n",
      "Progress: 45.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290346 -0.14042653]\n",
      "gradient\t[-6.92044804e-09  2.18081184e-08]\n",
      "weight after\t[-0.84290346 -0.1404265 ]\n",
      "Progress: 45.7% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290346 -0.1404265 ]\n",
      "gradient\t[-6.56145518e-08  3.27918200e-07]\n",
      "weight after\t[-0.84290353 -0.14042618]\n",
      "Progress: 45.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290353 -0.14042618]\n",
      "gradient\t[-7.06110025e-08  6.89346352e-07]\n",
      "weight after\t[-0.8429036  -0.14042549]\n",
      "Progress: 45.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429036  -0.14042549]\n",
      "gradient\t[-1.60525727e-08  1.80320027e-07]\n",
      "weight after\t[-0.84290361 -0.14042531]\n",
      "Progress: 45.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290361 -0.14042531]\n",
      "gradient\t[-3.76115407e-08  2.98245699e-07]\n",
      "weight after\t[-0.84290365 -0.14042501]\n",
      "Progress: 45.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290365 -0.14042501]\n",
      "gradient\t[-2.62079544e-08  2.56088406e-07]\n",
      "weight after\t[-0.84290368 -0.14042475]\n",
      "Progress: 46.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290368 -0.14042475]\n",
      "gradient\t[-1.27113692e-08  5.79666108e-08]\n",
      "weight after\t[-0.84290369 -0.14042469]\n",
      "Progress: 46.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290369 -0.14042469]\n",
      "gradient\t[-3.93847555e-08  1.63201497e-07]\n",
      "weight after\t[-0.84290373 -0.14042453]\n",
      "Progress: 46.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290373 -0.14042453]\n",
      "gradient\t[-5.26425103e-09  1.62447604e-07]\n",
      "weight after\t[-0.84290374 -0.14042437]\n",
      "Progress: 46.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290374 -0.14042437]\n",
      "gradient\t[-1.99247420e-08  1.49719245e-07]\n",
      "weight after\t[-0.84290376 -0.14042422]\n",
      "Progress: 46.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290376 -0.14042422]\n",
      "gradient\t[-2.49174892e-08  1.29610703e-07]\n",
      "weight after\t[-0.84290378 -0.14042409]\n",
      "Progress: 46.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290378 -0.14042409]\n",
      "gradient\t[-2.62177652e-08  5.41034774e-07]\n",
      "weight after\t[-0.84290381 -0.14042355]\n",
      "Progress: 46.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290381 -0.14042355]\n",
      "gradient\t[-2.71870253e-08  1.79930749e-07]\n",
      "weight after\t[-0.84290383 -0.14042337]\n",
      "Progress: 46.3% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290383 -0.14042337]\n",
      "gradient\t[-2.86849867e-08  5.42830649e-07]\n",
      "weight after\t[-0.84290386 -0.14042283]\n",
      "Progress: 46.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290386 -0.14042283]\n",
      "gradient\t[-3.18265345e-08  1.61374019e-07]\n",
      "weight after\t[-0.84290389 -0.14042266]\n",
      "Progress: 46.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290389 -0.14042266]\n",
      "gradient\t[-1.88168874e-08  1.54202701e-07]\n",
      "weight after\t[-0.84290391 -0.14042251]\n",
      "Progress: 46.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290391 -0.14042251]\n",
      "gradient\t[-2.52665143e-08  1.39698201e-07]\n",
      "weight after\t[-0.84290394 -0.14042237]\n",
      "Progress: 46.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290394 -0.14042237]\n",
      "gradient\t[-2.66199580e-08  2.63254885e-07]\n",
      "weight after\t[-0.84290397 -0.14042211]\n",
      "Progress: 46.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290397 -0.14042211]\n",
      "gradient\t[-1.32529921e-09  7.45679339e-09]\n",
      "weight after\t[-0.84290397 -0.1404221 ]\n",
      "Progress: 46.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290397 -0.1404221 ]\n",
      "gradient\t[-1.96078850e-08  2.04159907e-07]\n",
      "weight after\t[-0.84290399 -0.1404219 ]\n",
      "Progress: 46.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290399 -0.1404219 ]\n",
      "gradient\t[-2.47321325e-08  1.29506282e-07]\n",
      "weight after\t[-0.84290401 -0.14042177]\n",
      "Progress: 46.7% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290401 -0.14042177]\n",
      "gradient\t[-5.61077819e-09  6.98005534e-08]\n",
      "weight after\t[-0.84290402 -0.1404217 ]\n",
      "Progress: 46.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290402 -0.1404217 ]\n",
      "gradient\t[-1.57097714e-09  1.03553719e-08]\n",
      "weight after\t[-0.84290402 -0.14042169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 46.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290402 -0.14042169]\n",
      "gradient\t[-1.31348648e-08  5.89481851e-08]\n",
      "weight after\t[-0.84290403 -0.14042163]\n",
      "Progress: 46.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290403 -0.14042163]\n",
      "gradient\t[-3.62261489e-08  1.73724675e-07]\n",
      "weight after\t[-0.84290407 -0.14042145]\n",
      "Progress: 46.9% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290407 -0.14042145]\n",
      "gradient\t[-1.93514191e-08  2.21493476e-07]\n",
      "weight after\t[-0.84290409 -0.14042123]\n",
      "Progress: 47.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290409 -0.14042123]\n",
      "gradient\t[-2.72830172e-08  8.95909562e-07]\n",
      "weight after\t[-0.84290411 -0.14042034]\n",
      "Progress: 47.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290411 -0.14042034]\n",
      "gradient\t[-3.74110372e-08  1.29041108e-07]\n",
      "weight after\t[-0.84290415 -0.14042021]\n",
      "Progress: 47.0% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290415 -0.14042021]\n",
      "gradient\t[-2.35649954e-09  1.95904440e-08]\n",
      "weight after\t[-0.84290415 -0.14042019]\n",
      "Progress: 47.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290415 -0.14042019]\n",
      "gradient\t[-2.78724309e-08  7.03153716e-07]\n",
      "weight after\t[-0.84290418 -0.14041948]\n",
      "Progress: 47.1% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290418 -0.14041948]\n",
      "gradient\t[-5.87388942e-08  2.36344205e-07]\n",
      "weight after\t[-0.84290424 -0.14041925]\n",
      "Progress: 47.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290424 -0.14041925]\n",
      "gradient\t[-6.66470574e-08  6.29599074e-07]\n",
      "weight after\t[-0.84290431 -0.14041862]\n",
      "Progress: 47.2% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290431 -0.14041862]\n",
      "gradient\t[-3.90048553e-09  1.61225202e-07]\n",
      "weight after\t[-0.84290431 -0.14041846]\n",
      "Progress: 47.3% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290431 -0.14041846]\n",
      "gradient\t[-7.42880068e-08  2.74443124e-07]\n",
      "weight after\t[-0.84290439 -0.14041818]\n",
      "Progress: 47.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290439 -0.14041818]\n",
      "gradient\t[-4.03113302e-08  2.37831470e-07]\n",
      "weight after\t[-0.84290443 -0.14041794]\n",
      "Progress: 47.4% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290443 -0.14041794]\n",
      "gradient\t[-1.60150347e-08  4.77920044e-07]\n",
      "weight after\t[-0.84290444 -0.14041747]\n",
      "Progress: 47.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290444 -0.14041747]\n",
      "gradient\t[-1.15210286e-08  9.03621524e-08]\n",
      "weight after\t[-0.84290445 -0.14041738]\n",
      "Progress: 47.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290445 -0.14041738]\n",
      "gradient\t[-1.77991160e-08  9.57062285e-08]\n",
      "weight after\t[-0.84290447 -0.14041728]\n",
      "Progress: 47.5% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290447 -0.14041728]\n",
      "gradient\t[-6.70096518e-09  4.24649118e-07]\n",
      "weight after\t[-0.84290448 -0.14041686]\n",
      "Progress: 47.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290448 -0.14041686]\n",
      "gradient\t[-2.50819717e-08  2.04446253e-07]\n",
      "weight after\t[-0.8429045  -0.14041665]\n",
      "Progress: 47.6% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429045  -0.14041665]\n",
      "gradient\t[-3.33120402e-08  1.75354835e-07]\n",
      "weight after\t[-0.84290454 -0.14041648]\n",
      "Progress: 47.7% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290454 -0.14041648]\n",
      "gradient\t[-1.77709437e-08  5.96059217e-07]\n",
      "weight after\t[-0.84290455 -0.14041588]\n",
      "Progress: 47.8% ... Training loss: 0.487 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290455 -0.14041588]\n",
      "gradient\t[-3.43194635e-08  1.29027827e-07]\n",
      "weight after\t[-0.84290459 -0.14041575]\n",
      "Progress: 47.8% ... Training loss: 0.488 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290459 -0.14041575]\n",
      "gradient\t[-4.28403754e-08  2.50658879e-07]\n",
      "weight after\t[-0.84290463 -0.1404155 ]\n",
      "Progress: 47.9% ... Training loss: 0.488 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290463 -0.1404155 ]\n",
      "gradient\t[-6.20003391e-08  2.80867497e-07]\n",
      "weight after\t[-0.84290469 -0.14041522]\n",
      "Progress: 47.9% ... Training loss: 0.488 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290469 -0.14041522]\n",
      "gradient\t[-1.41980784e-08  4.41004553e-07]\n",
      "weight after\t[-0.84290471 -0.14041478]\n",
      "Progress: 48.0% ... Training loss: 0.488 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290471 -0.14041478]\n",
      "gradient\t[-4.03703877e-08  2.59551957e-07]\n",
      "weight after\t[-0.84290475 -0.14041452]\n",
      "Progress: 48.0% ... Training loss: 0.488 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290475 -0.14041452]\n",
      "gradient\t[-7.30195545e-08  2.75938786e-07]\n",
      "weight after\t[-0.84290482 -0.14041424]\n",
      "Progress: 48.0% ... Training loss: 0.488 ... Validation loss: 0.485 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290482 -0.14041424]\n",
      "gradient\t[-3.56103973e-08  2.65855598e-07]\n",
      "weight after\t[-0.84290486 -0.14041398]\n",
      "Progress: 48.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290486 -0.14041398]\n",
      "gradient\t[-3.61653476e-08  2.03791654e-07]\n",
      "weight after\t[-0.84290489 -0.14041377]\n",
      "Progress: 48.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290489 -0.14041377]\n",
      "gradient\t[-2.60353179e-08  1.12564702e-07]\n",
      "weight after\t[-0.84290492 -0.14041366]\n",
      "Progress: 48.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290492 -0.14041366]\n",
      "gradient\t[-3.73617737e-08  1.60568109e-07]\n",
      "weight after\t[-0.84290496 -0.1404135 ]\n",
      "Progress: 48.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290496 -0.1404135 ]\n",
      "gradient\t[-9.90260771e-10  4.19594437e-09]\n",
      "weight after\t[-0.84290496 -0.1404135 ]\n",
      "Progress: 48.3% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290496 -0.1404135 ]\n",
      "gradient\t[-3.46194507e-08  4.98179917e-07]\n",
      "weight after\t[-0.84290499 -0.140413  ]\n",
      "Progress: 48.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290499 -0.140413  ]\n",
      "gradient\t[-1.24248106e-09  2.07279358e-08]\n",
      "weight after\t[-0.84290499 -0.14041298]\n",
      "Progress: 48.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290499 -0.14041298]\n",
      "gradient\t[-7.64549890e-09  4.04023486e-08]\n",
      "weight after\t[-0.842905   -0.14041294]\n",
      "Progress: 48.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.842905   -0.14041294]\n",
      "gradient\t[-1.86291925e-08  7.44393343e-08]\n",
      "weight after\t[-0.84290502 -0.14041286]\n",
      "Progress: 48.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290502 -0.14041286]\n",
      "gradient\t[-1.62735894e-08  4.29296562e-07]\n",
      "weight after\t[-0.84290504 -0.14041243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 48.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290504 -0.14041243]\n",
      "gradient\t[-3.19664176e-08  1.67679220e-07]\n",
      "weight after\t[-0.84290507 -0.14041227]\n",
      "Progress: 48.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290507 -0.14041227]\n",
      "gradient\t[-4.11112287e-08  2.68304207e-07]\n",
      "weight after\t[-0.84290511 -0.140412  ]\n",
      "Progress: 48.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290511 -0.140412  ]\n",
      "gradient\t[-5.29189526e-09  3.00223869e-08]\n",
      "weight after\t[-0.84290511 -0.14041197]\n",
      "Progress: 48.7% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290511 -0.14041197]\n",
      "gradient\t[-3.78983543e-08  2.79462171e-07]\n",
      "weight after\t[-0.84290515 -0.14041169]\n",
      "Progress: 48.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290515 -0.14041169]\n",
      "gradient\t[-4.27787987e-09  1.27912736e-07]\n",
      "weight after\t[-0.84290516 -0.14041156]\n",
      "Progress: 48.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290516 -0.14041156]\n",
      "gradient\t[-5.60878155e-08  2.51226494e-07]\n",
      "weight after\t[-0.84290521 -0.14041131]\n",
      "Progress: 48.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290521 -0.14041131]\n",
      "gradient\t[-2.16418412e-08  6.42548558e-08]\n",
      "weight after\t[-0.84290523 -0.14041124]\n",
      "Progress: 48.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290523 -0.14041124]\n",
      "gradient\t[-3.07359825e-08  1.35560977e-07]\n",
      "weight after\t[-0.84290526 -0.14041111]\n",
      "Progress: 49.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290526 -0.14041111]\n",
      "gradient\t[-4.92397955e-08  2.10968512e-07]\n",
      "weight after\t[-0.84290531 -0.1404109 ]\n",
      "Progress: 49.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290531 -0.1404109 ]\n",
      "gradient\t[-1.93159110e-09  6.96248512e-07]\n",
      "weight after\t[-0.84290532 -0.1404102 ]\n",
      "Progress: 49.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290532 -0.1404102 ]\n",
      "gradient\t[-4.59414856e-08  1.50668648e-07]\n",
      "weight after\t[-0.84290536 -0.14041005]\n",
      "Progress: 49.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290536 -0.14041005]\n",
      "gradient\t[-2.56732301e-08  7.39486223e-07]\n",
      "weight after\t[-0.84290539 -0.14040931]\n",
      "Progress: 49.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290539 -0.14040931]\n",
      "gradient\t[-4.72769362e-08  1.75636061e-07]\n",
      "weight after\t[-0.84290543 -0.14040914]\n",
      "Progress: 49.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290543 -0.14040914]\n",
      "gradient\t[-6.96350964e-09  3.75778178e-07]\n",
      "weight after\t[-0.84290544 -0.14040876]\n",
      "Progress: 49.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290544 -0.14040876]\n",
      "gradient\t[-6.64904033e-08  2.20368820e-07]\n",
      "weight after\t[-0.84290551 -0.14040854]\n",
      "Progress: 49.3% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290551 -0.14040854]\n",
      "gradient\t[-2.63704187e-08  1.09586128e-07]\n",
      "weight after\t[-0.84290553 -0.14040843]\n",
      "Progress: 49.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290553 -0.14040843]\n",
      "gradient\t[-4.53063404e-09  2.84729153e-08]\n",
      "weight after\t[-0.84290554 -0.1404084 ]\n",
      "Progress: 49.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290554 -0.1404084 ]\n",
      "gradient\t[-5.51280249e-09  1.28363426e-07]\n",
      "weight after\t[-0.84290554 -0.14040827]\n",
      "Progress: 49.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290554 -0.14040827]\n",
      "gradient\t[-6.64532713e-09  1.66864761e-08]\n",
      "weight after\t[-0.84290555 -0.14040826]\n",
      "Progress: 49.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290555 -0.14040826]\n",
      "gradient\t[-2.36868925e-08  7.41334663e-08]\n",
      "weight after\t[-0.84290557 -0.14040818]\n",
      "Progress: 49.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290557 -0.14040818]\n",
      "gradient\t[-1.25078306e-08  5.07077632e-08]\n",
      "weight after\t[-0.84290559 -0.14040813]\n",
      "Progress: 49.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290559 -0.14040813]\n",
      "gradient\t[-1.53387908e-08  6.20925941e-08]\n",
      "weight after\t[-0.8429056  -0.14040807]\n",
      "Progress: 49.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429056  -0.14040807]\n",
      "gradient\t[-3.57352935e-08  1.21821691e-07]\n",
      "weight after\t[-0.84290564 -0.14040795]\n",
      "Progress: 49.7% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290564 -0.14040795]\n",
      "gradient\t[-2.26629945e-08  7.26579560e-08]\n",
      "weight after\t[-0.84290566 -0.14040787]\n",
      "Progress: 49.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290566 -0.14040787]\n",
      "gradient\t[-4.79940754e-10  6.46966598e-09]\n",
      "weight after\t[-0.84290566 -0.14040787]\n",
      "Progress: 49.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290566 -0.14040787]\n",
      "gradient\t[-2.29331406e-08  8.38017006e-08]\n",
      "weight after\t[-0.84290568 -0.14040778]\n",
      "Progress: 49.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290568 -0.14040778]\n",
      "gradient\t[-2.23226027e-08  8.04767053e-08]\n",
      "weight after\t[-0.84290571 -0.1404077 ]\n",
      "Progress: 49.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290571 -0.1404077 ]\n",
      "gradient\t[-2.10639074e-08  9.24174347e-08]\n",
      "weight after\t[-0.84290573 -0.14040761]\n",
      "Progress: 50.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290573 -0.14040761]\n",
      "gradient\t[-2.91294214e-08  2.71711985e-07]\n",
      "weight after\t[-0.84290576 -0.14040734]\n",
      "Progress: 50.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290576 -0.14040734]\n",
      "gradient\t[-4.61114859e-08  2.33929779e-07]\n",
      "weight after\t[-0.8429058  -0.14040711]\n",
      "Progress: 50.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429058  -0.14040711]\n",
      "gradient\t[-1.21193628e-09  1.34908044e-08]\n",
      "weight after\t[-0.8429058  -0.14040709]\n",
      "Progress: 50.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429058  -0.14040709]\n",
      "gradient\t[-3.66801802e-08  1.14116721e-07]\n",
      "weight after\t[-0.84290584 -0.14040698]\n",
      "Progress: 50.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290584 -0.14040698]\n",
      "gradient\t[-2.39730852e-08  1.18569416e-07]\n",
      "weight after\t[-0.84290586 -0.14040686]\n",
      "Progress: 50.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290586 -0.14040686]\n",
      "gradient\t[-3.50133775e-09  1.21916531e-08]\n",
      "weight after\t[-0.84290587 -0.14040685]\n",
      "Progress: 50.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290587 -0.14040685]\n",
      "gradient\t[-1.16325524e-08  1.66641377e-07]\n",
      "weight after\t[-0.84290588 -0.14040668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 50.3% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290588 -0.14040668]\n",
      "gradient\t[-1.81978657e-08  5.06049975e-08]\n",
      "weight after\t[-0.8429059  -0.14040663]\n",
      "Progress: 50.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429059  -0.14040663]\n",
      "gradient\t[-2.85340647e-09  2.01761481e-08]\n",
      "weight after\t[-0.8429059  -0.14040661]\n",
      "Progress: 50.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429059  -0.14040661]\n",
      "gradient\t[-8.60429350e-09  4.48326335e-08]\n",
      "weight after\t[-0.84290591 -0.14040657]\n",
      "Progress: 50.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290591 -0.14040657]\n",
      "gradient\t[-1.10879595e-08  6.40754831e-08]\n",
      "weight after\t[-0.84290592 -0.1404065 ]\n",
      "Progress: 50.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290592 -0.1404065 ]\n",
      "gradient\t[-1.02183853e-08  6.93169553e-08]\n",
      "weight after\t[-0.84290593 -0.14040643]\n",
      "Progress: 50.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290593 -0.14040643]\n",
      "gradient\t[-3.14901480e-08  1.19687453e-07]\n",
      "weight after\t[-0.84290596 -0.14040631]\n",
      "Progress: 50.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290596 -0.14040631]\n",
      "gradient\t[-3.76216474e-09  1.56449651e-08]\n",
      "weight after\t[-0.84290597 -0.1404063 ]\n",
      "Progress: 50.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290597 -0.1404063 ]\n",
      "gradient\t[-1.23783995e-08  5.46290151e-08]\n",
      "weight after\t[-0.84290598 -0.14040624]\n",
      "Progress: 50.7% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290598 -0.14040624]\n",
      "gradient\t[-6.94890046e-09  3.18698221e-08]\n",
      "weight after\t[-0.84290599 -0.14040621]\n",
      "Progress: 50.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290599 -0.14040621]\n",
      "gradient\t[-6.28135861e-09  1.77323195e-08]\n",
      "weight after\t[-0.84290599 -0.14040619]\n",
      "Progress: 50.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290599 -0.14040619]\n",
      "gradient\t[-1.39425589e-08  1.49757925e-07]\n",
      "weight after\t[-0.84290601 -0.14040604]\n",
      "Progress: 50.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290601 -0.14040604]\n",
      "gradient\t[-5.77408725e-09  3.36849074e-08]\n",
      "weight after\t[-0.84290601 -0.14040601]\n",
      "Progress: 50.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290601 -0.14040601]\n",
      "gradient\t[-5.01082788e-08  1.54089271e-07]\n",
      "weight after\t[-0.84290606 -0.14040585]\n",
      "Progress: 51.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290606 -0.14040585]\n",
      "gradient\t[-2.47929643e-08  7.35089752e-08]\n",
      "weight after\t[-0.84290609 -0.14040578]\n",
      "Progress: 51.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290609 -0.14040578]\n",
      "gradient\t[-1.60294235e-08  3.27539199e-07]\n",
      "weight after\t[-0.8429061  -0.14040545]\n",
      "Progress: 51.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429061  -0.14040545]\n",
      "gradient\t[-4.24985439e-09  2.08648709e-08]\n",
      "weight after\t[-0.84290611 -0.14040543]\n",
      "Progress: 51.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290611 -0.14040543]\n",
      "gradient\t[-1.17630437e-09  3.93197441e-10]\n",
      "weight after\t[-0.84290611 -0.14040543]\n",
      "Progress: 51.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290611 -0.14040543]\n",
      "gradient\t[-3.21526560e-08  9.93638821e-08]\n",
      "weight after\t[-0.84290614 -0.14040533]\n",
      "Progress: 51.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290614 -0.14040533]\n",
      "gradient\t[-4.57345324e-08  4.26208872e-07]\n",
      "weight after\t[-0.84290619 -0.14040491]\n",
      "Progress: 51.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290619 -0.14040491]\n",
      "gradient\t[-8.50400095e-09  1.21591203e-07]\n",
      "weight after\t[-0.84290619 -0.14040479]\n",
      "Progress: 51.3% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290619 -0.14040479]\n",
      "gradient\t[-7.81366649e-09  3.32327219e-08]\n",
      "weight after\t[-0.8429062  -0.14040475]\n",
      "Progress: 51.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429062  -0.14040475]\n",
      "gradient\t[-5.36515239e-08  4.63847667e-07]\n",
      "weight after\t[-0.84290626 -0.14040429]\n",
      "Progress: 51.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290626 -0.14040429]\n",
      "gradient\t[-8.90163836e-09  3.23013381e-08]\n",
      "weight after\t[-0.84290626 -0.14040426]\n",
      "Progress: 51.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290626 -0.14040426]\n",
      "gradient\t[-4.61786498e-08  1.47021254e-07]\n",
      "weight after\t[-0.84290631 -0.14040411]\n",
      "Progress: 51.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290631 -0.14040411]\n",
      "gradient\t[-4.13682538e-09  2.86070611e-07]\n",
      "weight after\t[-0.84290632 -0.14040382]\n",
      "Progress: 51.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290632 -0.14040382]\n",
      "gradient\t[-2.91590034e-09  1.02867148e-07]\n",
      "weight after\t[-0.84290632 -0.14040372]\n",
      "Progress: 51.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290632 -0.14040372]\n",
      "gradient\t[-3.61467663e-08  3.80769032e-07]\n",
      "weight after\t[-0.84290635 -0.14040334]\n",
      "Progress: 51.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290635 -0.14040334]\n",
      "gradient\t[-1.42404313e-08  6.88080461e-08]\n",
      "weight after\t[-0.84290637 -0.14040327]\n",
      "Progress: 51.7% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290637 -0.14040327]\n",
      "gradient\t[-3.70149710e-08  1.60859289e-07]\n",
      "weight after\t[-0.84290641 -0.14040311]\n",
      "Progress: 51.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290641 -0.14040311]\n",
      "gradient\t[-2.93243867e-09  1.81419647e-08]\n",
      "weight after\t[-0.84290641 -0.14040309]\n",
      "Progress: 51.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290641 -0.14040309]\n",
      "gradient\t[-2.23019614e-08  2.83502166e-07]\n",
      "weight after\t[-0.84290643 -0.14040281]\n",
      "Progress: 51.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290643 -0.14040281]\n",
      "gradient\t[-2.86811818e-08  3.72643091e-07]\n",
      "weight after\t[-0.84290646 -0.14040244]\n",
      "Progress: 51.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290646 -0.14040244]\n",
      "gradient\t[-1.03289786e-09  4.34756998e-10]\n",
      "weight after\t[-0.84290646 -0.14040243]\n",
      "Progress: 52.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290646 -0.14040243]\n",
      "gradient\t[-1.31749992e-08  3.00293211e-08]\n",
      "weight after\t[-0.84290647 -0.1404024 ]\n",
      "Progress: 52.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290647 -0.1404024 ]\n",
      "gradient\t[-2.19959949e-08  6.10370546e-08]\n",
      "weight after\t[-0.8429065  -0.14040234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 52.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429065  -0.14040234]\n",
      "gradient\t[-3.74476853e-08  3.84563631e-07]\n",
      "weight after\t[-0.84290653 -0.14040196]\n",
      "Progress: 52.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290653 -0.14040196]\n",
      "gradient\t[-5.31028799e-09  2.85903589e-08]\n",
      "weight after\t[-0.84290654 -0.14040193]\n",
      "Progress: 52.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290654 -0.14040193]\n",
      "gradient\t[-3.59390584e-10  1.51227902e-11]\n",
      "weight after\t[-0.84290654 -0.14040193]\n",
      "Progress: 52.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290654 -0.14040193]\n",
      "gradient\t[-9.10326456e-09  3.17947954e-08]\n",
      "weight after\t[-0.84290655 -0.1404019 ]\n",
      "Progress: 52.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290655 -0.1404019 ]\n",
      "gradient\t[-2.48660334e-08  4.02312051e-07]\n",
      "weight after\t[-0.84290657 -0.1404015 ]\n",
      "Progress: 52.3% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290657 -0.1404015 ]\n",
      "gradient\t[-1.10905251e-08  3.42948251e-08]\n",
      "weight after\t[-0.84290658 -0.14040146]\n",
      "Progress: 52.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290658 -0.14040146]\n",
      "gradient\t[-4.39896010e-08  1.21555286e-07]\n",
      "weight after\t[-0.84290663 -0.14040134]\n",
      "Progress: 52.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290663 -0.14040134]\n",
      "gradient\t[-4.02097387e-09  2.69997000e-07]\n",
      "weight after\t[-0.84290663 -0.14040107]\n",
      "Progress: 52.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290663 -0.14040107]\n",
      "gradient\t[-4.54212830e-08  2.24004201e-07]\n",
      "weight after\t[-0.84290668 -0.14040085]\n",
      "Progress: 52.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290668 -0.14040085]\n",
      "gradient\t[-4.71442538e-09  1.45612242e-08]\n",
      "weight after\t[-0.84290668 -0.14040083]\n",
      "Progress: 52.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290668 -0.14040083]\n",
      "gradient\t[-5.95502091e-09  2.76669773e-08]\n",
      "weight after\t[-0.84290669 -0.1404008 ]\n",
      "Progress: 52.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290669 -0.1404008 ]\n",
      "gradient\t[-1.27465875e-08  8.20323625e-07]\n",
      "weight after\t[-0.8429067  -0.14039998]\n",
      "Progress: 52.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429067  -0.14039998]\n",
      "gradient\t[-4.78760838e-08  3.93781456e-07]\n",
      "weight after\t[-0.84290675 -0.14039959]\n",
      "Progress: 52.7% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290675 -0.14039959]\n",
      "gradient\t[-6.94414638e-08  4.48228019e-07]\n",
      "weight after\t[-0.84290682 -0.14039914]\n",
      "Progress: 52.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290682 -0.14039914]\n",
      "gradient\t[-7.06514775e-08  5.52092542e-07]\n",
      "weight after\t[-0.84290689 -0.14039859]\n",
      "Progress: 52.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290689 -0.14039859]\n",
      "gradient\t[-3.36732583e-08  2.17251518e-07]\n",
      "weight after\t[-0.84290692 -0.14039837]\n",
      "Progress: 52.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290692 -0.14039837]\n",
      "gradient\t[-3.03132532e-08  1.30628682e-07]\n",
      "weight after\t[-0.84290695 -0.14039824]\n",
      "Progress: 52.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290695 -0.14039824]\n",
      "gradient\t[-1.10413909e-08  3.51293084e-08]\n",
      "weight after\t[-0.84290696 -0.14039821]\n",
      "Progress: 53.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290696 -0.14039821]\n",
      "gradient\t[-3.17949434e-08  1.86348500e-07]\n",
      "weight after\t[-0.842907   -0.14039802]\n",
      "Progress: 53.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.842907   -0.14039802]\n",
      "gradient\t[-1.41439076e-08  4.97196505e-08]\n",
      "weight after\t[-0.84290701 -0.14039797]\n",
      "Progress: 53.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290701 -0.14039797]\n",
      "gradient\t[-2.55771767e-08  7.89176134e-08]\n",
      "weight after\t[-0.84290703 -0.14039789]\n",
      "Progress: 53.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290703 -0.14039789]\n",
      "gradient\t[-4.28574552e-09  1.36043464e-08]\n",
      "weight after\t[-0.84290704 -0.14039788]\n",
      "Progress: 53.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290704 -0.14039788]\n",
      "gradient\t[-2.05083796e-09  2.64686126e-07]\n",
      "weight after\t[-0.84290704 -0.14039761]\n",
      "Progress: 53.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290704 -0.14039761]\n",
      "gradient\t[-2.62208723e-08  3.33423240e-07]\n",
      "weight after\t[-0.84290707 -0.14039728]\n",
      "Progress: 53.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290707 -0.14039728]\n",
      "gradient\t[-2.50368184e-08  6.64487076e-08]\n",
      "weight after\t[-0.84290709 -0.14039721]\n",
      "Progress: 53.3% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290709 -0.14039721]\n",
      "gradient\t[-2.07542416e-08  1.79653948e-07]\n",
      "weight after\t[-0.84290711 -0.14039703]\n",
      "Progress: 53.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290711 -0.14039703]\n",
      "gradient\t[-4.17382047e-08  1.59412866e-07]\n",
      "weight after\t[-0.84290716 -0.14039687]\n",
      "Progress: 53.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290716 -0.14039687]\n",
      "gradient\t[-2.29921917e-08  1.48731585e-07]\n",
      "weight after\t[-0.84290718 -0.14039673]\n",
      "Progress: 53.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290718 -0.14039673]\n",
      "gradient\t[-3.45573577e-09  1.03261099e-08]\n",
      "weight after\t[-0.84290718 -0.14039672]\n",
      "Progress: 53.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290718 -0.14039672]\n",
      "gradient\t[-4.43810269e-09  1.49120499e-08]\n",
      "weight after\t[-0.84290719 -0.1403967 ]\n",
      "Progress: 53.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290719 -0.1403967 ]\n",
      "gradient\t[-2.87193573e-08  1.72004289e-07]\n",
      "weight after\t[-0.84290721 -0.14039653]\n",
      "Progress: 53.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290721 -0.14039653]\n",
      "gradient\t[-1.19700379e-08  6.65742412e-08]\n",
      "weight after\t[-0.84290723 -0.14039646]\n",
      "Progress: 53.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290723 -0.14039646]\n",
      "gradient\t[-9.54983703e-09  5.09652163e-07]\n",
      "weight after\t[-0.84290724 -0.14039595]\n",
      "Progress: 53.7% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290724 -0.14039595]\n",
      "gradient\t[-4.54583168e-08  4.36216078e-07]\n",
      "weight after\t[-0.84290728 -0.14039552]\n",
      "Progress: 53.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290728 -0.14039552]\n",
      "gradient\t[-1.76194818e-08  1.52118477e-07]\n",
      "weight after\t[-0.8429073  -0.14039536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 53.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429073  -0.14039536]\n",
      "gradient\t[-1.1480562e-08  3.8924928e-08]\n",
      "weight after\t[-0.84290731 -0.14039533]\n",
      "Progress: 53.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290731 -0.14039533]\n",
      "gradient\t[-1.56578102e-08  9.00454666e-08]\n",
      "weight after\t[-0.84290733 -0.14039524]\n",
      "Progress: 53.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290733 -0.14039524]\n",
      "gradient\t[-1.40395739e-08  3.72480423e-08]\n",
      "weight after\t[-0.84290734 -0.1403952 ]\n",
      "Progress: 54.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290734 -0.1403952 ]\n",
      "gradient\t[-6.58255497e-09  2.44310066e-07]\n",
      "weight after\t[-0.84290735 -0.14039495]\n",
      "Progress: 54.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290735 -0.14039495]\n",
      "gradient\t[-6.36341747e-09  1.22477610e-08]\n",
      "weight after\t[-0.84290735 -0.14039494]\n",
      "Progress: 54.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290735 -0.14039494]\n",
      "gradient\t[-1.11753769e-08  2.02548116e-08]\n",
      "weight after\t[-0.84290736 -0.14039492]\n",
      "Progress: 54.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290736 -0.14039492]\n",
      "gradient\t[-8.48728264e-09  3.20899519e-07]\n",
      "weight after\t[-0.84290737 -0.1403946 ]\n",
      "Progress: 54.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290737 -0.1403946 ]\n",
      "gradient\t[-4.59235501e-09  1.78616994e-08]\n",
      "weight after\t[-0.84290738 -0.14039458]\n",
      "Progress: 54.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290738 -0.14039458]\n",
      "gradient\t[-1.32871584e-08  3.99147288e-08]\n",
      "weight after\t[-0.84290739 -0.14039454]\n",
      "Progress: 54.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290739 -0.14039454]\n",
      "gradient\t[-3.42023261e-08  3.43102809e-07]\n",
      "weight after\t[-0.84290743 -0.1403942 ]\n",
      "Progress: 54.3% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290743 -0.1403942 ]\n",
      "gradient\t[-6.91594811e-09  2.40617686e-07]\n",
      "weight after\t[-0.84290743 -0.14039396]\n",
      "Progress: 54.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290743 -0.14039396]\n",
      "gradient\t[-3.91680739e-08  1.21392091e-07]\n",
      "weight after\t[-0.84290747 -0.14039384]\n",
      "Progress: 54.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290747 -0.14039384]\n",
      "gradient\t[-4.79061548e-09  2.47102312e-07]\n",
      "weight after\t[-0.84290748 -0.14039359]\n",
      "Progress: 54.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290748 -0.14039359]\n",
      "gradient\t[-3.06801885e-08  8.66750232e-08]\n",
      "weight after\t[-0.84290751 -0.1403935 ]\n",
      "Progress: 54.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290751 -0.1403935 ]\n",
      "gradient\t[-2.54322942e-08  6.29405108e-08]\n",
      "weight after\t[-0.84290753 -0.14039344]\n",
      "Progress: 54.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290753 -0.14039344]\n",
      "gradient\t[-3.34416568e-08  9.97175883e-08]\n",
      "weight after\t[-0.84290757 -0.14039334]\n",
      "Progress: 54.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290757 -0.14039334]\n",
      "gradient\t[-3.73156815e-08  1.99108590e-07]\n",
      "weight after\t[-0.8429076  -0.14039314]\n",
      "Progress: 54.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429076  -0.14039314]\n",
      "gradient\t[-5.35784668e-09  3.03721900e-08]\n",
      "weight after\t[-0.84290761 -0.14039311]\n",
      "Progress: 54.7% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290761 -0.14039311]\n",
      "gradient\t[-4.11911166e-08  1.12018711e-07]\n",
      "weight after\t[-0.84290765 -0.140393  ]\n",
      "Progress: 54.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290765 -0.140393  ]\n",
      "gradient\t[-1.18045324e-08  3.43877307e-08]\n",
      "weight after\t[-0.84290766 -0.14039297]\n",
      "Progress: 54.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290766 -0.14039297]\n",
      "gradient\t[-5.24595864e-08  1.33715782e-07]\n",
      "weight after\t[-0.84290771 -0.14039283]\n",
      "Progress: 54.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290771 -0.14039283]\n",
      "gradient\t[-7.33332561e-09  9.31814807e-08]\n",
      "weight after\t[-0.84290772 -0.14039274]\n",
      "Progress: 54.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290772 -0.14039274]\n",
      "gradient\t[-2.69819750e-09  4.30036361e-07]\n",
      "weight after\t[-0.84290772 -0.14039231]\n",
      "Progress: 55.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290772 -0.14039231]\n",
      "gradient\t[-1.38490468e-08  2.41764821e-07]\n",
      "weight after\t[-0.84290774 -0.14039207]\n",
      "Progress: 55.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290774 -0.14039207]\n",
      "gradient\t[-6.43100109e-09  1.60453945e-08]\n",
      "weight after\t[-0.84290774 -0.14039205]\n",
      "Progress: 55.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290774 -0.14039205]\n",
      "gradient\t[-3.32486426e-08  2.94728931e-07]\n",
      "weight after\t[-0.84290778 -0.14039176]\n",
      "Progress: 55.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290778 -0.14039176]\n",
      "gradient\t[-1.10827037e-08  1.84393797e-08]\n",
      "weight after\t[-0.84290779 -0.14039174]\n",
      "Progress: 55.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290779 -0.14039174]\n",
      "gradient\t[-1.19523778e-09  2.42552503e-09]\n",
      "weight after\t[-0.84290779 -0.14039173]\n",
      "Progress: 55.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290779 -0.14039173]\n",
      "gradient\t[-4.20911471e-08  1.07974793e-07]\n",
      "weight after\t[-0.84290783 -0.14039163]\n",
      "Progress: 55.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290783 -0.14039163]\n",
      "gradient\t[-2.19168409e-08  5.45773942e-08]\n",
      "weight after\t[-0.84290785 -0.14039157]\n",
      "Progress: 55.3% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290785 -0.14039157]\n",
      "gradient\t[-2.04345829e-08  8.11982639e-08]\n",
      "weight after\t[-0.84290787 -0.14039149]\n",
      "Progress: 55.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290787 -0.14039149]\n",
      "gradient\t[-1.24507382e-09  4.79747502e-10]\n",
      "weight after\t[-0.84290788 -0.14039149]\n",
      "Progress: 55.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290788 -0.14039149]\n",
      "gradient\t[-1.75785639e-08  7.38128646e-08]\n",
      "weight after\t[-0.84290789 -0.14039142]\n",
      "Progress: 55.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290789 -0.14039142]\n",
      "gradient\t[-5.11384799e-09  2.75963994e-08]\n",
      "weight after\t[-0.8429079  -0.14039139]\n",
      "Progress: 55.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429079  -0.14039139]\n",
      "gradient\t[-5.72025810e-09  1.10142014e-08]\n",
      "weight after\t[-0.8429079  -0.14039138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 55.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429079  -0.14039138]\n",
      "gradient\t[-1.26117611e-08  4.07227478e-08]\n",
      "weight after\t[-0.84290792 -0.14039134]\n",
      "Progress: 55.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290792 -0.14039134]\n",
      "gradient\t[-3.14468946e-08  7.69186119e-08]\n",
      "weight after\t[-0.84290795 -0.14039126]\n",
      "Progress: 55.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290795 -0.14039126]\n",
      "gradient\t[-4.23291273e-08  9.90715873e-08]\n",
      "weight after\t[-0.84290799 -0.14039116]\n",
      "Progress: 55.7% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290799 -0.14039116]\n",
      "gradient\t[-2.15514252e-08  6.48495050e-08]\n",
      "weight after\t[-0.84290801 -0.1403911 ]\n",
      "Progress: 55.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290801 -0.1403911 ]\n",
      "gradient\t[-1.26585864e-08  7.56109490e-08]\n",
      "weight after\t[-0.84290802 -0.14039102]\n",
      "Progress: 55.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290802 -0.14039102]\n",
      "gradient\t[-6.30521039e-08  1.58107327e-07]\n",
      "weight after\t[-0.84290809 -0.14039086]\n",
      "Progress: 55.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290809 -0.14039086]\n",
      "gradient\t[-2.40250388e-08  1.31200230e-07]\n",
      "weight after\t[-0.84290811 -0.14039073]\n",
      "Progress: 55.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290811 -0.14039073]\n",
      "gradient\t[-1.33008276e-09  4.18179070e-09]\n",
      "weight after\t[-0.84290811 -0.14039073]\n",
      "Progress: 56.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290811 -0.14039073]\n",
      "gradient\t[-3.22756179e-08  8.03484485e-08]\n",
      "weight after\t[-0.84290814 -0.14039065]\n",
      "Progress: 56.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290814 -0.14039065]\n",
      "gradient\t[-2.39845274e-08  7.47200950e-08]\n",
      "weight after\t[-0.84290817 -0.14039057]\n",
      "Progress: 56.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290817 -0.14039057]\n",
      "gradient\t[-8.12541618e-09  2.03933958e-08]\n",
      "weight after\t[-0.84290818 -0.14039055]\n",
      "Progress: 56.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290818 -0.14039055]\n",
      "gradient\t[-3.41660832e-08  9.24862597e-08]\n",
      "weight after\t[-0.84290821 -0.14039046]\n",
      "Progress: 56.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290821 -0.14039046]\n",
      "gradient\t[-5.18464625e-08  1.96175134e-07]\n",
      "weight after\t[-0.84290826 -0.14039026]\n",
      "Progress: 56.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290826 -0.14039026]\n",
      "gradient\t[-5.57787753e-08  1.99496332e-07]\n",
      "weight after\t[-0.84290832 -0.14039006]\n",
      "Progress: 56.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290832 -0.14039006]\n",
      "gradient\t[-6.56202378e-09  1.16372349e-08]\n",
      "weight after\t[-0.84290833 -0.14039005]\n",
      "Progress: 56.3% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290833 -0.14039005]\n",
      "gradient\t[-5.25038391e-08  2.03838566e-07]\n",
      "weight after\t[-0.84290838 -0.14038985]\n",
      "Progress: 56.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290838 -0.14038985]\n",
      "gradient\t[-4.37083714e-08  3.32323299e-07]\n",
      "weight after\t[-0.84290842 -0.14038952]\n",
      "Progress: 56.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290842 -0.14038952]\n",
      "gradient\t[-2.38936271e-08  8.06603179e-08]\n",
      "weight after\t[-0.84290845 -0.14038944]\n",
      "Progress: 56.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290845 -0.14038944]\n",
      "gradient\t[-1.31599259e-08  4.16107158e-08]\n",
      "weight after\t[-0.84290846 -0.14038939]\n",
      "Progress: 56.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290846 -0.14038939]\n",
      "gradient\t[-2.32948852e-08  2.60543112e-07]\n",
      "weight after\t[-0.84290848 -0.14038913]\n",
      "Progress: 56.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290848 -0.14038913]\n",
      "gradient\t[-6.83247022e-09  2.18328850e-08]\n",
      "weight after\t[-0.84290849 -0.14038911]\n",
      "Progress: 56.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290849 -0.14038911]\n",
      "gradient\t[-2.63127390e-08  1.25955173e-07]\n",
      "weight after\t[-0.84290852 -0.14038899]\n",
      "Progress: 56.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290852 -0.14038899]\n",
      "gradient\t[-2.24505257e-08  6.05956015e-08]\n",
      "weight after\t[-0.84290854 -0.14038892]\n",
      "Progress: 56.7% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290854 -0.14038892]\n",
      "gradient\t[-1.67619099e-08  4.39726960e-08]\n",
      "weight after\t[-0.84290855 -0.14038888]\n",
      "Progress: 56.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290855 -0.14038888]\n",
      "gradient\t[-1.10261528e-08  1.78211097e-08]\n",
      "weight after\t[-0.84290857 -0.14038886]\n",
      "Progress: 56.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290857 -0.14038886]\n",
      "gradient\t[-3.10847156e-08  7.56059551e-08]\n",
      "weight after\t[-0.8429086  -0.14038879]\n",
      "Progress: 56.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429086  -0.14038879]\n",
      "gradient\t[-2.20389213e-08  8.05087362e-08]\n",
      "weight after\t[-0.84290862 -0.14038871]\n",
      "Progress: 56.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290862 -0.14038871]\n",
      "gradient\t[-5.20358763e-09  3.20285049e-08]\n",
      "weight after\t[-0.84290862 -0.14038867]\n",
      "Progress: 57.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290862 -0.14038867]\n",
      "gradient\t[-1.46104231e-09  5.69917109e-09]\n",
      "weight after\t[-0.84290863 -0.14038867]\n",
      "Progress: 57.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290863 -0.14038867]\n",
      "gradient\t[-1.14813448e-08  2.31930991e-07]\n",
      "weight after\t[-0.84290864 -0.14038844]\n",
      "Progress: 57.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290864 -0.14038844]\n",
      "gradient\t[-3.26557691e-08  1.38720543e-07]\n",
      "weight after\t[-0.84290867 -0.1403883 ]\n",
      "Progress: 57.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290867 -0.1403883 ]\n",
      "gradient\t[-3.52901378e-08  1.54527637e-07]\n",
      "weight after\t[-0.8429087  -0.14038814]\n",
      "Progress: 57.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429087  -0.14038814]\n",
      "gradient\t[-6.48456660e-09  2.76120255e-07]\n",
      "weight after\t[-0.84290871 -0.14038787]\n",
      "Progress: 57.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290871 -0.14038787]\n",
      "gradient\t[-3.38317593e-08  1.51757778e-07]\n",
      "weight after\t[-0.84290874 -0.14038772]\n",
      "Progress: 57.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290874 -0.14038772]\n",
      "gradient\t[-2.08158904e-08  6.75577081e-08]\n",
      "weight after\t[-0.84290877 -0.14038765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 57.3% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290877 -0.14038765]\n",
      "gradient\t[-2.65242203e-08  2.85286140e-07]\n",
      "weight after\t[-0.84290879 -0.14038736]\n",
      "Progress: 57.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290879 -0.14038736]\n",
      "gradient\t[-6.98841515e-09  7.96493915e-08]\n",
      "weight after\t[-0.8429088  -0.14038728]\n",
      "Progress: 57.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429088  -0.14038728]\n",
      "gradient\t[-3.97483557e-08  1.62518893e-07]\n",
      "weight after\t[-0.84290884 -0.14038712]\n",
      "Progress: 57.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290884 -0.14038712]\n",
      "gradient\t[-2.07193733e-08  4.48477575e-08]\n",
      "weight after\t[-0.84290886 -0.14038708]\n",
      "Progress: 57.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290886 -0.14038708]\n",
      "gradient\t[-9.68473653e-09  2.44499592e-07]\n",
      "weight after\t[-0.84290887 -0.14038683]\n",
      "Progress: 57.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290887 -0.14038683]\n",
      "gradient\t[-2.93386624e-08  9.48274036e-08]\n",
      "weight after\t[-0.8429089  -0.14038674]\n",
      "Progress: 57.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429089  -0.14038674]\n",
      "gradient\t[-1.27681238e-08  3.17192638e-08]\n",
      "weight after\t[-0.84290891 -0.14038671]\n",
      "Progress: 57.6% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290891 -0.14038671]\n",
      "gradient\t[-7.90957653e-09  2.67575007e-07]\n",
      "weight after\t[-0.84290892 -0.14038644]\n",
      "Progress: 57.7% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290892 -0.14038644]\n",
      "gradient\t[-2.99703162e-09  7.90548123e-09]\n",
      "weight after\t[-0.84290892 -0.14038643]\n",
      "Progress: 57.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290892 -0.14038643]\n",
      "gradient\t[-1.03975331e-10  4.29984252e-12]\n",
      "weight after\t[-0.84290892 -0.14038643]\n",
      "Progress: 57.8% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290892 -0.14038643]\n",
      "gradient\t[-2.35197339e-08  7.33653087e-08]\n",
      "weight after\t[-0.84290895 -0.14038636]\n",
      "Progress: 57.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290895 -0.14038636]\n",
      "gradient\t[-9.31997302e-09  2.23946053e-08]\n",
      "weight after\t[-0.84290896 -0.14038633]\n",
      "Progress: 57.9% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290896 -0.14038633]\n",
      "gradient\t[-1.25838609e-08  2.07858544e-07]\n",
      "weight after\t[-0.84290897 -0.14038613]\n",
      "Progress: 58.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290897 -0.14038613]\n",
      "gradient\t[-2.32946560e-08  1.11422073e-07]\n",
      "weight after\t[-0.84290899 -0.14038601]\n",
      "Progress: 58.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290899 -0.14038601]\n",
      "gradient\t[-2.11351509e-08  4.77293593e-08]\n",
      "weight after\t[-0.84290901 -0.14038597]\n",
      "Progress: 58.0% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290901 -0.14038597]\n",
      "gradient\t[-3.23745932e-08  2.59287857e-07]\n",
      "weight after\t[-0.84290904 -0.14038571]\n",
      "Progress: 58.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290904 -0.14038571]\n",
      "gradient\t[-1.00318134e-08  5.67558775e-08]\n",
      "weight after\t[-0.84290905 -0.14038565]\n",
      "Progress: 58.1% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290905 -0.14038565]\n",
      "gradient\t[-2.67861020e-08  1.32026962e-07]\n",
      "weight after\t[-0.84290908 -0.14038552]\n",
      "Progress: 58.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290908 -0.14038552]\n",
      "gradient\t[-4.29565696e-08  2.96868974e-07]\n",
      "weight after\t[-0.84290912 -0.14038522]\n",
      "Progress: 58.2% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290912 -0.14038522]\n",
      "gradient\t[-6.66462916e-09  1.37375432e-08]\n",
      "weight after\t[-0.84290913 -0.14038521]\n",
      "Progress: 58.3% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290913 -0.14038521]\n",
      "gradient\t[-1.40221397e-08  5.88616025e-08]\n",
      "weight after\t[-0.84290915 -0.14038515]\n",
      "Progress: 58.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290915 -0.14038515]\n",
      "gradient\t[-5.81932606e-09  7.44242057e-08]\n",
      "weight after\t[-0.84290915 -0.14038508]\n",
      "Progress: 58.4% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290915 -0.14038508]\n",
      "gradient\t[-3.26185395e-10  1.67085602e-11]\n",
      "weight after\t[-0.84290915 -0.14038508]\n",
      "Progress: 58.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290915 -0.14038508]\n",
      "gradient\t[-2.67243063e-08  7.89856293e-08]\n",
      "weight after\t[-0.84290918 -0.140385  ]\n",
      "Progress: 58.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290918 -0.140385  ]\n",
      "gradient\t[-2.39219270e-09  1.42384754e-08]\n",
      "weight after\t[-0.84290918 -0.14038498]\n",
      "Progress: 58.5% ... Training loss: 0.488 ... Validation loss: 0.486 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290918 -0.14038498]\n",
      "gradient\t[-9.85030246e-09  4.48302769e-08]\n",
      "weight after\t[-0.84290919 -0.14038494]\n",
      "Progress: 58.6% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290919 -0.14038494]\n",
      "gradient\t[-1.21140255e-08  5.23095656e-08]\n",
      "weight after\t[-0.8429092  -0.14038488]\n",
      "Progress: 58.6% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429092  -0.14038488]\n",
      "gradient\t[-8.91779499e-09  2.37222274e-08]\n",
      "weight after\t[-0.84290921 -0.14038486]\n",
      "Progress: 58.7% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290921 -0.14038486]\n",
      "gradient\t[-1.51687301e-09  9.86829732e-09]\n",
      "weight after\t[-0.84290921 -0.14038485]\n",
      "Progress: 58.8% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290921 -0.14038485]\n",
      "gradient\t[-6.22431500e-09  3.69830806e-08]\n",
      "weight after\t[-0.84290922 -0.14038481]\n",
      "Progress: 58.8% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290922 -0.14038481]\n",
      "gradient\t[-5.45632584e-08  1.73712101e-07]\n",
      "weight after\t[-0.84290927 -0.14038464]\n",
      "Progress: 58.9% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290927 -0.14038464]\n",
      "gradient\t[-1.17680671e-08  5.76946999e-08]\n",
      "weight after\t[-0.84290929 -0.14038458]\n",
      "Progress: 58.9% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290929 -0.14038458]\n",
      "gradient\t[-2.32343570e-08  5.19661793e-08]\n",
      "weight after\t[-0.84290931 -0.14038453]\n",
      "Progress: 59.0% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290931 -0.14038453]\n",
      "gradient\t[-5.75581513e-08  1.25235499e-07]\n",
      "weight after\t[-0.84290937 -0.14038441]\n",
      "Progress: 59.0% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290937 -0.14038441]\n",
      "gradient\t[-2.55302674e-09  1.91020964e-07]\n",
      "weight after\t[-0.84290937 -0.14038421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 59.0% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290937 -0.14038421]\n",
      "gradient\t[-8.80850382e-10  5.42744817e-09]\n",
      "weight after\t[-0.84290937 -0.14038421]\n",
      "Progress: 59.1% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290937 -0.14038421]\n",
      "gradient\t[-1.20477776e-09  5.73014024e-10]\n",
      "weight after\t[-0.84290937 -0.14038421]\n",
      "Progress: 59.1% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290937 -0.14038421]\n",
      "gradient\t[-2.04856791e-09  1.86400999e-07]\n",
      "weight after\t[-0.84290937 -0.14038402]\n",
      "Progress: 59.2% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290937 -0.14038402]\n",
      "gradient\t[-2.34608620e-08  7.17574173e-08]\n",
      "weight after\t[-0.8429094  -0.14038395]\n",
      "Progress: 59.2% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429094  -0.14038395]\n",
      "gradient\t[-2.11760835e-08  5.13606036e-08]\n",
      "weight after\t[-0.84290942 -0.1403839 ]\n",
      "Progress: 59.3% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290942 -0.1403839 ]\n",
      "gradient\t[-6.19820632e-10  1.76480026e-07]\n",
      "weight after\t[-0.84290942 -0.14038372]\n",
      "Progress: 59.4% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290942 -0.14038372]\n",
      "gradient\t[-2.08514514e-08  5.66574371e-08]\n",
      "weight after\t[-0.84290944 -0.14038367]\n",
      "Progress: 59.4% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290944 -0.14038367]\n",
      "gradient\t[-1.60592349e-08  4.39416930e-08]\n",
      "weight after\t[-0.84290946 -0.14038362]\n",
      "Progress: 59.5% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290946 -0.14038362]\n",
      "gradient\t[-3.62973941e-10  1.73145729e-07]\n",
      "weight after\t[-0.84290946 -0.14038345]\n",
      "Progress: 59.5% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290946 -0.14038345]\n",
      "gradient\t[-1.10863448e-08  2.26807278e-07]\n",
      "weight after\t[-0.84290947 -0.14038322]\n",
      "Progress: 59.5% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290947 -0.14038322]\n",
      "gradient\t[-1.51694907e-08  2.11064772e-07]\n",
      "weight after\t[-0.84290948 -0.14038301]\n",
      "Progress: 59.6% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290948 -0.14038301]\n",
      "gradient\t[-2.75317899e-08  1.94284753e-07]\n",
      "weight after\t[-0.84290951 -0.14038282]\n",
      "Progress: 59.6% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290951 -0.14038282]\n",
      "gradient\t[-3.41573135e-08  1.23760058e-07]\n",
      "weight after\t[-0.84290954 -0.14038269]\n",
      "Progress: 59.7% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290954 -0.14038269]\n",
      "gradient\t[-1.42674754e-09  4.21015353e-09]\n",
      "weight after\t[-0.84290954 -0.14038269]\n",
      "Progress: 59.8% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290954 -0.14038269]\n",
      "gradient\t[-5.96415602e-09  1.06900254e-08]\n",
      "weight after\t[-0.84290955 -0.14038268]\n",
      "Progress: 59.8% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290955 -0.14038268]\n",
      "gradient\t[-6.36014841e-09  4.03968609e-07]\n",
      "weight after\t[-0.84290956 -0.14038227]\n",
      "Progress: 59.9% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290956 -0.14038227]\n",
      "gradient\t[-2.47776463e-08  2.52133055e-07]\n",
      "weight after\t[-0.84290958 -0.14038202]\n",
      "Progress: 59.9% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290958 -0.14038202]\n",
      "gradient\t[-2.14560598e-09  5.38004793e-08]\n",
      "weight after\t[-0.84290958 -0.14038197]\n",
      "Progress: 60.0% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290958 -0.14038197]\n",
      "gradient\t[-3.29789834e-08  2.43213355e-07]\n",
      "weight after\t[-0.84290962 -0.14038172]\n",
      "Progress: 60.0% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290962 -0.14038172]\n",
      "gradient\t[-1.35520674e-08  2.30605313e-07]\n",
      "weight after\t[-0.84290963 -0.14038149]\n",
      "Progress: 60.0% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290963 -0.14038149]\n",
      "gradient\t[-1.11263613e-08  5.25526267e-08]\n",
      "weight after\t[-0.84290964 -0.14038144]\n",
      "Progress: 60.1% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290964 -0.14038144]\n",
      "gradient\t[-3.30869772e-08  1.04757288e-07]\n",
      "weight after\t[-0.84290967 -0.14038134]\n",
      "Progress: 60.1% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290967 -0.14038134]\n",
      "gradient\t[-2.03427664e-08  5.06630353e-08]\n",
      "weight after\t[-0.8429097  -0.14038129]\n",
      "Progress: 60.2% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429097  -0.14038129]\n",
      "gradient\t[-1.19156798e-08  5.69330139e-08]\n",
      "weight after\t[-0.84290971 -0.14038123]\n",
      "Progress: 60.2% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290971 -0.14038123]\n",
      "gradient\t[-3.03837882e-09  6.54539582e-08]\n",
      "weight after\t[-0.84290971 -0.14038116]\n",
      "Progress: 60.3% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290971 -0.14038116]\n",
      "gradient\t[-1.46058857e-08  2.03612051e-07]\n",
      "weight after\t[-0.84290972 -0.14038096]\n",
      "Progress: 60.4% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290972 -0.14038096]\n",
      "gradient\t[-5.83252740e-08  1.64314466e-07]\n",
      "weight after\t[-0.84290978 -0.1403808 ]\n",
      "Progress: 60.4% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290978 -0.1403808 ]\n",
      "gradient\t[-4.44862372e-08  2.06745013e-07]\n",
      "weight after\t[-0.84290983 -0.14038059]\n",
      "Progress: 60.5% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290983 -0.14038059]\n",
      "gradient\t[-4.97787398e-09  1.18502532e-08]\n",
      "weight after\t[-0.84290983 -0.14038058]\n",
      "Progress: 60.5% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290983 -0.14038058]\n",
      "gradient\t[-3.40240023e-08  5.75256396e-07]\n",
      "weight after\t[-0.84290987 -0.14038   ]\n",
      "Progress: 60.5% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290987 -0.14038   ]\n",
      "gradient\t[-9.17586715e-09  4.53127541e-08]\n",
      "weight after\t[-0.84290988 -0.14037996]\n",
      "Progress: 60.6% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290988 -0.14037996]\n",
      "gradient\t[-6.22866423e-08  2.22369709e-07]\n",
      "weight after\t[-0.84290994 -0.14037973]\n",
      "Progress: 60.6% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290994 -0.14037973]\n",
      "gradient\t[-3.95265527e-09  1.87851726e-08]\n",
      "weight after\t[-0.84290994 -0.14037972]\n",
      "Progress: 60.7% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84290994 -0.14037972]\n",
      "gradient\t[-6.25646419e-08  2.03098256e-07]\n",
      "weight after\t[-0.84291    -0.14037951]\n",
      "Progress: 60.8% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291    -0.14037951]\n",
      "gradient\t[-4.21616567e-08  1.48275005e-07]\n",
      "weight after\t[-0.84291005 -0.14037936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 60.8% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291005 -0.14037936]\n",
      "gradient\t[-2.82900100e-08  9.76070275e-08]\n",
      "weight after\t[-0.84291007 -0.14037927]\n",
      "Progress: 60.9% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291007 -0.14037927]\n",
      "gradient\t[-6.93819677e-09  1.81061153e-07]\n",
      "weight after\t[-0.84291008 -0.14037909]\n",
      "Progress: 60.9% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291008 -0.14037909]\n",
      "gradient\t[-2.65039400e-08  2.15597569e-07]\n",
      "weight after\t[-0.84291011 -0.14037887]\n",
      "Progress: 61.0% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291011 -0.14037887]\n",
      "gradient\t[-2.07565199e-08  4.65816907e-08]\n",
      "weight after\t[-0.84291013 -0.14037882]\n",
      "Progress: 61.0% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291013 -0.14037882]\n",
      "gradient\t[-3.41348031e-08  8.12397226e-08]\n",
      "weight after\t[-0.84291016 -0.14037874]\n",
      "Progress: 61.0% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291016 -0.14037874]\n",
      "gradient\t[-7.57883649e-09  6.55290840e-08]\n",
      "weight after\t[-0.84291017 -0.14037868]\n",
      "Progress: 61.1% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291017 -0.14037868]\n",
      "gradient\t[-3.06673100e-08  1.41867179e-07]\n",
      "weight after\t[-0.8429102  -0.14037853]\n",
      "Progress: 61.1% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429102  -0.14037853]\n",
      "gradient\t[-2.48653355e-08  2.78332281e-07]\n",
      "weight after\t[-0.84291023 -0.14037826]\n",
      "Progress: 61.2% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291023 -0.14037826]\n",
      "gradient\t[-2.89995291e-08  7.51230505e-08]\n",
      "weight after\t[-0.84291026 -0.14037818]\n",
      "Progress: 61.2% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291026 -0.14037818]\n",
      "gradient\t[-3.47659425e-09  3.37271474e-07]\n",
      "weight after\t[-0.84291026 -0.14037784]\n",
      "Progress: 61.3% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291026 -0.14037784]\n",
      "gradient\t[-1.17641489e-08  5.83005840e-08]\n",
      "weight after\t[-0.84291027 -0.14037779]\n",
      "Progress: 61.4% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291027 -0.14037779]\n",
      "gradient\t[-2.10664591e-08  4.37779422e-08]\n",
      "weight after\t[-0.84291029 -0.14037774]\n",
      "Progress: 61.4% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291029 -0.14037774]\n",
      "gradient\t[-3.39549358e-09  1.45736905e-08]\n",
      "weight after\t[-0.8429103  -0.14037773]\n",
      "Progress: 61.5% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429103  -0.14037773]\n",
      "gradient\t[-6.45159040e-09  1.69408145e-08]\n",
      "weight after\t[-0.8429103  -0.14037771]\n",
      "Progress: 61.5% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429103  -0.14037771]\n",
      "gradient\t[-2.98609284e-08  6.20776959e-08]\n",
      "weight after\t[-0.84291033 -0.14037765]\n",
      "Progress: 61.5% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291033 -0.14037765]\n",
      "gradient\t[-6.28705547e-10  2.30799596e-10]\n",
      "weight after\t[-0.84291033 -0.14037765]\n",
      "Progress: 61.6% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291033 -0.14037765]\n",
      "gradient\t[-2.39662859e-08  1.17206685e-07]\n",
      "weight after\t[-0.84291036 -0.14037753]\n",
      "Progress: 61.6% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291036 -0.14037753]\n",
      "gradient\t[-3.98608912e-09  9.11935804e-09]\n",
      "weight after\t[-0.84291036 -0.14037752]\n",
      "Progress: 61.7% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291036 -0.14037752]\n",
      "gradient\t[-4.35327539e-08  1.23549591e-07]\n",
      "weight after\t[-0.8429104 -0.1403774]\n",
      "Progress: 61.8% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429104 -0.1403774]\n",
      "gradient\t[-1.24081129e-08  1.05010875e-07]\n",
      "weight after\t[-0.84291042 -0.14037729]\n",
      "Progress: 61.8% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291042 -0.14037729]\n",
      "gradient\t[-4.81477692e-10  1.38564218e-09]\n",
      "weight after\t[-0.84291042 -0.14037729]\n",
      "Progress: 61.9% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291042 -0.14037729]\n",
      "gradient\t[-5.96326913e-09  2.70785570e-08]\n",
      "weight after\t[-0.84291042 -0.14037726]\n",
      "Progress: 61.9% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291042 -0.14037726]\n",
      "gradient\t[-3.28433521e-08  2.29248253e-07]\n",
      "weight after\t[-0.84291046 -0.14037704]\n",
      "Progress: 62.0% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291046 -0.14037704]\n",
      "gradient\t[-2.83940080e-08  8.65671214e-08]\n",
      "weight after\t[-0.84291048 -0.14037695]\n",
      "Progress: 62.0% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291048 -0.14037695]\n",
      "gradient\t[-3.58152230e-08  1.35609045e-07]\n",
      "weight after\t[-0.84291052 -0.14037681]\n",
      "Progress: 62.0% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291052 -0.14037681]\n",
      "gradient\t[-9.64712590e-09  1.98440297e-07]\n",
      "weight after\t[-0.84291053 -0.14037661]\n",
      "Progress: 62.1% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291053 -0.14037661]\n",
      "gradient\t[-2.45288324e-08  3.41195137e-07]\n",
      "weight after\t[-0.84291055 -0.14037627]\n",
      "Progress: 62.1% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291055 -0.14037627]\n",
      "gradient\t[-3.07189956e-08  6.86945706e-08]\n",
      "weight after\t[-0.84291058 -0.1403762 ]\n",
      "Progress: 62.2% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291058 -0.1403762 ]\n",
      "gradient\t[-2.78178606e-10  1.14919580e-09]\n",
      "weight after\t[-0.84291058 -0.1403762 ]\n",
      "Progress: 62.2% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291058 -0.1403762 ]\n",
      "gradient\t[-1.60811063e-08  3.86578084e-08]\n",
      "weight after\t[-0.8429106  -0.14037617]\n",
      "Progress: 62.3% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429106  -0.14037617]\n",
      "gradient\t[-3.10126858e-08  9.61459456e-08]\n",
      "weight after\t[-0.84291063 -0.14037607]\n",
      "Progress: 62.4% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291063 -0.14037607]\n",
      "gradient\t[-2.24581545e-08  5.46335085e-08]\n",
      "weight after\t[-0.84291065 -0.14037601]\n",
      "Progress: 62.4% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291065 -0.14037601]\n",
      "gradient\t[-5.23312056e-09  8.17863901e-09]\n",
      "weight after\t[-0.84291066 -0.14037601]\n",
      "Progress: 62.5% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291066 -0.14037601]\n",
      "gradient\t[-5.84160533e-09  2.29948453e-08]\n",
      "weight after\t[-0.84291067 -0.14037598]\n",
      "Progress: 62.5% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291067 -0.14037598]\n",
      "gradient\t[-2.24511520e-08  9.45799653e-08]\n",
      "weight after\t[-0.84291069 -0.14037589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 62.5% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291069 -0.14037589]\n",
      "gradient\t[-8.21823952e-10  7.71141037e-11]\n",
      "weight after\t[-0.84291069 -0.14037589]\n",
      "Progress: 62.6% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291069 -0.14037589]\n",
      "gradient\t[-6.86399961e-09  1.61007103e-07]\n",
      "weight after\t[-0.8429107  -0.14037573]\n",
      "Progress: 62.6% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429107  -0.14037573]\n",
      "gradient\t[-8.05284050e-08  1.72565754e-07]\n",
      "weight after\t[-0.84291078 -0.14037556]\n",
      "Progress: 62.7% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291078 -0.14037556]\n",
      "gradient\t[-1.05375022e-08  5.38583181e-08]\n",
      "weight after\t[-0.84291079 -0.1403755 ]\n",
      "Progress: 62.8% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291079 -0.1403755 ]\n",
      "gradient\t[-2.11685553e-08  7.03976777e-08]\n",
      "weight after\t[-0.84291081 -0.14037543]\n",
      "Progress: 62.8% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291081 -0.14037543]\n",
      "gradient\t[-3.05980914e-08  6.96058024e-08]\n",
      "weight after\t[-0.84291084 -0.14037536]\n",
      "Progress: 62.9% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291084 -0.14037536]\n",
      "gradient\t[-5.3768434e-08  1.9062614e-07]\n",
      "weight after\t[-0.84291089 -0.14037517]\n",
      "Progress: 62.9% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291089 -0.14037517]\n",
      "gradient\t[-5.88985982e-08  1.25133597e-07]\n",
      "weight after\t[-0.84291095 -0.14037505]\n",
      "Progress: 63.0% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291095 -0.14037505]\n",
      "gradient\t[-2.36384020e-08  5.23279601e-08]\n",
      "weight after\t[-0.84291097 -0.14037499]\n",
      "Progress: 63.0% ... Training loss: 0.488 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291097 -0.14037499]\n",
      "gradient\t[-2.43724208e-08  1.99763676e-07]\n",
      "weight after\t[-0.842911   -0.14037479]\n",
      "Progress: 63.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.842911   -0.14037479]\n",
      "gradient\t[-3.53101971e-08  7.41777718e-08]\n",
      "weight after\t[-0.84291103 -0.14037472]\n",
      "Progress: 63.1% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291103 -0.14037472]\n",
      "gradient\t[-2.58397088e-08  5.85312111e-08]\n",
      "weight after\t[-0.84291106 -0.14037466]\n",
      "Progress: 63.1% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291106 -0.14037466]\n",
      "gradient\t[-8.05781152e-09  1.68143122e-07]\n",
      "weight after\t[-0.84291107 -0.14037449]\n",
      "Progress: 63.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291107 -0.14037449]\n",
      "gradient\t[-3.49461348e-10  1.78273131e-10]\n",
      "weight after\t[-0.84291107 -0.14037449]\n",
      "Progress: 63.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291107 -0.14037449]\n",
      "gradient\t[-1.38695885e-08  1.80966272e-07]\n",
      "weight after\t[-0.84291108 -0.14037431]\n",
      "Progress: 63.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291108 -0.14037431]\n",
      "gradient\t[-4.74456846e-08  1.19059859e-07]\n",
      "weight after\t[-0.84291113 -0.14037419]\n",
      "Progress: 63.4% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291113 -0.14037419]\n",
      "gradient\t[-1.24660130e-08  6.24893826e-08]\n",
      "weight after\t[-0.84291114 -0.14037413]\n",
      "Progress: 63.4% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291114 -0.14037413]\n",
      "gradient\t[-6.90001339e-08  1.91343270e-07]\n",
      "weight after\t[-0.84291121 -0.14037394]\n",
      "Progress: 63.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291121 -0.14037394]\n",
      "gradient\t[-8.52027628e-10  1.00807924e-09]\n",
      "weight after\t[-0.84291121 -0.14037394]\n",
      "Progress: 63.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291121 -0.14037394]\n",
      "gradient\t[-1.35517952e-08  1.83082641e-07]\n",
      "weight after\t[-0.84291123 -0.14037375]\n",
      "Progress: 63.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291123 -0.14037375]\n",
      "gradient\t[-2.17228901e-08  4.62012866e-08]\n",
      "weight after\t[-0.84291125 -0.14037371]\n",
      "Progress: 63.6% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291125 -0.14037371]\n",
      "gradient\t[-1.04613487e-08  2.99883263e-08]\n",
      "weight after\t[-0.84291126 -0.14037368]\n",
      "Progress: 63.6% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291126 -0.14037368]\n",
      "gradient\t[-1.03835484e-08  1.68996445e-07]\n",
      "weight after\t[-0.84291127 -0.14037351]\n",
      "Progress: 63.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291127 -0.14037351]\n",
      "gradient\t[-2.15220071e-08  4.27496602e-08]\n",
      "weight after\t[-0.84291129 -0.14037347]\n",
      "Progress: 63.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291129 -0.14037347]\n",
      "gradient\t[-4.04986573e-08  2.42105150e-07]\n",
      "weight after\t[-0.84291133 -0.14037322]\n",
      "Progress: 63.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291133 -0.14037322]\n",
      "gradient\t[-9.93436408e-09  2.45647660e-08]\n",
      "weight after\t[-0.84291134 -0.1403732 ]\n",
      "Progress: 63.9% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291134 -0.1403732 ]\n",
      "gradient\t[-8.83753780e-10  4.18667332e-10]\n",
      "weight after\t[-0.84291134 -0.1403732 ]\n",
      "Progress: 63.9% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291134 -0.1403732 ]\n",
      "gradient\t[-3.99715975e-08  1.19940181e-07]\n",
      "weight after\t[-0.84291138 -0.14037308]\n",
      "Progress: 64.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291138 -0.14037308]\n",
      "gradient\t[-2.75288690e-08  8.92049876e-08]\n",
      "weight after\t[-0.84291141 -0.14037299]\n",
      "Progress: 64.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291141 -0.14037299]\n",
      "gradient\t[-2.03439713e-08  1.97092575e-07]\n",
      "weight after\t[-0.84291143 -0.14037279]\n",
      "Progress: 64.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291143 -0.14037279]\n",
      "gradient\t[-9.25108885e-09  4.66656080e-08]\n",
      "weight after\t[-0.84291144 -0.14037275]\n",
      "Progress: 64.1% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291144 -0.14037275]\n",
      "gradient\t[-1.04931237e-08  2.19419023e-08]\n",
      "weight after\t[-0.84291145 -0.14037272]\n",
      "Progress: 64.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291145 -0.14037272]\n",
      "gradient\t[-6.45429070e-09  6.27577542e-08]\n",
      "weight after\t[-0.84291146 -0.14037266]\n",
      "Progress: 64.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291146 -0.14037266]\n",
      "gradient\t[-3.77651819e-09  2.11482371e-08]\n",
      "weight after\t[-0.84291146 -0.14037264]\n",
      "Progress: 64.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291146 -0.14037264]\n",
      "gradient\t[-1.41283199e-09  1.46288422e-09]\n",
      "weight after\t[-0.84291146 -0.14037264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 64.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291146 -0.14037264]\n",
      "gradient\t[-4.76349048e-08  1.18878630e-07]\n",
      "weight after\t[-0.84291151 -0.14037252]\n",
      "Progress: 64.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291151 -0.14037252]\n",
      "gradient\t[-4.12471695e-08  2.31907814e-07]\n",
      "weight after\t[-0.84291155 -0.14037229]\n",
      "Progress: 64.4% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291155 -0.14037229]\n",
      "gradient\t[-2.78122384e-08  2.29302301e-07]\n",
      "weight after\t[-0.84291158 -0.14037206]\n",
      "Progress: 64.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291158 -0.14037206]\n",
      "gradient\t[-1.46590963e-09  1.44244721e-07]\n",
      "weight after\t[-0.84291158 -0.14037191]\n",
      "Progress: 64.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291158 -0.14037191]\n",
      "gradient\t[-5.88304090e-09  1.57991005e-08]\n",
      "weight after\t[-0.84291158 -0.1403719 ]\n",
      "Progress: 64.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291158 -0.1403719 ]\n",
      "gradient\t[-2.98098020e-08  9.87409133e-08]\n",
      "weight after\t[-0.84291161 -0.1403718 ]\n",
      "Progress: 64.6% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291161 -0.1403718 ]\n",
      "gradient\t[-3.43751294e-08  1.51058004e-07]\n",
      "weight after\t[-0.84291165 -0.14037165]\n",
      "Progress: 64.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291165 -0.14037165]\n",
      "gradient\t[-1.07198897e-08  1.75343619e-08]\n",
      "weight after\t[-0.84291166 -0.14037163]\n",
      "Progress: 64.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291166 -0.14037163]\n",
      "gradient\t[-1.30314074e-09  1.41995351e-07]\n",
      "weight after\t[-0.84291166 -0.14037149]\n",
      "Progress: 64.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291166 -0.14037149]\n",
      "gradient\t[-1.24641866e-09  9.28014473e-09]\n",
      "weight after\t[-0.84291166 -0.14037148]\n",
      "Progress: 64.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291166 -0.14037148]\n",
      "gradient\t[-2.86996855e-08  8.30237624e-08]\n",
      "weight after\t[-0.84291169 -0.1403714 ]\n",
      "Progress: 64.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291169 -0.1403714 ]\n",
      "gradient\t[-3.69372633e-08  1.09207693e-07]\n",
      "weight after\t[-0.84291173 -0.14037129]\n",
      "Progress: 64.9% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291173 -0.14037129]\n",
      "gradient\t[-5.52236427e-09  7.81399168e-09]\n",
      "weight after\t[-0.84291173 -0.14037128]\n",
      "Progress: 65.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291173 -0.14037128]\n",
      "gradient\t[-1.37231043e-09  2.25328621e-09]\n",
      "weight after\t[-0.84291173 -0.14037128]\n",
      "Progress: 65.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291173 -0.14037128]\n",
      "gradient\t[-8.37810092e-10  3.06137383e-09]\n",
      "weight after\t[-0.84291174 -0.14037127]\n",
      "Progress: 65.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291174 -0.14037127]\n",
      "gradient\t[-1.98295373e-08  1.84070150e-07]\n",
      "weight after\t[-0.84291175 -0.14037109]\n",
      "Progress: 65.1% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291175 -0.14037109]\n",
      "gradient\t[-6.96017261e-09  1.32600841e-08]\n",
      "weight after\t[-0.84291176 -0.14037108]\n",
      "Progress: 65.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291176 -0.14037108]\n",
      "gradient\t[-3.56695884e-09  1.31782814e-08]\n",
      "weight after\t[-0.84291177 -0.14037106]\n",
      "Progress: 65.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291177 -0.14037106]\n",
      "gradient\t[-1.34414795e-09  2.94946934e-10]\n",
      "weight after\t[-0.84291177 -0.14037106]\n",
      "Progress: 65.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291177 -0.14037106]\n",
      "gradient\t[-3.21299169e-09  8.34987361e-09]\n",
      "weight after\t[-0.84291177 -0.14037106]\n",
      "Progress: 65.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291177 -0.14037106]\n",
      "gradient\t[-1.16184833e-08  3.03390634e-08]\n",
      "weight after\t[-0.84291178 -0.14037103]\n",
      "Progress: 65.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291178 -0.14037103]\n",
      "gradient\t[-4.37446611e-09  1.09836017e-08]\n",
      "weight after\t[-0.84291179 -0.14037101]\n",
      "Progress: 65.4% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291179 -0.14037101]\n",
      "gradient\t[-1.94609197e-08  1.82670705e-07]\n",
      "weight after\t[-0.84291181 -0.14037083]\n",
      "Progress: 65.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291181 -0.14037083]\n",
      "gradient\t[-2.56407543e-09  9.34047292e-09]\n",
      "weight after\t[-0.84291181 -0.14037082]\n",
      "Progress: 65.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291181 -0.14037082]\n",
      "gradient\t[-9.29989735e-09  4.21649751e-08]\n",
      "weight after\t[-0.84291182 -0.14037078]\n",
      "Progress: 65.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291182 -0.14037078]\n",
      "gradient\t[-7.64379440e-09  1.33844925e-08]\n",
      "weight after\t[-0.84291182 -0.14037077]\n",
      "Progress: 65.6% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291182 -0.14037077]\n",
      "gradient\t[-3.63189950e-09  8.90090506e-09]\n",
      "weight after\t[-0.84291183 -0.14037076]\n",
      "Progress: 65.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291183 -0.14037076]\n",
      "gradient\t[-7.11347679e-08  2.32206753e-07]\n",
      "weight after\t[-0.8429119  -0.14037053]\n",
      "Progress: 65.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429119  -0.14037053]\n",
      "gradient\t[-2.29092458e-08  7.21361548e-08]\n",
      "weight after\t[-0.84291192 -0.14037045]\n",
      "Progress: 65.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291192 -0.14037045]\n",
      "gradient\t[-2.98571646e-09  1.71404936e-08]\n",
      "weight after\t[-0.84291193 -0.14037044]\n",
      "Progress: 65.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291193 -0.14037044]\n",
      "gradient\t[-2.20766444e-08  1.80216907e-07]\n",
      "weight after\t[-0.84291195 -0.14037026]\n",
      "Progress: 65.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291195 -0.14037026]\n",
      "gradient\t[-1.46880598e-09  8.37939949e-09]\n",
      "weight after\t[-0.84291195 -0.14037025]\n",
      "Progress: 65.9% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291195 -0.14037025]\n",
      "gradient\t[-1.24806114e-09  1.20361136e-09]\n",
      "weight after\t[-0.84291195 -0.14037025]\n",
      "Progress: 66.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291195 -0.14037025]\n",
      "gradient\t[-1.75687121e-08  4.14296621e-08]\n",
      "weight after\t[-0.84291197 -0.14037021]\n",
      "Progress: 66.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291197 -0.14037021]\n",
      "gradient\t[-4.54777114e-09  1.12706213e-08]\n",
      "weight after\t[-0.84291197 -0.14037019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 66.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291197 -0.14037019]\n",
      "gradient\t[-7.59705703e-09  1.33284180e-08]\n",
      "weight after\t[-0.84291198 -0.14037018]\n",
      "Progress: 66.1% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291198 -0.14037018]\n",
      "gradient\t[-7.34090297e-09  5.90033906e-08]\n",
      "weight after\t[-0.84291199 -0.14037012]\n",
      "Progress: 66.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291199 -0.14037012]\n",
      "gradient\t[-1.12174695e-08  8.68586975e-08]\n",
      "weight after\t[-0.842912   -0.14037003]\n",
      "Progress: 66.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.842912   -0.14037003]\n",
      "gradient\t[-1.08560691e-08  1.88870878e-07]\n",
      "weight after\t[-0.84291201 -0.14036985]\n",
      "Progress: 66.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291201 -0.14036985]\n",
      "gradient\t[-2.91570271e-08  1.15933495e-07]\n",
      "weight after\t[-0.84291204 -0.14036973]\n",
      "Progress: 66.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291204 -0.14036973]\n",
      "gradient\t[-1.01295033e-09  1.15654066e-09]\n",
      "weight after\t[-0.84291204 -0.14036973]\n",
      "Progress: 66.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291204 -0.14036973]\n",
      "gradient\t[-1.31386312e-09  2.86072550e-09]\n",
      "weight after\t[-0.84291204 -0.14036973]\n",
      "Progress: 66.4% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291204 -0.14036973]\n",
      "gradient\t[-2.08057118e-08  3.98306937e-08]\n",
      "weight after\t[-0.84291206 -0.14036969]\n",
      "Progress: 66.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291206 -0.14036969]\n",
      "gradient\t[-3.75906808e-09  2.35632523e-08]\n",
      "weight after\t[-0.84291207 -0.14036966]\n",
      "Progress: 66.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291207 -0.14036966]\n",
      "gradient\t[-1.39304006e-08  2.67130422e-08]\n",
      "weight after\t[-0.84291208 -0.14036964]\n",
      "Progress: 66.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291208 -0.14036964]\n",
      "gradient\t[-1.13355961e-08  9.25804493e-08]\n",
      "weight after\t[-0.84291209 -0.14036954]\n",
      "Progress: 66.6% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291209 -0.14036954]\n",
      "gradient\t[-1.12411651e-08  9.55346582e-08]\n",
      "weight after\t[-0.8429121  -0.14036945]\n",
      "Progress: 66.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429121  -0.14036945]\n",
      "gradient\t[-2.78690036e-08  1.87251546e-07]\n",
      "weight after\t[-0.84291213 -0.14036926]\n",
      "Progress: 66.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291213 -0.14036926]\n",
      "gradient\t[-2.82909828e-08  6.39783942e-08]\n",
      "weight after\t[-0.84291216 -0.1403692 ]\n",
      "Progress: 66.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291216 -0.1403692 ]\n",
      "gradient\t[-1.79591996e-08  5.39611576e-08]\n",
      "weight after\t[-0.84291218 -0.14036914]\n",
      "Progress: 66.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291218 -0.14036914]\n",
      "gradient\t[-8.29880998e-09  4.07807778e-08]\n",
      "weight after\t[-0.84291218 -0.1403691 ]\n",
      "Progress: 66.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291218 -0.1403691 ]\n",
      "gradient\t[-7.97531156e-10  1.69568788e-10]\n",
      "weight after\t[-0.84291219 -0.1403691 ]\n",
      "Progress: 66.9% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291219 -0.1403691 ]\n",
      "gradient\t[-4.83123663e-08  2.20374519e-07]\n",
      "weight after\t[-0.84291223 -0.14036888]\n",
      "Progress: 67.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291223 -0.14036888]\n",
      "gradient\t[-2.20559056e-09  4.16958527e-08]\n",
      "weight after\t[-0.84291224 -0.14036884]\n",
      "Progress: 67.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291224 -0.14036884]\n",
      "gradient\t[-3.01334301e-08  8.42491831e-08]\n",
      "weight after\t[-0.84291227 -0.14036876]\n",
      "Progress: 67.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291227 -0.14036876]\n",
      "gradient\t[-2.15612377e-08  5.03791698e-08]\n",
      "weight after\t[-0.84291229 -0.1403687 ]\n",
      "Progress: 67.1% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291229 -0.1403687 ]\n",
      "gradient\t[-9.58926676e-09  1.75013443e-08]\n",
      "weight after\t[-0.8429123  -0.14036869]\n",
      "Progress: 67.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429123  -0.14036869]\n",
      "gradient\t[-1.86314231e-09  3.56611441e-09]\n",
      "weight after\t[-0.8429123  -0.14036868]\n",
      "Progress: 67.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429123  -0.14036868]\n",
      "gradient\t[-4.24214553e-09  5.05253083e-08]\n",
      "weight after\t[-0.8429123  -0.14036863]\n",
      "Progress: 67.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429123  -0.14036863]\n",
      "gradient\t[-3.37973285e-08  1.99292810e-07]\n",
      "weight after\t[-0.84291234 -0.14036843]\n",
      "Progress: 67.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291234 -0.14036843]\n",
      "gradient\t[-2.17399772e-08  5.67201708e-08]\n",
      "weight after\t[-0.84291236 -0.14036838]\n",
      "Progress: 67.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291236 -0.14036838]\n",
      "gradient\t[-4.81600751e-08  2.35888474e-07]\n",
      "weight after\t[-0.84291241 -0.14036814]\n",
      "Progress: 67.4% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291241 -0.14036814]\n",
      "gradient\t[-1.26232097e-08  3.34507306e-08]\n",
      "weight after\t[-0.84291242 -0.14036811]\n",
      "Progress: 67.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291242 -0.14036811]\n",
      "gradient\t[-1.22295751e-08  1.87514508e-08]\n",
      "weight after\t[-0.84291243 -0.14036809]\n",
      "Progress: 67.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291243 -0.14036809]\n",
      "gradient\t[-1.16078558e-08  2.69548686e-07]\n",
      "weight after\t[-0.84291244 -0.14036782]\n",
      "Progress: 67.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291244 -0.14036782]\n",
      "gradient\t[-1.71936911e-09  4.56690392e-09]\n",
      "weight after\t[-0.84291245 -0.14036782]\n",
      "Progress: 67.6% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291245 -0.14036782]\n",
      "gradient\t[-3.83248573e-08  8.58049222e-08]\n",
      "weight after\t[-0.84291248 -0.14036773]\n",
      "Progress: 67.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291248 -0.14036773]\n",
      "gradient\t[-1.26163001e-08  6.28835917e-08]\n",
      "weight after\t[-0.8429125  -0.14036767]\n",
      "Progress: 67.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429125  -0.14036767]\n",
      "gradient\t[-6.25580178e-08  1.86861886e-07]\n",
      "weight after\t[-0.84291256 -0.14036748]\n",
      "Progress: 67.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291256 -0.14036748]\n",
      "gradient\t[-3.86728462e-08  7.02592493e-08]\n",
      "weight after\t[-0.8429126  -0.14036741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 67.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429126  -0.14036741]\n",
      "gradient\t[-2.25668315e-08  8.98246358e-08]\n",
      "weight after\t[-0.84291262 -0.14036732]\n",
      "Progress: 67.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291262 -0.14036732]\n",
      "gradient\t[-8.51780960e-09  6.19058283e-08]\n",
      "weight after\t[-0.84291263 -0.14036726]\n",
      "Progress: 67.9% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291263 -0.14036726]\n",
      "gradient\t[-3.87491304e-08  8.13567422e-08]\n",
      "weight after\t[-0.84291267 -0.14036718]\n",
      "Progress: 68.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291267 -0.14036718]\n",
      "gradient\t[-2.40064540e-08  4.59617004e-08]\n",
      "weight after\t[-0.84291269 -0.14036713]\n",
      "Progress: 68.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291269 -0.14036713]\n",
      "gradient\t[-3.43479879e-08  1.97616004e-07]\n",
      "weight after\t[-0.84291273 -0.14036693]\n",
      "Progress: 68.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291273 -0.14036693]\n",
      "gradient\t[-3.67697190e-09  1.11377362e-08]\n",
      "weight after\t[-0.84291273 -0.14036692]\n",
      "Progress: 68.1% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291273 -0.14036692]\n",
      "gradient\t[-6.43620881e-09  1.64694154e-08]\n",
      "weight after\t[-0.84291274 -0.14036691]\n",
      "Progress: 68.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291274 -0.14036691]\n",
      "gradient\t[-1.10139884e-08  8.70788514e-08]\n",
      "weight after\t[-0.84291275 -0.14036682]\n",
      "Progress: 68.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291275 -0.14036682]\n",
      "gradient\t[-1.50931896e-09  1.29095549e-07]\n",
      "weight after\t[-0.84291275 -0.14036669]\n",
      "Progress: 68.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291275 -0.14036669]\n",
      "gradient\t[-3.69742698e-09  1.78298835e-08]\n",
      "weight after\t[-0.84291275 -0.14036667]\n",
      "Progress: 68.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291275 -0.14036667]\n",
      "gradient\t[-9.99160019e-09  1.22285535e-08]\n",
      "weight after\t[-0.84291276 -0.14036666]\n",
      "Progress: 68.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291276 -0.14036666]\n",
      "gradient\t[-7.64290299e-09  1.48120993e-08]\n",
      "weight after\t[-0.84291277 -0.14036664]\n",
      "Progress: 68.4% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291277 -0.14036664]\n",
      "gradient\t[-1.24045876e-08  1.91890453e-08]\n",
      "weight after\t[-0.84291278 -0.14036662]\n",
      "Progress: 68.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291278 -0.14036662]\n",
      "gradient\t[-6.94175591e-09  2.96441740e-07]\n",
      "weight after\t[-0.84291279 -0.14036633]\n",
      "Progress: 68.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291279 -0.14036633]\n",
      "gradient\t[-4.11493092e-09  1.00859213e-08]\n",
      "weight after\t[-0.84291279 -0.14036632]\n",
      "Progress: 68.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291279 -0.14036632]\n",
      "gradient\t[-2.63858654e-08  5.29446095e-08]\n",
      "weight after\t[-0.84291282 -0.14036627]\n",
      "Progress: 68.6% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291282 -0.14036627]\n",
      "gradient\t[-3.42467828e-08  2.48389727e-07]\n",
      "weight after\t[-0.84291285 -0.14036602]\n",
      "Progress: 68.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291285 -0.14036602]\n",
      "gradient\t[-2.08930593e-08  1.65939785e-07]\n",
      "weight after\t[-0.84291287 -0.14036585]\n",
      "Progress: 68.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291287 -0.14036585]\n",
      "gradient\t[-2.76869415e-09  1.08955710e-08]\n",
      "weight after\t[-0.84291288 -0.14036584]\n",
      "Progress: 68.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291288 -0.14036584]\n",
      "gradient\t[-1.3633369e-08  2.7390670e-07]\n",
      "weight after\t[-0.84291289 -0.14036557]\n",
      "Progress: 68.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291289 -0.14036557]\n",
      "gradient\t[-3.58073019e-09  1.34379593e-07]\n",
      "weight after\t[-0.84291289 -0.14036543]\n",
      "Progress: 68.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291289 -0.14036543]\n",
      "gradient\t[-3.23635258e-08  5.77397125e-08]\n",
      "weight after\t[-0.84291293 -0.14036537]\n",
      "Progress: 68.9% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291293 -0.14036537]\n",
      "gradient\t[-2.34482052e-08  4.91267068e-08]\n",
      "weight after\t[-0.84291295 -0.14036532]\n",
      "Progress: 69.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291295 -0.14036532]\n",
      "gradient\t[-1.14747868e-08  2.85465518e-08]\n",
      "weight after\t[-0.84291296 -0.1403653 ]\n",
      "Progress: 69.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291296 -0.1403653 ]\n",
      "gradient\t[-5.60400742e-10  1.23509416e-09]\n",
      "weight after\t[-0.84291296 -0.1403653 ]\n",
      "Progress: 69.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291296 -0.1403653 ]\n",
      "gradient\t[-1.81493964e-09  2.86292497e-09]\n",
      "weight after\t[-0.84291296 -0.14036529]\n",
      "Progress: 69.1% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291296 -0.14036529]\n",
      "gradient\t[-1.14104861e-08  2.07827057e-07]\n",
      "weight after\t[-0.84291298 -0.14036508]\n",
      "Progress: 69.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291298 -0.14036508]\n",
      "gradient\t[-1.2163669e-08  2.2313345e-08]\n",
      "weight after\t[-0.84291299 -0.14036506]\n",
      "Progress: 69.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291299 -0.14036506]\n",
      "gradient\t[-7.93273324e-09  1.38263742e-08]\n",
      "weight after\t[-0.842913   -0.14036505]\n",
      "Progress: 69.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.842913   -0.14036505]\n",
      "gradient\t[-4.70181556e-08  2.31185185e-07]\n",
      "weight after\t[-0.84291304 -0.14036482]\n",
      "Progress: 69.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291304 -0.14036482]\n",
      "gradient\t[-2.94614218e-09  7.87103262e-08]\n",
      "weight after\t[-0.84291305 -0.14036474]\n",
      "Progress: 69.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291305 -0.14036474]\n",
      "gradient\t[-5.19952532e-08  1.40027057e-07]\n",
      "weight after\t[-0.8429131 -0.1403646]\n",
      "Progress: 69.4% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429131 -0.1403646]\n",
      "gradient\t[-2.07457489e-08  9.43602521e-08]\n",
      "weight after\t[-0.84291312 -0.1403645 ]\n",
      "Progress: 69.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291312 -0.1403645 ]\n",
      "gradient\t[-2.29335844e-09  6.55903361e-09]\n",
      "weight after\t[-0.84291312 -0.1403645 ]\n",
      "Progress: 69.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291312 -0.1403645 ]\n",
      "gradient\t[-3.01036518e-08  1.96956614e-07]\n",
      "weight after\t[-0.84291315 -0.1403643 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 69.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291315 -0.1403643 ]\n",
      "gradient\t[-6.07607842e-08  1.25922337e-07]\n",
      "weight after\t[-0.84291321 -0.14036417]\n",
      "Progress: 69.6% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291321 -0.14036417]\n",
      "gradient\t[-1.96430495e-08  4.25087373e-08]\n",
      "weight after\t[-0.84291323 -0.14036413]\n",
      "Progress: 69.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291323 -0.14036413]\n",
      "gradient\t[-7.05686283e-09  2.45841768e-07]\n",
      "weight after\t[-0.84291324 -0.14036389]\n",
      "Progress: 69.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291324 -0.14036389]\n",
      "gradient\t[-3.88471851e-08  1.93978896e-07]\n",
      "weight after\t[-0.84291328 -0.14036369]\n",
      "Progress: 69.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291328 -0.14036369]\n",
      "gradient\t[-1.91090332e-08  3.34251854e-08]\n",
      "weight after\t[-0.8429133  -0.14036366]\n",
      "Progress: 69.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429133  -0.14036366]\n",
      "gradient\t[-1.66266946e-09  3.83673202e-08]\n",
      "weight after\t[-0.8429133  -0.14036362]\n",
      "Progress: 69.8% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429133  -0.14036362]\n",
      "gradient\t[-1.04548876e-08  2.10164547e-08]\n",
      "weight after\t[-0.84291331 -0.1403636 ]\n",
      "Progress: 69.9% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291331 -0.1403636 ]\n",
      "gradient\t[-8.89999857e-10  6.69184311e-11]\n",
      "weight after\t[-0.84291331 -0.1403636 ]\n",
      "Progress: 70.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291331 -0.1403636 ]\n",
      "gradient\t[-3.81428410e-09  1.31200084e-07]\n",
      "weight after\t[-0.84291331 -0.14036347]\n",
      "Progress: 70.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291331 -0.14036347]\n",
      "gradient\t[-4.19058453e-08  9.51412500e-08]\n",
      "weight after\t[-0.84291335 -0.14036337]\n",
      "Progress: 70.0% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291335 -0.14036337]\n",
      "gradient\t[-4.97282938e-09  8.03047378e-08]\n",
      "weight after\t[-0.84291336 -0.14036329]\n",
      "Progress: 70.1% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291336 -0.14036329]\n",
      "gradient\t[-5.59659170e-08  1.78645802e-07]\n",
      "weight after\t[-0.84291342 -0.14036311]\n",
      "Progress: 70.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291342 -0.14036311]\n",
      "gradient\t[-5.69825359e-09  5.65984586e-08]\n",
      "weight after\t[-0.84291342 -0.14036306]\n",
      "Progress: 70.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291342 -0.14036306]\n",
      "gradient\t[-3.85314430e-08  8.05787808e-08]\n",
      "weight after\t[-0.84291346 -0.14036298]\n",
      "Progress: 70.2% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291346 -0.14036298]\n",
      "gradient\t[-2.50523138e-09  7.98651584e-09]\n",
      "weight after\t[-0.84291346 -0.14036297]\n",
      "Progress: 70.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291346 -0.14036297]\n",
      "gradient\t[-2.44154408e-08  1.05084736e-07]\n",
      "weight after\t[-0.84291349 -0.14036286]\n",
      "Progress: 70.3% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291349 -0.14036286]\n",
      "gradient\t[-5.95921375e-09  4.89590607e-08]\n",
      "weight after\t[-0.84291349 -0.14036281]\n",
      "Progress: 70.4% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291349 -0.14036281]\n",
      "gradient\t[-7.31723174e-09  2.02505220e-08]\n",
      "weight after\t[-0.8429135  -0.14036279]\n",
      "Progress: 70.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429135  -0.14036279]\n",
      "gradient\t[-9.90601883e-09  1.64598744e-08]\n",
      "weight after\t[-0.84291351 -0.14036278]\n",
      "Progress: 70.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291351 -0.14036278]\n",
      "gradient\t[-1.06759196e-09  3.38134418e-09]\n",
      "weight after\t[-0.84291351 -0.14036277]\n",
      "Progress: 70.5% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291351 -0.14036277]\n",
      "gradient\t[-1.43321492e-08  5.60695299e-08]\n",
      "weight after\t[-0.84291353 -0.14036272]\n",
      "Progress: 70.6% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291353 -0.14036272]\n",
      "gradient\t[-1.11703934e-08  1.36519019e-07]\n",
      "weight after\t[-0.84291354 -0.14036258]\n",
      "Progress: 70.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291354 -0.14036258]\n",
      "gradient\t[-2.13536176e-08  4.55679433e-08]\n",
      "weight after\t[-0.84291356 -0.14036254]\n",
      "Progress: 70.7% ... Training loss: 0.489 ... Validation loss: 0.487 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291356 -0.14036254]\n",
      "gradient\t[-2.13722936e-08  6.71624898e-08]\n",
      "weight after\t[-0.84291358 -0.14036247]\n",
      "Progress: 70.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291358 -0.14036247]\n",
      "gradient\t[-3.40617401e-09  1.21274299e-07]\n",
      "weight after\t[-0.84291358 -0.14036235]\n",
      "Progress: 70.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291358 -0.14036235]\n",
      "gradient\t[-1.81355649e-08  3.87682695e-08]\n",
      "weight after\t[-0.8429136  -0.14036231]\n",
      "Progress: 70.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429136  -0.14036231]\n",
      "gradient\t[-2.17662690e-08  4.24677806e-08]\n",
      "weight after\t[-0.84291362 -0.14036227]\n",
      "Progress: 70.9% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291362 -0.14036227]\n",
      "gradient\t[-1.60895329e-08  6.68163923e-08]\n",
      "weight after\t[-0.84291364 -0.1403622 ]\n",
      "Progress: 71.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291364 -0.1403622 ]\n",
      "gradient\t[-4.37503139e-08  9.30290972e-08]\n",
      "weight after\t[-0.84291368 -0.14036211]\n",
      "Progress: 71.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291368 -0.14036211]\n",
      "gradient\t[-1.0262715e-08  1.8164254e-08]\n",
      "weight after\t[-0.84291369 -0.14036209]\n",
      "Progress: 71.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291369 -0.14036209]\n",
      "gradient\t[-1.89312011e-08  4.00678580e-08]\n",
      "weight after\t[-0.84291371 -0.14036205]\n",
      "Progress: 71.1% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291371 -0.14036205]\n",
      "gradient\t[-1.40842262e-08  6.46866659e-08]\n",
      "weight after\t[-0.84291373 -0.14036198]\n",
      "Progress: 71.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291373 -0.14036198]\n",
      "gradient\t[-2.29334502e-09  8.35763986e-09]\n",
      "weight after\t[-0.84291373 -0.14036198]\n",
      "Progress: 71.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291373 -0.14036198]\n",
      "gradient\t[-3.48096138e-09  8.77629186e-09]\n",
      "weight after\t[-0.84291373 -0.14036197]\n",
      "Progress: 71.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291373 -0.14036197]\n",
      "gradient\t[-1.94868802e-08  3.52878736e-08]\n",
      "weight after\t[-0.84291375 -0.14036193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 71.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291375 -0.14036193]\n",
      "gradient\t[-3.72353015e-10  8.11486872e-10]\n",
      "weight after\t[-0.84291375 -0.14036193]\n",
      "Progress: 71.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291375 -0.14036193]\n",
      "gradient\t[-2.00476116e-08  3.55632335e-08]\n",
      "weight after\t[-0.84291377 -0.1403619 ]\n",
      "Progress: 71.4% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291377 -0.1403619 ]\n",
      "gradient\t[-1.85065516e-08  3.95316615e-08]\n",
      "weight after\t[-0.84291379 -0.14036186]\n",
      "Progress: 71.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291379 -0.14036186]\n",
      "gradient\t[-1.96731908e-08  1.48667411e-07]\n",
      "weight after\t[-0.84291381 -0.14036171]\n",
      "Progress: 71.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291381 -0.14036171]\n",
      "gradient\t[-4.18473048e-08  1.09395546e-07]\n",
      "weight after\t[-0.84291385 -0.1403616 ]\n",
      "Progress: 71.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291385 -0.1403616 ]\n",
      "gradient\t[-3.40427531e-08  8.81890828e-08]\n",
      "weight after\t[-0.84291389 -0.14036151]\n",
      "Progress: 71.6% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291389 -0.14036151]\n",
      "gradient\t[-4.39860626e-09  2.38902627e-07]\n",
      "weight after\t[-0.84291389 -0.14036127]\n",
      "Progress: 71.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291389 -0.14036127]\n",
      "gradient\t[-8.73829222e-09  1.30634552e-07]\n",
      "weight after\t[-0.8429139  -0.14036114]\n",
      "Progress: 71.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429139  -0.14036114]\n",
      "gradient\t[-2.04616129e-08  1.58294911e-07]\n",
      "weight after\t[-0.84291392 -0.14036098]\n",
      "Progress: 71.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291392 -0.14036098]\n",
      "gradient\t[-2.22439826e-08  3.16236824e-08]\n",
      "weight after\t[-0.84291394 -0.14036095]\n",
      "Progress: 71.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291394 -0.14036095]\n",
      "gradient\t[-3.68155888e-09  1.01642593e-08]\n",
      "weight after\t[-0.84291395 -0.14036094]\n",
      "Progress: 71.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291395 -0.14036094]\n",
      "gradient\t[-2.26819629e-08  5.14048184e-08]\n",
      "weight after\t[-0.84291397 -0.14036089]\n",
      "Progress: 71.9% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291397 -0.14036089]\n",
      "gradient\t[-1.95819883e-08  1.39621897e-07]\n",
      "weight after\t[-0.84291399 -0.14036075]\n",
      "Progress: 72.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291399 -0.14036075]\n",
      "gradient\t[-2.05913233e-08  5.17800842e-08]\n",
      "weight after\t[-0.84291401 -0.1403607 ]\n",
      "Progress: 72.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291401 -0.1403607 ]\n",
      "gradient\t[-4.24200233e-09  9.41621750e-09]\n",
      "weight after\t[-0.84291401 -0.14036069]\n",
      "Progress: 72.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291401 -0.14036069]\n",
      "gradient\t[-6.01342765e-10  4.72140344e-11]\n",
      "weight after\t[-0.84291401 -0.14036069]\n",
      "Progress: 72.1% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291401 -0.14036069]\n",
      "gradient\t[-1.23308664e-08  8.79027825e-08]\n",
      "weight after\t[-0.84291403 -0.1403606 ]\n",
      "Progress: 72.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291403 -0.1403606 ]\n",
      "gradient\t[-7.1144318e-09  1.1895403e-08]\n",
      "weight after\t[-0.84291403 -0.14036059]\n",
      "Progress: 72.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291403 -0.14036059]\n",
      "gradient\t[-9.05975797e-09  3.96125329e-08]\n",
      "weight after\t[-0.84291404 -0.14036055]\n",
      "Progress: 72.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291404 -0.14036055]\n",
      "gradient\t[-1.90455284e-08  2.59127388e-07]\n",
      "weight after\t[-0.84291406 -0.14036029]\n",
      "Progress: 72.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291406 -0.14036029]\n",
      "gradient\t[-1.11424059e-08  5.01112525e-08]\n",
      "weight after\t[-0.84291407 -0.14036024]\n",
      "Progress: 72.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291407 -0.14036024]\n",
      "gradient\t[-7.94932539e-10  2.03558894e-10]\n",
      "weight after\t[-0.84291407 -0.14036024]\n",
      "Progress: 72.4% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291407 -0.14036024]\n",
      "gradient\t[-7.95307681e-09  1.31156485e-08]\n",
      "weight after\t[-0.84291408 -0.14036023]\n",
      "Progress: 72.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291408 -0.14036023]\n",
      "gradient\t[-9.73519545e-09  1.15690282e-08]\n",
      "weight after\t[-0.84291409 -0.14036021]\n",
      "Progress: 72.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291409 -0.14036021]\n",
      "gradient\t[-2.25574463e-09  3.73017457e-08]\n",
      "weight after\t[-0.84291409 -0.14036018]\n",
      "Progress: 72.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291409 -0.14036018]\n",
      "gradient\t[-3.17245259e-08  6.15700033e-08]\n",
      "weight after\t[-0.84291412 -0.14036012]\n",
      "Progress: 72.6% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291412 -0.14036012]\n",
      "gradient\t[-3.98443843e-09  7.42865812e-09]\n",
      "weight after\t[-0.84291413 -0.14036011]\n",
      "Progress: 72.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291413 -0.14036011]\n",
      "gradient\t[-2.31539587e-08  6.32394600e-08]\n",
      "weight after\t[-0.84291415 -0.14036004]\n",
      "Progress: 72.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291415 -0.14036004]\n",
      "gradient\t[-1.34181544e-08  4.97296813e-08]\n",
      "weight after\t[-0.84291416 -0.14035999]\n",
      "Progress: 72.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291416 -0.14035999]\n",
      "gradient\t[-4.19389933e-08  7.23232271e-08]\n",
      "weight after\t[-0.84291421 -0.14035992]\n",
      "Progress: 72.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291421 -0.14035992]\n",
      "gradient\t[-1.42652854e-08  1.30007424e-07]\n",
      "weight after\t[-0.84291422 -0.14035979]\n",
      "Progress: 72.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291422 -0.14035979]\n",
      "gradient\t[-1.20684082e-08  2.47713232e-08]\n",
      "weight after\t[-0.84291423 -0.14035977]\n",
      "Progress: 72.9% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291423 -0.14035977]\n",
      "gradient\t[-5.05443796e-08  9.07717482e-08]\n",
      "weight after\t[-0.84291428 -0.14035968]\n",
      "Progress: 73.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291428 -0.14035968]\n",
      "gradient\t[-1.32710008e-08  1.17645375e-07]\n",
      "weight after\t[-0.8429143  -0.14035956]\n",
      "Progress: 73.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429143  -0.14035956]\n",
      "gradient\t[-1.22062153e-08  1.77007093e-08]\n",
      "weight after\t[-0.84291431 -0.14035954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 73.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291431 -0.14035954]\n",
      "gradient\t[-1.67015639e-09  2.32697110e-09]\n",
      "weight after\t[-0.84291431 -0.14035954]\n",
      "Progress: 73.1% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291431 -0.14035954]\n",
      "gradient\t[-2.13594149e-08  3.81098602e-08]\n",
      "weight after\t[-0.84291433 -0.1403595 ]\n",
      "Progress: 73.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291433 -0.1403595 ]\n",
      "gradient\t[-4.44250205e-09  1.56580768e-07]\n",
      "weight after\t[-0.84291434 -0.14035934]\n",
      "Progress: 73.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291434 -0.14035934]\n",
      "gradient\t[-2.48194810e-08  4.75270971e-08]\n",
      "weight after\t[-0.84291436 -0.1403593 ]\n",
      "Progress: 73.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291436 -0.1403593 ]\n",
      "gradient\t[-5.18221075e-09  6.62006072e-09]\n",
      "weight after\t[-0.84291437 -0.14035929]\n",
      "Progress: 73.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291437 -0.14035929]\n",
      "gradient\t[-8.99514839e-09  5.14754897e-08]\n",
      "weight after\t[-0.84291438 -0.14035924]\n",
      "Progress: 73.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291438 -0.14035924]\n",
      "gradient\t[-3.64081925e-09  2.25180551e-07]\n",
      "weight after\t[-0.84291438 -0.14035901]\n",
      "Progress: 73.4% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291438 -0.14035901]\n",
      "gradient\t[-1.85393839e-08  1.73815174e-07]\n",
      "weight after\t[-0.8429144  -0.14035884]\n",
      "Progress: 73.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429144  -0.14035884]\n",
      "gradient\t[-2.84639924e-08  1.60581936e-07]\n",
      "weight after\t[-0.84291443 -0.14035868]\n",
      "Progress: 73.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291443 -0.14035868]\n",
      "gradient\t[-4.09473994e-08  1.80558669e-07]\n",
      "weight after\t[-0.84291447 -0.1403585 ]\n",
      "Progress: 73.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291447 -0.1403585 ]\n",
      "gradient\t[-1.32604836e-08  5.09011027e-08]\n",
      "weight after\t[-0.84291448 -0.14035845]\n",
      "Progress: 73.6% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291448 -0.14035845]\n",
      "gradient\t[-5.09809829e-09  1.04377023e-08]\n",
      "weight after\t[-0.84291449 -0.14035844]\n",
      "Progress: 73.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291449 -0.14035844]\n",
      "gradient\t[-4.25578561e-09  1.16679328e-08]\n",
      "weight after\t[-0.84291449 -0.14035843]\n",
      "Progress: 73.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291449 -0.14035843]\n",
      "gradient\t[-3.28658343e-08  1.86327304e-07]\n",
      "weight after\t[-0.84291452 -0.14035824]\n",
      "Progress: 73.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291452 -0.14035824]\n",
      "gradient\t[-2.28349795e-08  4.23518955e-08]\n",
      "weight after\t[-0.84291455 -0.1403582 ]\n",
      "Progress: 73.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291455 -0.1403582 ]\n",
      "gradient\t[-4.71351722e-08  8.77213982e-08]\n",
      "weight after\t[-0.84291459 -0.14035811]\n",
      "Progress: 73.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291459 -0.14035811]\n",
      "gradient\t[-8.40754290e-09  1.71322064e-08]\n",
      "weight after\t[-0.8429146  -0.14035809]\n",
      "Progress: 73.9% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429146  -0.14035809]\n",
      "gradient\t[-9.63906619e-09  1.05503448e-08]\n",
      "weight after\t[-0.84291461 -0.14035808]\n",
      "Progress: 74.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291461 -0.14035808]\n",
      "gradient\t[-3.49660912e-08  1.93157481e-07]\n",
      "weight after\t[-0.84291465 -0.14035789]\n",
      "Progress: 74.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291465 -0.14035789]\n",
      "gradient\t[-3.07723659e-08  1.64051025e-07]\n",
      "weight after\t[-0.84291468 -0.14035772]\n",
      "Progress: 74.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291468 -0.14035772]\n",
      "gradient\t[-1.01083640e-08  3.94807154e-08]\n",
      "weight after\t[-0.84291469 -0.14035769]\n",
      "Progress: 74.1% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291469 -0.14035769]\n",
      "gradient\t[-2.16976241e-08  4.06209659e-08]\n",
      "weight after\t[-0.84291471 -0.14035764]\n",
      "Progress: 74.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291471 -0.14035764]\n",
      "gradient\t[-3.20990839e-08  5.36041305e-08]\n",
      "weight after\t[-0.84291474 -0.14035759]\n",
      "Progress: 74.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291474 -0.14035759]\n",
      "gradient\t[-1.69213063e-09  3.28808049e-08]\n",
      "weight after\t[-0.84291474 -0.14035756]\n",
      "Progress: 74.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291474 -0.14035756]\n",
      "gradient\t[-2.38087572e-08  3.90953934e-08]\n",
      "weight after\t[-0.84291477 -0.14035752]\n",
      "Progress: 74.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291477 -0.14035752]\n",
      "gradient\t[-5.97502417e-09  4.39728263e-08]\n",
      "weight after\t[-0.84291477 -0.14035748]\n",
      "Progress: 74.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291477 -0.14035748]\n",
      "gradient\t[-1.20293840e-08  2.28012587e-08]\n",
      "weight after\t[-0.84291478 -0.14035745]\n",
      "Progress: 74.4% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291478 -0.14035745]\n",
      "gradient\t[-1.07174121e-09  2.48799858e-10]\n",
      "weight after\t[-0.84291478 -0.14035745]\n",
      "Progress: 74.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291478 -0.14035745]\n",
      "gradient\t[-3.14263363e-09  4.60635264e-09]\n",
      "weight after\t[-0.84291479 -0.14035745]\n",
      "Progress: 74.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291479 -0.14035745]\n",
      "gradient\t[-1.72533973e-09  2.04064665e-07]\n",
      "weight after\t[-0.84291479 -0.14035724]\n",
      "Progress: 74.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291479 -0.14035724]\n",
      "gradient\t[-2.89678495e-09  3.66589098e-08]\n",
      "weight after\t[-0.84291479 -0.14035721]\n",
      "Progress: 74.6% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291479 -0.14035721]\n",
      "gradient\t[-6.95380305e-08  2.27556726e-07]\n",
      "weight after\t[-0.84291486 -0.14035698]\n",
      "Progress: 74.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291486 -0.14035698]\n",
      "gradient\t[-2.69405241e-08  7.43756385e-08]\n",
      "weight after\t[-0.84291489 -0.1403569 ]\n",
      "Progress: 74.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291489 -0.1403569 ]\n",
      "gradient\t[-4.10315792e-09  1.39641637e-08]\n",
      "weight after\t[-0.84291489 -0.14035689]\n",
      "Progress: 74.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291489 -0.14035689]\n",
      "gradient\t[-8.61632947e-10  2.85876552e-10]\n",
      "weight after\t[-0.84291489 -0.14035689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 74.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291489 -0.14035689]\n",
      "gradient\t[-1.79496574e-08  3.52427045e-08]\n",
      "weight after\t[-0.84291491 -0.14035686]\n",
      "Progress: 74.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291491 -0.14035686]\n",
      "gradient\t[-3.02780577e-09  9.18202862e-09]\n",
      "weight after\t[-0.84291491 -0.14035685]\n",
      "Progress: 74.9% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291491 -0.14035685]\n",
      "gradient\t[-3.82726584e-09  6.20589682e-09]\n",
      "weight after\t[-0.84291492 -0.14035684]\n",
      "Progress: 75.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291492 -0.14035684]\n",
      "gradient\t[-1.13572221e-08  4.31942704e-08]\n",
      "weight after\t[-0.84291493 -0.1403568 ]\n",
      "Progress: 75.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291493 -0.1403568 ]\n",
      "gradient\t[-9.69270612e-09  1.80853251e-08]\n",
      "weight after\t[-0.84291494 -0.14035678]\n",
      "Progress: 75.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291494 -0.14035678]\n",
      "gradient\t[-4.81870987e-08  9.18467107e-08]\n",
      "weight after\t[-0.84291499 -0.14035669]\n",
      "Progress: 75.1% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291499 -0.14035669]\n",
      "gradient\t[-1.69041123e-09  9.79107640e-08]\n",
      "weight after\t[-0.84291499 -0.14035659]\n",
      "Progress: 75.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291499 -0.14035659]\n",
      "gradient\t[-3.31320743e-08  1.82935105e-07]\n",
      "weight after\t[-0.84291502 -0.14035641]\n",
      "Progress: 75.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291502 -0.14035641]\n",
      "gradient\t[-4.41442612e-08  1.32232056e-07]\n",
      "weight after\t[-0.84291507 -0.14035627]\n",
      "Progress: 75.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291507 -0.14035627]\n",
      "gradient\t[-9.48095004e-09  1.78685471e-08]\n",
      "weight after\t[-0.84291508 -0.14035626]\n",
      "Progress: 75.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291508 -0.14035626]\n",
      "gradient\t[-1.27729496e-09  1.95050747e-09]\n",
      "weight after\t[-0.84291508 -0.14035625]\n",
      "Progress: 75.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291508 -0.14035625]\n",
      "gradient\t[-2.86394438e-08  7.54239844e-08]\n",
      "weight after\t[-0.84291511 -0.14035618]\n",
      "Progress: 75.4% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291511 -0.14035618]\n",
      "gradient\t[-1.67728806e-08  2.44836030e-08]\n",
      "weight after\t[-0.84291512 -0.14035615]\n",
      "Progress: 75.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291512 -0.14035615]\n",
      "gradient\t[-4.90367648e-09  5.61028001e-09]\n",
      "weight after\t[-0.84291513 -0.14035615]\n",
      "Progress: 75.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291513 -0.14035615]\n",
      "gradient\t[-1.19634704e-09  9.35784211e-08]\n",
      "weight after\t[-0.84291513 -0.14035605]\n",
      "Progress: 75.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291513 -0.14035605]\n",
      "gradient\t[-2.69899699e-08  1.57393776e-07]\n",
      "weight after\t[-0.84291516 -0.1403559 ]\n",
      "Progress: 75.6% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291516 -0.1403559 ]\n",
      "gradient\t[-5.56745481e-08  1.28704830e-07]\n",
      "weight after\t[-0.84291521 -0.14035577]\n",
      "Progress: 75.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291521 -0.14035577]\n",
      "gradient\t[-5.53214624e-08  1.06663417e-07]\n",
      "weight after\t[-0.84291527 -0.14035566]\n",
      "Progress: 75.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291527 -0.14035566]\n",
      "gradient\t[-1.39357839e-08  1.40939759e-07]\n",
      "weight after\t[-0.84291528 -0.14035552]\n",
      "Progress: 75.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291528 -0.14035552]\n",
      "gradient\t[-1.05705846e-08  6.51045873e-08]\n",
      "weight after\t[-0.84291529 -0.14035546]\n",
      "Progress: 75.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291529 -0.14035546]\n",
      "gradient\t[-2.82970894e-08  1.97851442e-07]\n",
      "weight after\t[-0.84291532 -0.14035526]\n",
      "Progress: 75.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291532 -0.14035526]\n",
      "gradient\t[-4.56122243e-08  7.64052549e-08]\n",
      "weight after\t[-0.84291537 -0.14035518]\n",
      "Progress: 75.9% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291537 -0.14035518]\n",
      "gradient\t[-4.55974094e-08  1.58918239e-07]\n",
      "weight after\t[-0.84291541 -0.14035502]\n",
      "Progress: 76.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291541 -0.14035502]\n",
      "gradient\t[-2.40142742e-08  4.53624106e-08]\n",
      "weight after\t[-0.84291544 -0.14035498]\n",
      "Progress: 76.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291544 -0.14035498]\n",
      "gradient\t[-2.63685329e-08  6.62080730e-08]\n",
      "weight after\t[-0.84291546 -0.14035491]\n",
      "Progress: 76.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291546 -0.14035491]\n",
      "gradient\t[-1.99696194e-08  6.75608976e-08]\n",
      "weight after\t[-0.84291548 -0.14035484]\n",
      "Progress: 76.1% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291548 -0.14035484]\n",
      "gradient\t[-1.87523673e-08  2.82655509e-08]\n",
      "weight after\t[-0.8429155  -0.14035482]\n",
      "Progress: 76.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429155  -0.14035482]\n",
      "gradient\t[-4.64044085e-08  1.55791368e-07]\n",
      "weight after\t[-0.84291555 -0.14035466]\n",
      "Progress: 76.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291555 -0.14035466]\n",
      "gradient\t[-1.08870188e-09  2.39139123e-09]\n",
      "weight after\t[-0.84291555 -0.14035466]\n",
      "Progress: 76.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291555 -0.14035466]\n",
      "gradient\t[-3.57126560e-08  5.84477814e-08]\n",
      "weight after\t[-0.84291558 -0.1403546 ]\n",
      "Progress: 76.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291558 -0.1403546 ]\n",
      "gradient\t[-1.09563577e-08  9.32565328e-08]\n",
      "weight after\t[-0.84291559 -0.14035451]\n",
      "Progress: 76.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291559 -0.14035451]\n",
      "gradient\t[-4.11368914e-08  1.57019266e-07]\n",
      "weight after\t[-0.84291564 -0.14035435]\n",
      "Progress: 76.4% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291564 -0.14035435]\n",
      "gradient\t[-1.72797832e-08  3.30161469e-08]\n",
      "weight after\t[-0.84291565 -0.14035432]\n",
      "Progress: 76.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291565 -0.14035432]\n",
      "gradient\t[-2.40266659e-09  3.45993187e-08]\n",
      "weight after\t[-0.84291566 -0.14035428]\n",
      "Progress: 76.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291566 -0.14035428]\n",
      "gradient\t[-2.05472244e-08  3.45302356e-08]\n",
      "weight after\t[-0.84291568 -0.14035425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 76.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291568 -0.14035425]\n",
      "gradient\t[-1.34431464e-08  2.47037313e-08]\n",
      "weight after\t[-0.84291569 -0.14035422]\n",
      "Progress: 76.6% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291569 -0.14035422]\n",
      "gradient\t[-3.64944186e-10  3.75051227e-11]\n",
      "weight after\t[-0.84291569 -0.14035422]\n",
      "Progress: 76.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291569 -0.14035422]\n",
      "gradient\t[-6.31942824e-08  1.08870117e-07]\n",
      "weight after\t[-0.84291575 -0.14035411]\n",
      "Progress: 76.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291575 -0.14035411]\n",
      "gradient\t[-5.46205445e-08  9.70676998e-08]\n",
      "weight after\t[-0.84291581 -0.14035402]\n",
      "Progress: 76.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291581 -0.14035402]\n",
      "gradient\t[-1.07417431e-08  9.23789154e-08]\n",
      "weight after\t[-0.84291582 -0.14035392]\n",
      "Progress: 76.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291582 -0.14035392]\n",
      "gradient\t[-3.27560937e-10  8.90385284e-08]\n",
      "weight after\t[-0.84291582 -0.14035383]\n",
      "Progress: 76.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291582 -0.14035383]\n",
      "gradient\t[-8.35323246e-10  1.94876350e-09]\n",
      "weight after\t[-0.84291582 -0.14035383]\n",
      "Progress: 76.9% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291582 -0.14035383]\n",
      "gradient\t[-9.18599292e-09  1.28507049e-07]\n",
      "weight after\t[-0.84291583 -0.1403537 ]\n",
      "Progress: 77.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291583 -0.1403537 ]\n",
      "gradient\t[-5.41440677e-08  9.25307725e-08]\n",
      "weight after\t[-0.84291588 -0.14035361]\n",
      "Progress: 77.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291588 -0.14035361]\n",
      "gradient\t[-1.96274954e-08  1.16768937e-07]\n",
      "weight after\t[-0.8429159  -0.14035349]\n",
      "Progress: 77.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429159  -0.14035349]\n",
      "gradient\t[-1.91801572e-08  5.36770712e-08]\n",
      "weight after\t[-0.84291592 -0.14035344]\n",
      "Progress: 77.1% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291592 -0.14035344]\n",
      "gradient\t[-1.26378431e-08  3.77048729e-08]\n",
      "weight after\t[-0.84291593 -0.1403534 ]\n",
      "Progress: 77.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291593 -0.1403534 ]\n",
      "gradient\t[-2.68543250e-08  1.28282317e-07]\n",
      "weight after\t[-0.84291596 -0.14035327]\n",
      "Progress: 77.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291596 -0.14035327]\n",
      "gradient\t[-1.83308037e-08  3.16365856e-08]\n",
      "weight after\t[-0.84291598 -0.14035324]\n",
      "Progress: 77.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291598 -0.14035324]\n",
      "gradient\t[-5.02281931e-09  5.89218692e-09]\n",
      "weight after\t[-0.84291598 -0.14035324]\n",
      "Progress: 77.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291598 -0.14035324]\n",
      "gradient\t[-9.25394344e-09  9.18930596e-09]\n",
      "weight after\t[-0.84291599 -0.14035323]\n",
      "Progress: 77.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291599 -0.14035323]\n",
      "gradient\t[-2.61212051e-08  7.63819127e-08]\n",
      "weight after\t[-0.84291602 -0.14035315]\n",
      "Progress: 77.4% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291602 -0.14035315]\n",
      "gradient\t[-5.84844837e-09  9.54154655e-08]\n",
      "weight after\t[-0.84291603 -0.14035306]\n",
      "Progress: 77.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291603 -0.14035306]\n",
      "gradient\t[-3.14896990e-08  7.38859017e-08]\n",
      "weight after\t[-0.84291606 -0.14035298]\n",
      "Progress: 77.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291606 -0.14035298]\n",
      "gradient\t[-2.33302068e-08  3.34296262e-08]\n",
      "weight after\t[-0.84291608 -0.14035295]\n",
      "Progress: 77.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291608 -0.14035295]\n",
      "gradient\t[-3.75233620e-08  5.16650861e-08]\n",
      "weight after\t[-0.84291612 -0.1403529 ]\n",
      "Progress: 77.6% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291612 -0.1403529 ]\n",
      "gradient\t[-6.12903839e-09  1.16944439e-07]\n",
      "weight after\t[-0.84291612 -0.14035278]\n",
      "Progress: 77.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291612 -0.14035278]\n",
      "gradient\t[-4.37585576e-08  1.15486626e-07]\n",
      "weight after\t[-0.84291617 -0.14035266]\n",
      "Progress: 77.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291617 -0.14035266]\n",
      "gradient\t[-3.95072005e-09  6.61641852e-09]\n",
      "weight after\t[-0.84291617 -0.14035266]\n",
      "Progress: 77.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291617 -0.14035266]\n",
      "gradient\t[-4.89979921e-09  5.26055034e-09]\n",
      "weight after\t[-0.84291618 -0.14035265]\n",
      "Progress: 77.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291618 -0.14035265]\n",
      "gradient\t[-9.78572483e-09  1.59471148e-08]\n",
      "weight after\t[-0.84291619 -0.14035264]\n",
      "Progress: 77.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291619 -0.14035264]\n",
      "gradient\t[-1.18484208e-08  3.83690711e-08]\n",
      "weight after\t[-0.8429162 -0.1403526]\n",
      "Progress: 77.9% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429162 -0.1403526]\n",
      "gradient\t[-1.11879764e-08  1.19772530e-07]\n",
      "weight after\t[-0.84291621 -0.14035248]\n",
      "Progress: 78.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291621 -0.14035248]\n",
      "gradient\t[-3.25741583e-08  1.52399034e-07]\n",
      "weight after\t[-0.84291624 -0.14035233]\n",
      "Progress: 78.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291624 -0.14035233]\n",
      "gradient\t[-3.83482697e-09  6.52278969e-09]\n",
      "weight after\t[-0.84291625 -0.14035232]\n",
      "Progress: 78.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291625 -0.14035232]\n",
      "gradient\t[-3.22770695e-09  7.44861592e-09]\n",
      "weight after\t[-0.84291625 -0.14035231]\n",
      "Progress: 78.1% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291625 -0.14035231]\n",
      "gradient\t[-4.01093932e-09  3.04381595e-08]\n",
      "weight after\t[-0.84291625 -0.14035228]\n",
      "Progress: 78.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291625 -0.14035228]\n",
      "gradient\t[-4.13433403e-10  2.63789152e-11]\n",
      "weight after\t[-0.84291625 -0.14035228]\n",
      "Progress: 78.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291625 -0.14035228]\n",
      "gradient\t[-1.02532960e-08  1.08730533e-08]\n",
      "weight after\t[-0.84291626 -0.14035227]\n",
      "Progress: 78.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291626 -0.14035227]\n",
      "gradient\t[-1.57577057e-09  2.62763916e-08]\n",
      "weight after\t[-0.84291627 -0.14035224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 78.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291627 -0.14035224]\n",
      "gradient\t[-1.19472699e-08  9.62865271e-08]\n",
      "weight after\t[-0.84291628 -0.14035215]\n",
      "Progress: 78.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291628 -0.14035215]\n",
      "gradient\t[-3.58354482e-08  7.27518098e-08]\n",
      "weight after\t[-0.84291631 -0.14035208]\n",
      "Progress: 78.4% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291631 -0.14035208]\n",
      "gradient\t[-2.21082792e-08  5.90671925e-08]\n",
      "weight after\t[-0.84291634 -0.14035202]\n",
      "Progress: 78.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291634 -0.14035202]\n",
      "gradient\t[-4.97040702e-09  4.94374940e-09]\n",
      "weight after\t[-0.84291634 -0.14035201]\n",
      "Progress: 78.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291634 -0.14035201]\n",
      "gradient\t[-2.64698296e-08  4.59058412e-08]\n",
      "weight after\t[-0.84291637 -0.14035197]\n",
      "Progress: 78.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291637 -0.14035197]\n",
      "gradient\t[-2.74427763e-08  7.70844736e-08]\n",
      "weight after\t[-0.84291639 -0.14035189]\n",
      "Progress: 78.6% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291639 -0.14035189]\n",
      "gradient\t[-1.80312360e-08  2.57200567e-08]\n",
      "weight after\t[-0.84291641 -0.14035186]\n",
      "Progress: 78.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291641 -0.14035186]\n",
      "gradient\t[-1.93855610e-08  5.19680428e-08]\n",
      "weight after\t[-0.84291643 -0.14035181]\n",
      "Progress: 78.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291643 -0.14035181]\n",
      "gradient\t[-2.00485557e-08  6.11405543e-08]\n",
      "weight after\t[-0.84291645 -0.14035175]\n",
      "Progress: 78.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291645 -0.14035175]\n",
      "gradient\t[-5.31750272e-09  1.05172565e-08]\n",
      "weight after\t[-0.84291646 -0.14035174]\n",
      "Progress: 78.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291646 -0.14035174]\n",
      "gradient\t[-1.17856632e-08  4.19425633e-08]\n",
      "weight after\t[-0.84291647 -0.1403517 ]\n",
      "Progress: 78.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291647 -0.1403517 ]\n",
      "gradient\t[-3.45212349e-09  2.84260307e-08]\n",
      "weight after\t[-0.84291647 -0.14035167]\n",
      "Progress: 78.9% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291647 -0.14035167]\n",
      "gradient\t[-2.12284563e-08  3.60730259e-08]\n",
      "weight after\t[-0.84291649 -0.14035163]\n",
      "Progress: 79.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291649 -0.14035163]\n",
      "gradient\t[-9.53491833e-09  9.74477658e-09]\n",
      "weight after\t[-0.8429165  -0.14035162]\n",
      "Progress: 79.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429165  -0.14035162]\n",
      "gradient\t[-5.31993718e-09  6.41485035e-09]\n",
      "weight after\t[-0.84291651 -0.14035162]\n",
      "Progress: 79.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291651 -0.14035162]\n",
      "gradient\t[-3.16357030e-09  3.07450764e-08]\n",
      "weight after\t[-0.84291651 -0.14035159]\n",
      "Progress: 79.1% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291651 -0.14035159]\n",
      "gradient\t[-3.98496096e-08  5.67651554e-08]\n",
      "weight after\t[-0.84291655 -0.14035153]\n",
      "Progress: 79.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291655 -0.14035153]\n",
      "gradient\t[-5.20968870e-08  1.54357415e-07]\n",
      "weight after\t[-0.8429166  -0.14035138]\n",
      "Progress: 79.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429166  -0.14035138]\n",
      "gradient\t[-1.19273721e-08  3.91873471e-08]\n",
      "weight after\t[-0.84291662 -0.14035134]\n",
      "Progress: 79.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291662 -0.14035134]\n",
      "gradient\t[-1.82379788e-08  1.02834491e-07]\n",
      "weight after\t[-0.84291663 -0.14035123]\n",
      "Progress: 79.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291663 -0.14035123]\n",
      "gradient\t[-1.37238130e-08  1.70719066e-08]\n",
      "weight after\t[-0.84291665 -0.14035122]\n",
      "Progress: 79.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291665 -0.14035122]\n",
      "gradient\t[-6.36382059e-08  2.23602422e-07]\n",
      "weight after\t[-0.84291671 -0.14035099]\n",
      "Progress: 79.4% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291671 -0.14035099]\n",
      "gradient\t[-2.59813475e-08  1.95992544e-07]\n",
      "weight after\t[-0.84291674 -0.1403508 ]\n",
      "Progress: 79.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291674 -0.1403508 ]\n",
      "gradient\t[-3.70183508e-09  8.75160640e-09]\n",
      "weight after\t[-0.84291674 -0.14035079]\n",
      "Progress: 79.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291674 -0.14035079]\n",
      "gradient\t[-2.12161320e-08  1.10536631e-07]\n",
      "weight after\t[-0.84291676 -0.14035068]\n",
      "Progress: 79.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291676 -0.14035068]\n",
      "gradient\t[-3.29997205e-08  1.58474442e-07]\n",
      "weight after\t[-0.84291679 -0.14035052]\n",
      "Progress: 79.6% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291679 -0.14035052]\n",
      "gradient\t[-2.95702501e-09  7.94088647e-08]\n",
      "weight after\t[-0.8429168  -0.14035044]\n",
      "Progress: 79.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429168  -0.14035044]\n",
      "gradient\t[-8.24010716e-09  2.98335403e-08]\n",
      "weight after\t[-0.84291681 -0.14035041]\n",
      "Progress: 79.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291681 -0.14035041]\n",
      "gradient\t[-9.94467858e-10  1.51067251e-09]\n",
      "weight after\t[-0.84291681 -0.14035041]\n",
      "Progress: 79.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291681 -0.14035041]\n",
      "gradient\t[-2.24762411e-08  3.48984056e-08]\n",
      "weight after\t[-0.84291683 -0.14035037]\n",
      "Progress: 79.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291683 -0.14035037]\n",
      "gradient\t[-3.56922299e-08  5.03168582e-08]\n",
      "weight after\t[-0.84291686 -0.14035032]\n",
      "Progress: 79.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291686 -0.14035032]\n",
      "gradient\t[-1.84030602e-08  2.50778365e-08]\n",
      "weight after\t[-0.84291688 -0.1403503 ]\n",
      "Progress: 79.9% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291688 -0.1403503 ]\n",
      "gradient\t[-2.85412578e-08  5.04341198e-08]\n",
      "weight after\t[-0.84291691 -0.14035025]\n",
      "Progress: 80.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291691 -0.14035025]\n",
      "gradient\t[-3.30559411e-08  5.00427745e-08]\n",
      "weight after\t[-0.84291694 -0.1403502 ]\n",
      "Progress: 80.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291694 -0.1403502 ]\n",
      "gradient\t[-3.75004765e-08  7.20624486e-08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight after\t[-0.84291698 -0.14035013]\n",
      "Progress: 80.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291698 -0.14035013]\n",
      "gradient\t[-9.66957358e-10  3.92783228e-09]\n",
      "weight after\t[-0.84291698 -0.14035012]\n",
      "Progress: 80.1% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291698 -0.14035012]\n",
      "gradient\t[-1.94552117e-08  3.39553307e-08]\n",
      "weight after\t[-0.842917   -0.14035009]\n",
      "Progress: 80.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.842917   -0.14035009]\n",
      "gradient\t[-9.59563253e-09  8.36774219e-09]\n",
      "weight after\t[-0.84291701 -0.14035008]\n",
      "Progress: 80.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291701 -0.14035008]\n",
      "gradient\t[-2.92467949e-08  6.08993840e-08]\n",
      "weight after\t[-0.84291704 -0.14035002]\n",
      "Progress: 80.2% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291704 -0.14035002]\n",
      "gradient\t[-2.53817826e-09  7.76271365e-08]\n",
      "weight after\t[-0.84291704 -0.14034994]\n",
      "Progress: 80.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291704 -0.14034994]\n",
      "gradient\t[-5.84010291e-09  8.29705129e-08]\n",
      "weight after\t[-0.84291705 -0.14034986]\n",
      "Progress: 80.3% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291705 -0.14034986]\n",
      "gradient\t[-2.86134260e-08  4.75987718e-08]\n",
      "weight after\t[-0.84291708 -0.14034981]\n",
      "Progress: 80.4% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291708 -0.14034981]\n",
      "gradient\t[-2.68034242e-08  1.78765679e-07]\n",
      "weight after\t[-0.84291711 -0.14034963]\n",
      "Progress: 80.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291711 -0.14034963]\n",
      "gradient\t[-6.18216611e-09  8.06011072e-08]\n",
      "weight after\t[-0.84291711 -0.14034955]\n",
      "Progress: 80.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291711 -0.14034955]\n",
      "gradient\t[-3.50930987e-08  7.30172782e-08]\n",
      "weight after\t[-0.84291715 -0.14034948]\n",
      "Progress: 80.5% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291715 -0.14034948]\n",
      "gradient\t[-1.19956244e-08  3.63249323e-08]\n",
      "weight after\t[-0.84291716 -0.14034944]\n",
      "Progress: 80.6% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291716 -0.14034944]\n",
      "gradient\t[-4.45870025e-09  2.81108682e-08]\n",
      "weight after\t[-0.84291716 -0.14034941]\n",
      "Progress: 80.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291716 -0.14034941]\n",
      "gradient\t[-5.26566818e-09  8.75631531e-09]\n",
      "weight after\t[-0.84291717 -0.1403494 ]\n",
      "Progress: 80.7% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291717 -0.1403494 ]\n",
      "gradient\t[-9.31231146e-09  1.47007260e-08]\n",
      "weight after\t[-0.84291718 -0.14034939]\n",
      "Progress: 80.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291718 -0.14034939]\n",
      "gradient\t[-4.00559217e-08  5.27102370e-08]\n",
      "weight after\t[-0.84291722 -0.14034934]\n",
      "Progress: 80.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291722 -0.14034934]\n",
      "gradient\t[-4.24938025e-08  1.08109393e-07]\n",
      "weight after\t[-0.84291726 -0.14034923]\n",
      "Progress: 80.8% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291726 -0.14034923]\n",
      "gradient\t[-4.60715873e-10  7.26965227e-08]\n",
      "weight after\t[-0.84291726 -0.14034916]\n",
      "Progress: 80.9% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291726 -0.14034916]\n",
      "gradient\t[-2.31350444e-08  1.02184934e-07]\n",
      "weight after\t[-0.84291728 -0.14034905]\n",
      "Progress: 81.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291728 -0.14034905]\n",
      "gradient\t[-7.65097758e-08  1.14781034e-07]\n",
      "weight after\t[-0.84291736 -0.14034894]\n",
      "Progress: 81.0% ... Training loss: 0.489 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291736 -0.14034894]\n",
      "gradient\t[-8.03701094e-09  1.06480265e-08]\n",
      "weight after\t[-0.84291737 -0.14034893]\n",
      "Progress: 81.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291737 -0.14034893]\n",
      "gradient\t[-1.97973897e-08  3.44105927e-08]\n",
      "weight after\t[-0.84291739 -0.14034889]\n",
      "Progress: 81.1% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291739 -0.14034889]\n",
      "gradient\t[-9.51111512e-09  3.36499509e-08]\n",
      "weight after\t[-0.8429174  -0.14034886]\n",
      "Progress: 81.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429174  -0.14034886]\n",
      "gradient\t[-4.73237816e-08  1.60319980e-07]\n",
      "weight after\t[-0.84291745 -0.1403487 ]\n",
      "Progress: 81.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291745 -0.1403487 ]\n",
      "gradient\t[-8.41289169e-09  1.25824705e-08]\n",
      "weight after\t[-0.84291745 -0.14034869]\n",
      "Progress: 81.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291745 -0.14034869]\n",
      "gradient\t[-1.45417007e-08  2.23397719e-08]\n",
      "weight after\t[-0.84291747 -0.14034866]\n",
      "Progress: 81.3% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291747 -0.14034866]\n",
      "gradient\t[-1.76137352e-09  1.60021938e-09]\n",
      "weight after\t[-0.84291747 -0.14034866]\n",
      "Progress: 81.3% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291747 -0.14034866]\n",
      "gradient\t[-1.68529487e-08  2.76175679e-08]\n",
      "weight after\t[-0.84291749 -0.14034864]\n",
      "Progress: 81.4% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291749 -0.14034864]\n",
      "gradient\t[-3.45443182e-08  1.22461879e-07]\n",
      "weight after\t[-0.84291752 -0.14034851]\n",
      "Progress: 81.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291752 -0.14034851]\n",
      "gradient\t[-3.22052689e-09  1.45958726e-07]\n",
      "weight after\t[-0.84291752 -0.14034837]\n",
      "Progress: 81.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291752 -0.14034837]\n",
      "gradient\t[-2.22703747e-08  1.25783055e-07]\n",
      "weight after\t[-0.84291755 -0.14034824]\n",
      "Progress: 81.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291755 -0.14034824]\n",
      "gradient\t[-5.15647021e-08  6.30685687e-08]\n",
      "weight after\t[-0.8429176  -0.14034818]\n",
      "Progress: 81.6% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429176  -0.14034818]\n",
      "gradient\t[-1.62681533e-08  3.68185292e-08]\n",
      "weight after\t[-0.84291761 -0.14034814]\n",
      "Progress: 81.7% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291761 -0.14034814]\n",
      "gradient\t[-9.60385105e-09  8.02622444e-09]\n",
      "weight after\t[-0.84291762 -0.14034813]\n",
      "Progress: 81.7% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291762 -0.14034813]\n",
      "gradient\t[-2.30751865e-09  3.05876053e-09]\n",
      "weight after\t[-0.84291763 -0.14034813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 81.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291763 -0.14034813]\n",
      "gradient\t[-9.47506675e-09  8.80389925e-09]\n",
      "weight after\t[-0.84291764 -0.14034812]\n",
      "Progress: 81.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291764 -0.14034812]\n",
      "gradient\t[-1.63133314e-08  3.67354234e-08]\n",
      "weight after\t[-0.84291765 -0.14034809]\n",
      "Progress: 81.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291765 -0.14034809]\n",
      "gradient\t[-1.38540655e-08  1.55050376e-07]\n",
      "weight after\t[-0.84291767 -0.14034793]\n",
      "Progress: 81.9% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291767 -0.14034793]\n",
      "gradient\t[-2.57460778e-08  2.33731383e-08]\n",
      "weight after\t[-0.84291769 -0.14034791]\n",
      "Progress: 82.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291769 -0.14034791]\n",
      "gradient\t[-2.03672110e-08  3.31962964e-08]\n",
      "weight after\t[-0.84291771 -0.14034787]\n",
      "Progress: 82.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291771 -0.14034787]\n",
      "gradient\t[-1.38273375e-09  1.42734262e-07]\n",
      "weight after\t[-0.84291771 -0.14034773]\n",
      "Progress: 82.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291771 -0.14034773]\n",
      "gradient\t[-1.84236745e-08  3.94431964e-08]\n",
      "weight after\t[-0.84291773 -0.14034769]\n",
      "Progress: 82.1% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291773 -0.14034769]\n",
      "gradient\t[-3.19570398e-08  6.96568263e-08]\n",
      "weight after\t[-0.84291776 -0.14034762]\n",
      "Progress: 82.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291776 -0.14034762]\n",
      "gradient\t[-1.45149610e-10  1.27529171e-11]\n",
      "weight after\t[-0.84291776 -0.14034762]\n",
      "Progress: 82.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291776 -0.14034762]\n",
      "gradient\t[-3.38505835e-08  6.05681541e-08]\n",
      "weight after\t[-0.8429178  -0.14034756]\n",
      "Progress: 82.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429178  -0.14034756]\n",
      "gradient\t[-1.91401763e-09  2.30711395e-08]\n",
      "weight after\t[-0.8429178  -0.14034754]\n",
      "Progress: 82.3% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429178  -0.14034754]\n",
      "gradient\t[-2.60625429e-08  3.96110253e-08]\n",
      "weight after\t[-0.84291783 -0.1403475 ]\n",
      "Progress: 82.3% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291783 -0.1403475 ]\n",
      "gradient\t[-1.07580947e-08  1.69869149e-07]\n",
      "weight after\t[-0.84291784 -0.14034733]\n",
      "Progress: 82.4% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291784 -0.14034733]\n",
      "gradient\t[-9.31702521e-09  7.75628441e-08]\n",
      "weight after\t[-0.84291785 -0.14034725]\n",
      "Progress: 82.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291785 -0.14034725]\n",
      "gradient\t[-3.02645451e-09  7.24870153e-08]\n",
      "weight after\t[-0.84291785 -0.14034718]\n",
      "Progress: 82.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291785 -0.14034718]\n",
      "gradient\t[-3.22301203e-08  8.41563002e-08]\n",
      "weight after\t[-0.84291788 -0.14034709]\n",
      "Progress: 82.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291788 -0.14034709]\n",
      "gradient\t[-3.40146270e-09  2.52285371e-08]\n",
      "weight after\t[-0.84291788 -0.14034707]\n",
      "Progress: 82.6% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291788 -0.14034707]\n",
      "gradient\t[-2.87999655e-08  2.46374846e-07]\n",
      "weight after\t[-0.84291791 -0.14034682]\n",
      "Progress: 82.7% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291791 -0.14034682]\n",
      "gradient\t[-2.54311009e-08  1.29544263e-07]\n",
      "weight after\t[-0.84291794 -0.14034669]\n",
      "Progress: 82.7% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291794 -0.14034669]\n",
      "gradient\t[-1.72389648e-08  2.81790904e-08]\n",
      "weight after\t[-0.84291796 -0.14034666]\n",
      "Progress: 82.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291796 -0.14034666]\n",
      "gradient\t[-1.99409042e-08  9.64483151e-08]\n",
      "weight after\t[-0.84291798 -0.14034657]\n",
      "Progress: 82.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291798 -0.14034657]\n",
      "gradient\t[-3.68835316e-08  1.53067741e-07]\n",
      "weight after\t[-0.84291801 -0.14034642]\n",
      "Progress: 82.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291801 -0.14034642]\n",
      "gradient\t[-1.08297844e-08  3.53392477e-08]\n",
      "weight after\t[-0.84291802 -0.14034638]\n",
      "Progress: 82.9% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291802 -0.14034638]\n",
      "gradient\t[-1.91539721e-08  1.29276940e-07]\n",
      "weight after\t[-0.84291804 -0.14034625]\n",
      "Progress: 83.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291804 -0.14034625]\n",
      "gradient\t[-1.14392397e-08  1.23819448e-08]\n",
      "weight after\t[-0.84291805 -0.14034624]\n",
      "Progress: 83.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291805 -0.14034624]\n",
      "gradient\t[-4.31127386e-09  6.24308742e-09]\n",
      "weight after\t[-0.84291806 -0.14034623]\n",
      "Progress: 83.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291806 -0.14034623]\n",
      "gradient\t[-2.87357866e-08  1.06807537e-07]\n",
      "weight after\t[-0.84291809 -0.14034613]\n",
      "Progress: 83.1% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291809 -0.14034613]\n",
      "gradient\t[-1.20235365e-08  7.86016706e-08]\n",
      "weight after\t[-0.8429181  -0.14034605]\n",
      "Progress: 83.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429181  -0.14034605]\n",
      "gradient\t[-3.14996460e-09  2.45535822e-08]\n",
      "weight after\t[-0.8429181  -0.14034602]\n",
      "Progress: 83.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429181  -0.14034602]\n",
      "gradient\t[-1.36820443e-09  4.88095071e-10]\n",
      "weight after\t[-0.8429181  -0.14034602]\n",
      "Progress: 83.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429181  -0.14034602]\n",
      "gradient\t[-1.74129134e-08  2.01708248e-08]\n",
      "weight after\t[-0.84291812 -0.140346  ]\n",
      "Progress: 83.3% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291812 -0.140346  ]\n",
      "gradient\t[-1.03422590e-09  3.93362493e-09]\n",
      "weight after\t[-0.84291812 -0.140346  ]\n",
      "Progress: 83.3% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291812 -0.140346  ]\n",
      "gradient\t[-3.61044457e-08  1.06526895e-07]\n",
      "weight after\t[-0.84291816 -0.14034589]\n",
      "Progress: 83.4% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291816 -0.14034589]\n",
      "gradient\t[-1.94783074e-08  2.41352486e-08]\n",
      "weight after\t[-0.84291818 -0.14034587]\n",
      "Progress: 83.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291818 -0.14034587]\n",
      "gradient\t[-2.69358554e-08  5.84465894e-08]\n",
      "weight after\t[-0.84291821 -0.14034581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 83.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291821 -0.14034581]\n",
      "gradient\t[-7.37663457e-09  7.09905196e-08]\n",
      "weight after\t[-0.84291821 -0.14034574]\n",
      "Progress: 83.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291821 -0.14034574]\n",
      "gradient\t[-9.94584735e-09  5.07407904e-08]\n",
      "weight after\t[-0.84291822 -0.14034569]\n",
      "Progress: 83.6% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291822 -0.14034569]\n",
      "gradient\t[-3.49984128e-09  6.84129817e-09]\n",
      "weight after\t[-0.84291823 -0.14034568]\n",
      "Progress: 83.7% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291823 -0.14034568]\n",
      "gradient\t[-9.38079656e-09  3.15784538e-08]\n",
      "weight after\t[-0.84291824 -0.14034565]\n",
      "Progress: 83.7% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291824 -0.14034565]\n",
      "gradient\t[-2.51852228e-09  4.69987526e-09]\n",
      "weight after\t[-0.84291824 -0.14034564]\n",
      "Progress: 83.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291824 -0.14034564]\n",
      "gradient\t[-2.59559710e-08  3.44981298e-08]\n",
      "weight after\t[-0.84291826 -0.14034561]\n",
      "Progress: 83.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291826 -0.14034561]\n",
      "gradient\t[-2.02295293e-08  4.40338104e-08]\n",
      "weight after\t[-0.84291828 -0.14034557]\n",
      "Progress: 83.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291828 -0.14034557]\n",
      "gradient\t[-1.73631058e-08  8.79986607e-08]\n",
      "weight after\t[-0.8429183  -0.14034548]\n",
      "Progress: 83.9% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429183  -0.14034548]\n",
      "gradient\t[-1.81138774e-08  8.36201173e-08]\n",
      "weight after\t[-0.84291832 -0.14034539]\n",
      "Progress: 84.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291832 -0.14034539]\n",
      "gradient\t[-5.64391426e-10  1.98675034e-10]\n",
      "weight after\t[-0.84291832 -0.14034539]\n",
      "Progress: 84.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291832 -0.14034539]\n",
      "gradient\t[-1.19789435e-08  5.31047752e-08]\n",
      "weight after\t[-0.84291833 -0.14034534]\n",
      "Progress: 84.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291833 -0.14034534]\n",
      "gradient\t[-2.01848191e-08  2.78591683e-08]\n",
      "weight after\t[-0.84291835 -0.14034531]\n",
      "Progress: 84.1% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291835 -0.14034531]\n",
      "gradient\t[-4.38247527e-09  7.55889062e-09]\n",
      "weight after\t[-0.84291836 -0.1403453 ]\n",
      "Progress: 84.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291836 -0.1403453 ]\n",
      "gradient\t[-1.26405455e-08  1.20354265e-07]\n",
      "weight after\t[-0.84291837 -0.14034518]\n",
      "Progress: 84.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291837 -0.14034518]\n",
      "gradient\t[-1.63584971e-08  3.48844565e-08]\n",
      "weight after\t[-0.84291839 -0.14034515]\n",
      "Progress: 84.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291839 -0.14034515]\n",
      "gradient\t[-3.39741656e-08  8.07823266e-08]\n",
      "weight after\t[-0.84291842 -0.14034507]\n",
      "Progress: 84.3% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291842 -0.14034507]\n",
      "gradient\t[-1.63058061e-08  2.56608076e-08]\n",
      "weight after\t[-0.84291844 -0.14034504]\n",
      "Progress: 84.3% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291844 -0.14034504]\n",
      "gradient\t[-1.08993131e-08  1.39454482e-08]\n",
      "weight after\t[-0.84291845 -0.14034503]\n",
      "Progress: 84.4% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291845 -0.14034503]\n",
      "gradient\t[-4.08646089e-09  7.63600248e-09]\n",
      "weight after\t[-0.84291845 -0.14034502]\n",
      "Progress: 84.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291845 -0.14034502]\n",
      "gradient\t[-1.42735250e-09  2.08890871e-08]\n",
      "weight after\t[-0.84291845 -0.140345  ]\n",
      "Progress: 84.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291845 -0.140345  ]\n",
      "gradient\t[-4.09920996e-08  8.14190394e-08]\n",
      "weight after\t[-0.84291849 -0.14034492]\n",
      "Progress: 84.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291849 -0.14034492]\n",
      "gradient\t[-1.68343867e-08  2.56181434e-08]\n",
      "weight after\t[-0.84291851 -0.14034489]\n",
      "Progress: 84.6% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291851 -0.14034489]\n",
      "gradient\t[-2.67540305e-08  4.34218771e-08]\n",
      "weight after\t[-0.84291854 -0.14034485]\n",
      "Progress: 84.7% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291854 -0.14034485]\n",
      "gradient\t[-1.58709888e-08  3.89584192e-08]\n",
      "weight after\t[-0.84291855 -0.14034481]\n",
      "Progress: 84.7% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291855 -0.14034481]\n",
      "gradient\t[-3.19316528e-08  8.29566492e-08]\n",
      "weight after\t[-0.84291858 -0.14034473]\n",
      "Progress: 84.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291858 -0.14034473]\n",
      "gradient\t[-1.18564149e-08  2.10571399e-08]\n",
      "weight after\t[-0.8429186  -0.14034471]\n",
      "Progress: 84.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429186  -0.14034471]\n",
      "gradient\t[-6.22867470e-10  5.37908553e-10]\n",
      "weight after\t[-0.8429186  -0.14034471]\n",
      "Progress: 84.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429186  -0.14034471]\n",
      "gradient\t[-1.67117433e-08  1.00784360e-07]\n",
      "weight after\t[-0.84291861 -0.14034461]\n",
      "Progress: 84.9% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291861 -0.14034461]\n",
      "gradient\t[-1.16102053e-08  1.16074855e-08]\n",
      "weight after\t[-0.84291863 -0.14034459]\n",
      "Progress: 85.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291863 -0.14034459]\n",
      "gradient\t[-1.71613346e-08  8.85465522e-08]\n",
      "weight after\t[-0.84291864 -0.14034451]\n",
      "Progress: 85.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291864 -0.14034451]\n",
      "gradient\t[-2.76947024e-08  4.63135404e-08]\n",
      "weight after\t[-0.84291867 -0.14034446]\n",
      "Progress: 85.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291867 -0.14034446]\n",
      "gradient\t[-2.58029164e-09  3.11078969e-09]\n",
      "weight after\t[-0.84291867 -0.14034446]\n",
      "Progress: 85.1% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291867 -0.14034446]\n",
      "gradient\t[-1.89287563e-08  4.11533471e-08]\n",
      "weight after\t[-0.84291869 -0.14034442]\n",
      "Progress: 85.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291869 -0.14034442]\n",
      "gradient\t[-2.02765104e-08  5.00105172e-08]\n",
      "weight after\t[-0.84291871 -0.14034437]\n",
      "Progress: 85.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291871 -0.14034437]\n",
      "gradient\t[-3.38868067e-09  2.38455906e-08]\n",
      "weight after\t[-0.84291872 -0.14034434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 85.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291872 -0.14034434]\n",
      "gradient\t[-1.03330203e-08  1.60478308e-08]\n",
      "weight after\t[-0.84291873 -0.14034433]\n",
      "Progress: 85.3% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291873 -0.14034433]\n",
      "gradient\t[-2.15168526e-09  4.42428251e-09]\n",
      "weight after\t[-0.84291873 -0.14034432]\n",
      "Progress: 85.3% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291873 -0.14034432]\n",
      "gradient\t[-5.10171542e-09  9.84241828e-09]\n",
      "weight after\t[-0.84291873 -0.14034431]\n",
      "Progress: 85.4% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291873 -0.14034431]\n",
      "gradient\t[-7.47200551e-09  9.94207538e-09]\n",
      "weight after\t[-0.84291874 -0.1403443 ]\n",
      "Progress: 85.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291874 -0.1403443 ]\n",
      "gradient\t[-7.16738801e-09  7.01728537e-08]\n",
      "weight after\t[-0.84291875 -0.14034423]\n",
      "Progress: 85.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291875 -0.14034423]\n",
      "gradient\t[-2.47002732e-08  5.43246427e-08]\n",
      "weight after\t[-0.84291877 -0.14034418]\n",
      "Progress: 85.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291877 -0.14034418]\n",
      "gradient\t[-1.22819638e-08  3.70522778e-08]\n",
      "weight after\t[-0.84291878 -0.14034414]\n",
      "Progress: 85.6% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291878 -0.14034414]\n",
      "gradient\t[-3.53110426e-09  2.51847820e-08]\n",
      "weight after\t[-0.84291879 -0.14034411]\n",
      "Progress: 85.7% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291879 -0.14034411]\n",
      "gradient\t[-2.83404487e-09  4.02538358e-09]\n",
      "weight after\t[-0.84291879 -0.14034411]\n",
      "Progress: 85.7% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291879 -0.14034411]\n",
      "gradient\t[-3.28749789e-09  6.90653325e-09]\n",
      "weight after\t[-0.84291879 -0.1403441 ]\n",
      "Progress: 85.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291879 -0.1403441 ]\n",
      "gradient\t[-2.30402767e-08  1.55538806e-07]\n",
      "weight after\t[-0.84291882 -0.14034395]\n",
      "Progress: 85.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291882 -0.14034395]\n",
      "gradient\t[-1.79126652e-08  4.49649915e-08]\n",
      "weight after\t[-0.84291884 -0.1403439 ]\n",
      "Progress: 85.8% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291884 -0.1403439 ]\n",
      "gradient\t[-2.48630734e-09  2.17237484e-08]\n",
      "weight after\t[-0.84291884 -0.14034388]\n",
      "Progress: 85.9% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291884 -0.14034388]\n",
      "gradient\t[-4.07054459e-08  7.21650856e-08]\n",
      "weight after\t[-0.84291888 -0.14034381]\n",
      "Progress: 86.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291888 -0.14034381]\n",
      "gradient\t[-1.26712861e-08  3.65817243e-08]\n",
      "weight after\t[-0.84291889 -0.14034377]\n",
      "Progress: 86.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291889 -0.14034377]\n",
      "gradient\t[-4.28897945e-08  1.91613251e-07]\n",
      "weight after\t[-0.84291893 -0.14034358]\n",
      "Progress: 86.0% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291893 -0.14034358]\n",
      "gradient\t[-2.51105830e-08  9.26088136e-08]\n",
      "weight after\t[-0.84291896 -0.14034349]\n",
      "Progress: 86.1% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291896 -0.14034349]\n",
      "gradient\t[-1.30566739e-08  9.40811054e-08]\n",
      "weight after\t[-0.84291897 -0.14034339]\n",
      "Progress: 86.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291897 -0.14034339]\n",
      "gradient\t[-4.63097744e-09  5.05961910e-09]\n",
      "weight after\t[-0.84291898 -0.14034339]\n",
      "Progress: 86.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291898 -0.14034339]\n",
      "gradient\t[-1.96160835e-08  3.79432752e-08]\n",
      "weight after\t[-0.842919   -0.14034335]\n",
      "Progress: 86.2% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.842919   -0.14034335]\n",
      "gradient\t[-2.72656757e-08  4.74343135e-08]\n",
      "weight after\t[-0.84291902 -0.1403433 ]\n",
      "Progress: 86.3% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291902 -0.1403433 ]\n",
      "gradient\t[-9.17694389e-09  1.27189847e-08]\n",
      "weight after\t[-0.84291903 -0.14034329]\n",
      "Progress: 86.3% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291903 -0.14034329]\n",
      "gradient\t[-1.35274852e-08  5.19631518e-08]\n",
      "weight after\t[-0.84291905 -0.14034324]\n",
      "Progress: 86.4% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291905 -0.14034324]\n",
      "gradient\t[-1.38885146e-08  3.06367407e-08]\n",
      "weight after\t[-0.84291906 -0.14034321]\n",
      "Progress: 86.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291906 -0.14034321]\n",
      "gradient\t[-1.95165670e-08  8.50060189e-08]\n",
      "weight after\t[-0.84291908 -0.14034312]\n",
      "Progress: 86.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291908 -0.14034312]\n",
      "gradient\t[-2.36781535e-08  5.08919826e-08]\n",
      "weight after\t[-0.8429191  -0.14034307]\n",
      "Progress: 86.5% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429191  -0.14034307]\n",
      "gradient\t[-2.92250478e-08  3.25228425e-08]\n",
      "weight after\t[-0.84291913 -0.14034304]\n",
      "Progress: 86.6% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291913 -0.14034304]\n",
      "gradient\t[-1.96298637e-08  2.21825140e-08]\n",
      "weight after\t[-0.84291915 -0.14034302]\n",
      "Progress: 86.7% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291915 -0.14034302]\n",
      "gradient\t[-1.65561282e-08  2.30560140e-08]\n",
      "weight after\t[-0.84291917 -0.14034299]\n",
      "Progress: 86.7% ... Training loss: 0.490 ... Validation loss: 0.488 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291917 -0.14034299]\n",
      "gradient\t[-2.90985005e-08  5.21514944e-08]\n",
      "weight after\t[-0.8429192  -0.14034294]\n",
      "Progress: 86.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429192  -0.14034294]\n",
      "gradient\t[-8.04341494e-09  2.60589465e-08]\n",
      "weight after\t[-0.84291921 -0.14034292]\n",
      "Progress: 86.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291921 -0.14034292]\n",
      "gradient\t[-1.76749080e-08  3.70627617e-08]\n",
      "weight after\t[-0.84291922 -0.14034288]\n",
      "Progress: 86.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291922 -0.14034288]\n",
      "gradient\t[-8.19614308e-09  2.76811812e-08]\n",
      "weight after\t[-0.84291923 -0.14034285]\n",
      "Progress: 86.9% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291923 -0.14034285]\n",
      "gradient\t[-1.98484863e-08  2.19025312e-07]\n",
      "weight after\t[-0.84291925 -0.14034263]\n",
      "Progress: 87.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291925 -0.14034263]\n",
      "gradient\t[-2.28548156e-09  2.29012731e-08]\n",
      "weight after\t[-0.84291925 -0.14034261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 87.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291925 -0.14034261]\n",
      "gradient\t[-4.27222251e-09  6.47440657e-09]\n",
      "weight after\t[-0.84291926 -0.1403426 ]\n",
      "Progress: 87.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291926 -0.1403426 ]\n",
      "gradient\t[-3.96904661e-09  8.44424146e-09]\n",
      "weight after\t[-0.84291926 -0.14034259]\n",
      "Progress: 87.1% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291926 -0.14034259]\n",
      "gradient\t[-3.56746571e-08  4.94502531e-08]\n",
      "weight after\t[-0.8429193  -0.14034255]\n",
      "Progress: 87.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429193  -0.14034255]\n",
      "gradient\t[-7.98556740e-09  2.60587775e-08]\n",
      "weight after\t[-0.84291931 -0.14034252]\n",
      "Progress: 87.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291931 -0.14034252]\n",
      "gradient\t[-1.21431041e-08  3.74331275e-08]\n",
      "weight after\t[-0.84291932 -0.14034248]\n",
      "Progress: 87.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291932 -0.14034248]\n",
      "gradient\t[-2.49372216e-09  2.08196216e-08]\n",
      "weight after\t[-0.84291932 -0.14034246]\n",
      "Progress: 87.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291932 -0.14034246]\n",
      "gradient\t[-3.81857022e-08  6.79363840e-08]\n",
      "weight after\t[-0.84291936 -0.14034239]\n",
      "Progress: 87.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291936 -0.14034239]\n",
      "gradient\t[-1.50403512e-08  1.41424608e-08]\n",
      "weight after\t[-0.84291937 -0.14034238]\n",
      "Progress: 87.4% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291937 -0.14034238]\n",
      "gradient\t[-2.43217183e-08  3.51201960e-08]\n",
      "weight after\t[-0.8429194  -0.14034234]\n",
      "Progress: 87.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429194  -0.14034234]\n",
      "gradient\t[-4.01303461e-08  7.13555282e-08]\n",
      "weight after\t[-0.84291944 -0.14034227]\n",
      "Progress: 87.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291944 -0.14034227]\n",
      "gradient\t[-6.70782586e-10  5.65079048e-11]\n",
      "weight after\t[-0.84291944 -0.14034227]\n",
      "Progress: 87.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291944 -0.14034227]\n",
      "gradient\t[-1.05862504e-08  1.56313688e-08]\n",
      "weight after\t[-0.84291945 -0.14034226]\n",
      "Progress: 87.6% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291945 -0.14034226]\n",
      "gradient\t[-1.06822810e-08  1.14847808e-08]\n",
      "weight after\t[-0.84291946 -0.14034225]\n",
      "Progress: 87.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291946 -0.14034225]\n",
      "gradient\t[-2.39861920e-09  3.73670091e-09]\n",
      "weight after\t[-0.84291946 -0.14034224]\n",
      "Progress: 87.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291946 -0.14034224]\n",
      "gradient\t[-3.22760824e-08  4.86449805e-08]\n",
      "weight after\t[-0.84291949 -0.14034219]\n",
      "Progress: 87.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291949 -0.14034219]\n",
      "gradient\t[-2.83554363e-09  3.62777884e-09]\n",
      "weight after\t[-0.8429195  -0.14034219]\n",
      "Progress: 87.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429195  -0.14034219]\n",
      "gradient\t[-4.24798113e-08  6.26616373e-08]\n",
      "weight after\t[-0.84291954 -0.14034213]\n",
      "Progress: 87.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291954 -0.14034213]\n",
      "gradient\t[-7.63204728e-09  4.34095679e-08]\n",
      "weight after\t[-0.84291955 -0.14034208]\n",
      "Progress: 87.9% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291955 -0.14034208]\n",
      "gradient\t[-2.63469733e-08  3.77707478e-08]\n",
      "weight after\t[-0.84291957 -0.14034205]\n",
      "Progress: 88.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291957 -0.14034205]\n",
      "gradient\t[-8.48245493e-10  5.77208328e-08]\n",
      "weight after\t[-0.84291957 -0.14034199]\n",
      "Progress: 88.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291957 -0.14034199]\n",
      "gradient\t[-2.25597165e-08  2.74230006e-08]\n",
      "weight after\t[-0.8429196  -0.14034196]\n",
      "Progress: 88.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429196  -0.14034196]\n",
      "gradient\t[-1.80328714e-08  2.80231259e-08]\n",
      "weight after\t[-0.84291962 -0.14034193]\n",
      "Progress: 88.1% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291962 -0.14034193]\n",
      "gradient\t[-1.98214146e-08  2.72371535e-08]\n",
      "weight after\t[-0.84291964 -0.14034191]\n",
      "Progress: 88.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291964 -0.14034191]\n",
      "gradient\t[-6.03417931e-09  1.16002369e-08]\n",
      "weight after\t[-0.84291964 -0.14034189]\n",
      "Progress: 88.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291964 -0.14034189]\n",
      "gradient\t[-1.98003109e-08  8.27294647e-08]\n",
      "weight after\t[-0.84291966 -0.14034181]\n",
      "Progress: 88.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291966 -0.14034181]\n",
      "gradient\t[-3.43181427e-08  6.63698319e-08]\n",
      "weight after\t[-0.8429197  -0.14034174]\n",
      "Progress: 88.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429197  -0.14034174]\n",
      "gradient\t[-8.22428141e-09  2.57020140e-08]\n",
      "weight after\t[-0.8429197  -0.14034172]\n",
      "Progress: 88.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429197  -0.14034172]\n",
      "gradient\t[-1.90168086e-08  4.52159416e-08]\n",
      "weight after\t[-0.84291972 -0.14034167]\n",
      "Progress: 88.4% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291972 -0.14034167]\n",
      "gradient\t[-2.43397388e-09  2.53027310e-09]\n",
      "weight after\t[-0.84291973 -0.14034167]\n",
      "Progress: 88.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291973 -0.14034167]\n",
      "gradient\t[-1.30047972e-08  1.57044025e-08]\n",
      "weight after\t[-0.84291974 -0.14034166]\n",
      "Progress: 88.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291974 -0.14034166]\n",
      "gradient\t[-2.23878214e-08  3.02164396e-08]\n",
      "weight after\t[-0.84291976 -0.14034163]\n",
      "Progress: 88.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291976 -0.14034163]\n",
      "gradient\t[-8.58051484e-09  1.24007292e-08]\n",
      "weight after\t[-0.84291977 -0.14034161]\n",
      "Progress: 88.6% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291977 -0.14034161]\n",
      "gradient\t[-3.09603957e-09  3.64375391e-09]\n",
      "weight after\t[-0.84291977 -0.14034161]\n",
      "Progress: 88.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291977 -0.14034161]\n",
      "gradient\t[-2.50452197e-08  3.39846357e-08]\n",
      "weight after\t[-0.8429198  -0.14034158]\n",
      "Progress: 88.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429198  -0.14034158]\n",
      "gradient\t[-1.72952235e-09  7.49993231e-08]\n",
      "weight after\t[-0.8429198 -0.1403415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 88.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429198 -0.1403415]\n",
      "gradient\t[-3.62828814e-08  1.03250589e-07]\n",
      "weight after\t[-0.84291984 -0.1403414 ]\n",
      "Progress: 88.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291984 -0.1403414 ]\n",
      "gradient\t[-1.65300620e-08  3.24927274e-08]\n",
      "weight after\t[-0.84291985 -0.14034136]\n",
      "Progress: 88.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291985 -0.14034136]\n",
      "gradient\t[-1.76314764e-08  9.13167720e-08]\n",
      "weight after\t[-0.84291987 -0.14034127]\n",
      "Progress: 88.9% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291987 -0.14034127]\n",
      "gradient\t[-2.16353937e-08  2.40319050e-08]\n",
      "weight after\t[-0.84291989 -0.14034125]\n",
      "Progress: 89.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291989 -0.14034125]\n",
      "gradient\t[-6.61175109e-09  7.60878210e-09]\n",
      "weight after\t[-0.8429199  -0.14034124]\n",
      "Progress: 89.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429199  -0.14034124]\n",
      "gradient\t[-2.08211534e-09  4.07503984e-09]\n",
      "weight after\t[-0.8429199  -0.14034124]\n",
      "Progress: 89.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429199  -0.14034124]\n",
      "gradient\t[-6.64757046e-09  1.48879183e-08]\n",
      "weight after\t[-0.84291991 -0.14034122]\n",
      "Progress: 89.1% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291991 -0.14034122]\n",
      "gradient\t[-2.18283246e-09  2.48580431e-09]\n",
      "weight after\t[-0.84291991 -0.14034122]\n",
      "Progress: 89.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291991 -0.14034122]\n",
      "gradient\t[-2.31480714e-08  6.23937943e-08]\n",
      "weight after\t[-0.84291993 -0.14034116]\n",
      "Progress: 89.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291993 -0.14034116]\n",
      "gradient\t[-2.13515661e-08  1.13799727e-07]\n",
      "weight after\t[-0.84291995 -0.14034104]\n",
      "Progress: 89.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291995 -0.14034104]\n",
      "gradient\t[-7.55166829e-10  3.59824312e-10]\n",
      "weight after\t[-0.84291995 -0.14034104]\n",
      "Progress: 89.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291995 -0.14034104]\n",
      "gradient\t[-8.30057028e-09  2.80424015e-08]\n",
      "weight after\t[-0.84291996 -0.14034102]\n",
      "Progress: 89.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291996 -0.14034102]\n",
      "gradient\t[-2.60750177e-08  1.03470285e-07]\n",
      "weight after\t[-0.84291999 -0.14034091]\n",
      "Progress: 89.4% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291999 -0.14034091]\n",
      "gradient\t[-1.57643238e-10  2.46468139e-12]\n",
      "weight after\t[-0.84291999 -0.14034091]\n",
      "Progress: 89.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84291999 -0.14034091]\n",
      "gradient\t[-2.60745500e-08  4.84707083e-08]\n",
      "weight after\t[-0.84292001 -0.14034086]\n",
      "Progress: 89.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292001 -0.14034086]\n",
      "gradient\t[-3.31132227e-08  4.36731887e-08]\n",
      "weight after\t[-0.84292005 -0.14034082]\n",
      "Progress: 89.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292005 -0.14034082]\n",
      "gradient\t[-1.31741893e-08  8.92934608e-08]\n",
      "weight after\t[-0.84292006 -0.14034073]\n",
      "Progress: 89.6% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292006 -0.14034073]\n",
      "gradient\t[-1.84545262e-08  2.39669258e-08]\n",
      "weight after\t[-0.84292008 -0.14034071]\n",
      "Progress: 89.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292008 -0.14034071]\n",
      "gradient\t[-1.67241239e-08  7.02743207e-08]\n",
      "weight after\t[-0.8429201  -0.14034064]\n",
      "Progress: 89.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429201  -0.14034064]\n",
      "gradient\t[-9.12560699e-09  9.49133194e-09]\n",
      "weight after\t[-0.84292011 -0.14034063]\n",
      "Progress: 89.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292011 -0.14034063]\n",
      "gradient\t[-1.01657612e-08  3.04272643e-08]\n",
      "weight after\t[-0.84292012 -0.1403406 ]\n",
      "Progress: 89.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292012 -0.1403406 ]\n",
      "gradient\t[-3.36678302e-08  9.76294132e-08]\n",
      "weight after\t[-0.84292015 -0.1403405 ]\n",
      "Progress: 89.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292015 -0.1403405 ]\n",
      "gradient\t[-1.21840815e-09  5.71304503e-08]\n",
      "weight after\t[-0.84292015 -0.14034044]\n",
      "Progress: 89.9% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292015 -0.14034044]\n",
      "gradient\t[-1.56416853e-09  1.95722106e-08]\n",
      "weight after\t[-0.84292015 -0.14034042]\n",
      "Progress: 90.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292015 -0.14034042]\n",
      "gradient\t[-1.98068673e-08  4.51784102e-08]\n",
      "weight after\t[-0.84292017 -0.14034038]\n",
      "Progress: 90.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292017 -0.14034038]\n",
      "gradient\t[-1.07177070e-08  1.00094644e-08]\n",
      "weight after\t[-0.84292018 -0.14034037]\n",
      "Progress: 90.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292018 -0.14034037]\n",
      "gradient\t[-8.22669460e-09  1.09963608e-08]\n",
      "weight after\t[-0.84292019 -0.14034036]\n",
      "Progress: 90.1% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292019 -0.14034036]\n",
      "gradient\t[-3.01482023e-08  2.97439625e-08]\n",
      "weight after\t[-0.84292022 -0.14034033]\n",
      "Progress: 90.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292022 -0.14034033]\n",
      "gradient\t[-2.08922917e-08  1.15244546e-07]\n",
      "weight after\t[-0.84292024 -0.14034021]\n",
      "Progress: 90.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292024 -0.14034021]\n",
      "gradient\t[-6.02558361e-09  6.03388882e-09]\n",
      "weight after\t[-0.84292025 -0.1403402 ]\n",
      "Progress: 90.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292025 -0.1403402 ]\n",
      "gradient\t[-1.66036742e-08  2.61041603e-08]\n",
      "weight after\t[-0.84292026 -0.14034018]\n",
      "Progress: 90.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292026 -0.14034018]\n",
      "gradient\t[-2.09462691e-08  1.07991780e-07]\n",
      "weight after\t[-0.84292029 -0.14034007]\n",
      "Progress: 90.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292029 -0.14034007]\n",
      "gradient\t[-1.64631952e-08  2.38394502e-08]\n",
      "weight after\t[-0.8429203  -0.14034005]\n",
      "Progress: 90.4% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429203  -0.14034005]\n",
      "gradient\t[-2.08678132e-09  1.83843147e-08]\n",
      "weight after\t[-0.8429203  -0.14034003]\n",
      "Progress: 90.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429203  -0.14034003]\n",
      "gradient\t[-2.48271384e-08  3.06361240e-08]\n",
      "weight after\t[-0.84292033 -0.14034   ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 90.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292033 -0.14034   ]\n",
      "gradient\t[-2.62069117e-08  7.01991832e-08]\n",
      "weight after\t[-0.84292035 -0.14033993]\n",
      "Progress: 90.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292035 -0.14033993]\n",
      "gradient\t[-2.61068759e-08  1.61181831e-07]\n",
      "weight after\t[-0.84292038 -0.14033977]\n",
      "Progress: 90.6% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292038 -0.14033977]\n",
      "gradient\t[-1.61390525e-08  2.31178875e-08]\n",
      "weight after\t[-0.8429204  -0.14033974]\n",
      "Progress: 90.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429204  -0.14033974]\n",
      "gradient\t[-3.62790137e-08  3.96966903e-08]\n",
      "weight after\t[-0.84292043 -0.1403397 ]\n",
      "Progress: 90.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292043 -0.1403397 ]\n",
      "gradient\t[-1.73402724e-08  2.07185176e-08]\n",
      "weight after\t[-0.84292045 -0.14033968]\n",
      "Progress: 90.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292045 -0.14033968]\n",
      "gradient\t[-1.44777143e-09  1.79308134e-08]\n",
      "weight after\t[-0.84292045 -0.14033966]\n",
      "Progress: 90.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292045 -0.14033966]\n",
      "gradient\t[-2.58956469e-10  3.81755777e-11]\n",
      "weight after\t[-0.84292045 -0.14033966]\n",
      "Progress: 90.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292045 -0.14033966]\n",
      "gradient\t[-1.43426333e-08  3.29234769e-08]\n",
      "weight after\t[-0.84292047 -0.14033963]\n",
      "Progress: 90.9% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292047 -0.14033963]\n",
      "gradient\t[-1.19162026e-08  1.57199907e-08]\n",
      "weight after\t[-0.84292048 -0.14033962]\n",
      "Progress: 91.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292048 -0.14033962]\n",
      "gradient\t[-5.21886121e-08  7.09023116e-08]\n",
      "weight after\t[-0.84292053 -0.14033955]\n",
      "Progress: 91.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292053 -0.14033955]\n",
      "gradient\t[-2.40112452e-08  5.02548084e-08]\n",
      "weight after\t[-0.84292055 -0.1403395 ]\n",
      "Progress: 91.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292055 -0.1403395 ]\n",
      "gradient\t[-2.64331766e-08  3.68363043e-08]\n",
      "weight after\t[-0.84292058 -0.14033946]\n",
      "Progress: 91.1% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292058 -0.14033946]\n",
      "gradient\t[-2.58929882e-08  4.71660011e-08]\n",
      "weight after\t[-0.84292061 -0.14033941]\n",
      "Progress: 91.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292061 -0.14033941]\n",
      "gradient\t[-1.47689806e-09  1.44961020e-09]\n",
      "weight after\t[-0.84292061 -0.14033941]\n",
      "Progress: 91.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292061 -0.14033941]\n",
      "gradient\t[-1.80268625e-09  5.52037183e-09]\n",
      "weight after\t[-0.84292061 -0.1403394 ]\n",
      "Progress: 91.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292061 -0.1403394 ]\n",
      "gradient\t[-1.63472104e-08  3.70066347e-08]\n",
      "weight after\t[-0.84292063 -0.14033937]\n",
      "Progress: 91.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292063 -0.14033937]\n",
      "gradient\t[-1.63019179e-08  2.28974021e-08]\n",
      "weight after\t[-0.84292064 -0.14033934]\n",
      "Progress: 91.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292064 -0.14033934]\n",
      "gradient\t[-4.45159586e-09  5.70642449e-09]\n",
      "weight after\t[-0.84292065 -0.14033934]\n",
      "Progress: 91.4% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292065 -0.14033934]\n",
      "gradient\t[-1.25516994e-08  3.02834053e-08]\n",
      "weight after\t[-0.84292066 -0.14033931]\n",
      "Progress: 91.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292066 -0.14033931]\n",
      "gradient\t[-2.22920302e-09  4.08710495e-09]\n",
      "weight after\t[-0.84292066 -0.1403393 ]\n",
      "Progress: 91.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292066 -0.1403393 ]\n",
      "gradient\t[-5.65505876e-09  5.66099778e-09]\n",
      "weight after\t[-0.84292067 -0.1403393 ]\n",
      "Progress: 91.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292067 -0.1403393 ]\n",
      "gradient\t[-3.01843429e-09  1.11021786e-07]\n",
      "weight after\t[-0.84292067 -0.14033919]\n",
      "Progress: 91.6% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292067 -0.14033919]\n",
      "gradient\t[-2.39122746e-08  2.30457250e-08]\n",
      "weight after\t[-0.84292069 -0.14033916]\n",
      "Progress: 91.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292069 -0.14033916]\n",
      "gradient\t[-6.73119903e-09  1.00658085e-08]\n",
      "weight after\t[-0.8429207  -0.14033915]\n",
      "Progress: 91.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429207  -0.14033915]\n",
      "gradient\t[-5.82791534e-08  1.57696136e-07]\n",
      "weight after\t[-0.84292076 -0.140339  ]\n",
      "Progress: 91.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292076 -0.140339  ]\n",
      "gradient\t[-1.42469693e-08  3.28236334e-08]\n",
      "weight after\t[-0.84292077 -0.14033896]\n",
      "Progress: 91.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292077 -0.14033896]\n",
      "gradient\t[-9.86507969e-09  9.45302194e-09]\n",
      "weight after\t[-0.84292078 -0.14033895]\n",
      "Progress: 91.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292078 -0.14033895]\n",
      "gradient\t[-2.04864969e-08  2.80020321e-08]\n",
      "weight after\t[-0.8429208  -0.14033893]\n",
      "Progress: 91.9% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429208  -0.14033893]\n",
      "gradient\t[-3.36231063e-08  5.21123957e-08]\n",
      "weight after\t[-0.84292084 -0.14033887]\n",
      "Progress: 92.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292084 -0.14033887]\n",
      "gradient\t[-8.53232927e-09  1.06192151e-08]\n",
      "weight after\t[-0.84292085 -0.14033886]\n",
      "Progress: 92.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292085 -0.14033886]\n",
      "gradient\t[-1.13980477e-08  7.94171385e-08]\n",
      "weight after\t[-0.84292086 -0.14033878]\n",
      "Progress: 92.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292086 -0.14033878]\n",
      "gradient\t[-1.86671415e-08  2.24325301e-08]\n",
      "weight after\t[-0.84292088 -0.14033876]\n",
      "Progress: 92.1% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292088 -0.14033876]\n",
      "gradient\t[-1.77557645e-08  3.62977132e-08]\n",
      "weight after\t[-0.84292089 -0.14033873]\n",
      "Progress: 92.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292089 -0.14033873]\n",
      "gradient\t[-1.59717658e-08  2.25225736e-08]\n",
      "weight after\t[-0.84292091 -0.1403387 ]\n",
      "Progress: 92.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292091 -0.1403387 ]\n",
      "gradient\t[-2.62705127e-08  4.93484041e-08]\n",
      "weight after\t[-0.84292094 -0.14033865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 92.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292094 -0.14033865]\n",
      "gradient\t[-2.91853778e-09  2.76656276e-09]\n",
      "weight after\t[-0.84292094 -0.14033865]\n",
      "Progress: 92.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292094 -0.14033865]\n",
      "gradient\t[-2.84586079e-08  4.91067801e-08]\n",
      "weight after\t[-0.84292097 -0.1403386 ]\n",
      "Progress: 92.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292097 -0.1403386 ]\n",
      "gradient\t[-5.91781962e-08  7.61311426e-08]\n",
      "weight after\t[-0.84292103 -0.14033853]\n",
      "Progress: 92.4% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292103 -0.14033853]\n",
      "gradient\t[-8.19419004e-09  1.01381535e-08]\n",
      "weight after\t[-0.84292104 -0.14033852]\n",
      "Progress: 92.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292104 -0.14033852]\n",
      "gradient\t[-1.02267345e-08  7.79120199e-08]\n",
      "weight after\t[-0.84292105 -0.14033844]\n",
      "Progress: 92.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292105 -0.14033844]\n",
      "gradient\t[-1.67229390e-08  2.23930622e-08]\n",
      "weight after\t[-0.84292106 -0.14033842]\n",
      "Progress: 92.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292106 -0.14033842]\n",
      "gradient\t[-1.92458145e-08  5.43518020e-08]\n",
      "weight after\t[-0.84292108 -0.14033836]\n",
      "Progress: 92.6% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292108 -0.14033836]\n",
      "gradient\t[-2.52502774e-08  4.90586116e-08]\n",
      "weight after\t[-0.84292111 -0.14033831]\n",
      "Progress: 92.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292111 -0.14033831]\n",
      "gradient\t[-7.36465100e-08  9.55748452e-08]\n",
      "weight after\t[-0.84292118 -0.14033822]\n",
      "Progress: 92.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292118 -0.14033822]\n",
      "gradient\t[-1.29053443e-09  5.17734654e-08]\n",
      "weight after\t[-0.84292118 -0.14033816]\n",
      "Progress: 92.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292118 -0.14033816]\n",
      "gradient\t[-4.31163764e-10  1.93670668e-11]\n",
      "weight after\t[-0.84292118 -0.14033816]\n",
      "Progress: 92.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292118 -0.14033816]\n",
      "gradient\t[-3.07947260e-09  5.00851486e-09]\n",
      "weight after\t[-0.84292119 -0.14033816]\n",
      "Progress: 92.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292119 -0.14033816]\n",
      "gradient\t[-1.07539965e-09  5.19623414e-08]\n",
      "weight after\t[-0.84292119 -0.14033811]\n",
      "Progress: 92.9% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292119 -0.14033811]\n",
      "gradient\t[-3.13147761e-08  5.47267021e-08]\n",
      "weight after\t[-0.84292122 -0.14033805]\n",
      "Progress: 93.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292122 -0.14033805]\n",
      "gradient\t[-1.35418379e-09  1.50090836e-09]\n",
      "weight after\t[-0.84292122 -0.14033805]\n",
      "Progress: 93.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292122 -0.14033805]\n",
      "gradient\t[-2.23581195e-08  2.84051976e-08]\n",
      "weight after\t[-0.84292124 -0.14033802]\n",
      "Progress: 93.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292124 -0.14033802]\n",
      "gradient\t[-1.82685873e-08  2.23828312e-08]\n",
      "weight after\t[-0.84292126 -0.140338  ]\n",
      "Progress: 93.1% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292126 -0.140338  ]\n",
      "gradient\t[-2.45673847e-08  7.71935926e-08]\n",
      "weight after\t[-0.84292128 -0.14033792]\n",
      "Progress: 93.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292128 -0.14033792]\n",
      "gradient\t[-1.05652810e-08  1.74172252e-08]\n",
      "weight after\t[-0.84292129 -0.14033791]\n",
      "Progress: 93.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292129 -0.14033791]\n",
      "gradient\t[-3.36585246e-08  7.31736499e-08]\n",
      "weight after\t[-0.84292133 -0.14033783]\n",
      "Progress: 93.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292133 -0.14033783]\n",
      "gradient\t[-1.25060720e-08  3.50217373e-08]\n",
      "weight after\t[-0.84292134 -0.1403378 ]\n",
      "Progress: 93.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292134 -0.1403378 ]\n",
      "gradient\t[-3.49823206e-08  4.30646964e-08]\n",
      "weight after\t[-0.84292138 -0.14033775]\n",
      "Progress: 93.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292138 -0.14033775]\n",
      "gradient\t[-3.68868821e-08  7.52572714e-08]\n",
      "weight after\t[-0.84292141 -0.14033768]\n",
      "Progress: 93.4% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292141 -0.14033768]\n",
      "gradient\t[-1.52747878e-08  3.00362013e-08]\n",
      "weight after\t[-0.84292143 -0.14033765]\n",
      "Progress: 93.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292143 -0.14033765]\n",
      "gradient\t[-2.07654579e-08  2.45413791e-08]\n",
      "weight after\t[-0.84292145 -0.14033762]\n",
      "Progress: 93.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292145 -0.14033762]\n",
      "gradient\t[-4.81881625e-08  6.61707376e-08]\n",
      "weight after\t[-0.8429215  -0.14033756]\n",
      "Progress: 93.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429215  -0.14033756]\n",
      "gradient\t[-8.04878996e-09  9.97228916e-09]\n",
      "weight after\t[-0.84292151 -0.14033755]\n",
      "Progress: 93.6% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292151 -0.14033755]\n",
      "gradient\t[-8.74396284e-10  3.27950515e-10]\n",
      "weight after\t[-0.84292151 -0.14033755]\n",
      "Progress: 93.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292151 -0.14033755]\n",
      "gradient\t[-3.12551564e-08  4.18240695e-08]\n",
      "weight after\t[-0.84292154 -0.14033751]\n",
      "Progress: 93.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292154 -0.14033751]\n",
      "gradient\t[-9.80356960e-09  1.36373972e-08]\n",
      "weight after\t[-0.84292155 -0.14033749]\n",
      "Progress: 93.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292155 -0.14033749]\n",
      "gradient\t[-8.95547858e-09  8.91752887e-09]\n",
      "weight after\t[-0.84292156 -0.14033748]\n",
      "Progress: 93.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292156 -0.14033748]\n",
      "gradient\t[-1.58025761e-08  2.16985346e-08]\n",
      "weight after\t[-0.84292157 -0.14033746]\n",
      "Progress: 93.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292157 -0.14033746]\n",
      "gradient\t[-6.27681841e-09  7.87095760e-09]\n",
      "weight after\t[-0.84292158 -0.14033745]\n",
      "Progress: 93.9% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292158 -0.14033745]\n",
      "gradient\t[-3.31888874e-08  5.69253054e-08]\n",
      "weight after\t[-0.84292161 -0.1403374 ]\n",
      "Progress: 94.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292161 -0.1403374 ]\n",
      "gradient\t[-2.50038907e-08  3.51299694e-08]\n",
      "weight after\t[-0.84292164 -0.14033736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 94.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292164 -0.14033736]\n",
      "gradient\t[-1.84323793e-08  3.60808866e-08]\n",
      "weight after\t[-0.84292165 -0.14033733]\n",
      "Progress: 94.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292165 -0.14033733]\n",
      "gradient\t[-8.85590398e-09  7.36506980e-09]\n",
      "weight after\t[-0.84292166 -0.14033732]\n",
      "Progress: 94.1% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292166 -0.14033732]\n",
      "gradient\t[-3.48796253e-09  4.29001524e-09]\n",
      "weight after\t[-0.84292167 -0.14033731]\n",
      "Progress: 94.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292167 -0.14033731]\n",
      "gradient\t[-1.33387266e-08  3.05390119e-08]\n",
      "weight after\t[-0.84292168 -0.14033728]\n",
      "Progress: 94.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292168 -0.14033728]\n",
      "gradient\t[-6.25642879e-10  5.72668825e-10]\n",
      "weight after\t[-0.84292168 -0.14033728]\n",
      "Progress: 94.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292168 -0.14033728]\n",
      "gradient\t[-2.53570988e-08  7.67069464e-08]\n",
      "weight after\t[-0.84292171 -0.14033721]\n",
      "Progress: 94.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292171 -0.14033721]\n",
      "gradient\t[-2.64381760e-09  5.36369442e-08]\n",
      "weight after\t[-0.84292171 -0.14033715]\n",
      "Progress: 94.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292171 -0.14033715]\n",
      "gradient\t[-1.30202668e-08  1.26099075e-08]\n",
      "weight after\t[-0.84292172 -0.14033714]\n",
      "Progress: 94.4% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292172 -0.14033714]\n",
      "gradient\t[-9.17046953e-09  6.26288851e-08]\n",
      "weight after\t[-0.84292173 -0.14033708]\n",
      "Progress: 94.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292173 -0.14033708]\n",
      "gradient\t[-4.35497783e-08  7.40020321e-08]\n",
      "weight after\t[-0.84292177 -0.140337  ]\n",
      "Progress: 94.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292177 -0.140337  ]\n",
      "gradient\t[-4.46504000e-09  3.61658144e-09]\n",
      "weight after\t[-0.84292178 -0.140337  ]\n",
      "Progress: 94.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292178 -0.140337  ]\n",
      "gradient\t[-1.94480737e-08  2.18732853e-08]\n",
      "weight after\t[-0.8429218  -0.14033698]\n",
      "Progress: 94.6% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429218  -0.14033698]\n",
      "gradient\t[-9.41601209e-09  6.21364751e-08]\n",
      "weight after\t[-0.84292181 -0.14033692]\n",
      "Progress: 94.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292181 -0.14033692]\n",
      "gradient\t[-1.80404322e-08  1.55918186e-08]\n",
      "weight after\t[-0.84292183 -0.1403369 ]\n",
      "Progress: 94.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292183 -0.1403369 ]\n",
      "gradient\t[-5.55897251e-09  1.99563268e-08]\n",
      "weight after\t[-0.84292183 -0.14033688]\n",
      "Progress: 94.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292183 -0.14033688]\n",
      "gradient\t[-2.53179663e-09  2.25743316e-09]\n",
      "weight after\t[-0.84292183 -0.14033688]\n",
      "Progress: 94.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292183 -0.14033688]\n",
      "gradient\t[-2.05734959e-08  2.44439298e-08]\n",
      "weight after\t[-0.84292185 -0.14033685]\n",
      "Progress: 94.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292185 -0.14033685]\n",
      "gradient\t[-2.72503699e-08  6.28244295e-08]\n",
      "weight after\t[-0.84292188 -0.14033679]\n",
      "Progress: 94.9% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292188 -0.14033679]\n",
      "gradient\t[-1.59789095e-08  1.57185710e-08]\n",
      "weight after\t[-0.8429219  -0.14033678]\n",
      "Progress: 95.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429219  -0.14033678]\n",
      "gradient\t[-4.11187445e-08  7.83916372e-08]\n",
      "weight after\t[-0.84292194 -0.1403367 ]\n",
      "Progress: 95.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292194 -0.1403367 ]\n",
      "gradient\t[-2.66193477e-08  9.24902979e-08]\n",
      "weight after\t[-0.84292197 -0.1403366 ]\n",
      "Progress: 95.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292197 -0.1403366 ]\n",
      "gradient\t[-5.34973119e-09  6.74162977e-08]\n",
      "weight after\t[-0.84292197 -0.14033654]\n",
      "Progress: 95.1% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292197 -0.14033654]\n",
      "gradient\t[-1.84178171e-08  2.09556668e-08]\n",
      "weight after\t[-0.84292199 -0.14033652]\n",
      "Progress: 95.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292199 -0.14033652]\n",
      "gradient\t[-4.05562116e-09  5.67803566e-09]\n",
      "weight after\t[-0.84292199 -0.14033651]\n",
      "Progress: 95.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292199 -0.14033651]\n",
      "gradient\t[-4.35320452e-09  7.81229104e-09]\n",
      "weight after\t[-0.842922  -0.1403365]\n",
      "Progress: 95.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.842922  -0.1403365]\n",
      "gradient\t[-1.57739039e-08  2.11110476e-08]\n",
      "weight after\t[-0.84292201 -0.14033648]\n",
      "Progress: 95.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292201 -0.14033648]\n",
      "gradient\t[-1.73976992e-08  1.37881593e-08]\n",
      "weight after\t[-0.84292203 -0.14033647]\n",
      "Progress: 95.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292203 -0.14033647]\n",
      "gradient\t[-1.65711474e-08  6.98312144e-08]\n",
      "weight after\t[-0.84292205 -0.1403364 ]\n",
      "Progress: 95.4% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292205 -0.1403364 ]\n",
      "gradient\t[-1.08451012e-08  1.35793977e-08]\n",
      "weight after\t[-0.84292206 -0.14033638]\n",
      "Progress: 95.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292206 -0.14033638]\n",
      "gradient\t[-2.97326421e-09  5.83782952e-09]\n",
      "weight after\t[-0.84292206 -0.14033638]\n",
      "Progress: 95.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292206 -0.14033638]\n",
      "gradient\t[-2.47984104e-08  3.39248744e-08]\n",
      "weight after\t[-0.84292209 -0.14033634]\n",
      "Progress: 95.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292209 -0.14033634]\n",
      "gradient\t[-1.15105854e-08  2.70998857e-08]\n",
      "weight after\t[-0.8429221  -0.14033632]\n",
      "Progress: 95.6% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429221  -0.14033632]\n",
      "gradient\t[-6.00257733e-09  8.83192380e-09]\n",
      "weight after\t[-0.8429221  -0.14033631]\n",
      "Progress: 95.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429221  -0.14033631]\n",
      "gradient\t[-9.80665802e-09  1.16945517e-08]\n",
      "weight after\t[-0.84292211 -0.1403363 ]\n",
      "Progress: 95.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292211 -0.1403363 ]\n",
      "gradient\t[-1.80328854e-08  2.70648893e-08]\n",
      "weight after\t[-0.84292213 -0.14033627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 95.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292213 -0.14033627]\n",
      "gradient\t[-3.5013003e-08  5.7793734e-08]\n",
      "weight after\t[-0.84292217 -0.14033621]\n",
      "Progress: 95.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292217 -0.14033621]\n",
      "gradient\t[-8.39152678e-09  9.88049758e-09]\n",
      "weight after\t[-0.84292218 -0.1403362 ]\n",
      "Progress: 95.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292218 -0.1403362 ]\n",
      "gradient\t[-3.52212002e-08  5.08822986e-08]\n",
      "weight after\t[-0.84292221 -0.14033615]\n",
      "Progress: 95.9% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292221 -0.14033615]\n",
      "gradient\t[-2.00188132e-09  2.39806607e-09]\n",
      "weight after\t[-0.84292221 -0.14033615]\n",
      "Progress: 96.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292221 -0.14033615]\n",
      "gradient\t[-3.47837853e-08  4.20981629e-08]\n",
      "weight after\t[-0.84292225 -0.14033611]\n",
      "Progress: 96.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292225 -0.14033611]\n",
      "gradient\t[-3.16328450e-08  3.89889434e-08]\n",
      "weight after\t[-0.84292228 -0.14033607]\n",
      "Progress: 96.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292228 -0.14033607]\n",
      "gradient\t[-2.46925383e-09  4.45322041e-09]\n",
      "weight after\t[-0.84292228 -0.14033606]\n",
      "Progress: 96.1% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292228 -0.14033606]\n",
      "gradient\t[-6.23657214e-09  5.48330463e-08]\n",
      "weight after\t[-0.84292229 -0.14033601]\n",
      "Progress: 96.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292229 -0.14033601]\n",
      "gradient\t[-1.63706028e-09  3.47202077e-09]\n",
      "weight after\t[-0.84292229 -0.140336  ]\n",
      "Progress: 96.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292229 -0.140336  ]\n",
      "gradient\t[-3.45365657e-08  5.68515406e-08]\n",
      "weight after\t[-0.84292232 -0.14033595]\n",
      "Progress: 96.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292232 -0.14033595]\n",
      "gradient\t[-2.69807192e-08  3.02181071e-08]\n",
      "weight after\t[-0.84292235 -0.14033592]\n",
      "Progress: 96.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292235 -0.14033592]\n",
      "gradient\t[-2.76740727e-09  5.33488662e-08]\n",
      "weight after\t[-0.84292235 -0.14033586]\n",
      "Progress: 96.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292235 -0.14033586]\n",
      "gradient\t[-8.70774378e-09  1.05631598e-08]\n",
      "weight after\t[-0.84292236 -0.14033585]\n",
      "Progress: 96.4% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292236 -0.14033585]\n",
      "gradient\t[-2.75376414e-08  3.51862112e-08]\n",
      "weight after\t[-0.84292239 -0.14033582]\n",
      "Progress: 96.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292239 -0.14033582]\n",
      "gradient\t[-1.64335863e-08  4.93025498e-08]\n",
      "weight after\t[-0.84292241 -0.14033577]\n",
      "Progress: 96.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292241 -0.14033577]\n",
      "gradient\t[-1.62374593e-08  1.65813461e-08]\n",
      "weight after\t[-0.84292242 -0.14033575]\n",
      "Progress: 96.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292242 -0.14033575]\n",
      "gradient\t[-3.29475196e-08  4.95023921e-08]\n",
      "weight after\t[-0.84292246 -0.1403357 ]\n",
      "Progress: 96.6% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292246 -0.1403357 ]\n",
      "gradient\t[-1.99258272e-08  3.89437184e-08]\n",
      "weight after\t[-0.84292248 -0.14033566]\n",
      "Progress: 96.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292248 -0.14033566]\n",
      "gradient\t[-2.34996191e-08  2.67093762e-08]\n",
      "weight after\t[-0.8429225  -0.14033564]\n",
      "Progress: 96.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429225  -0.14033564]\n",
      "gradient\t[-1.58018546e-08  2.08248711e-08]\n",
      "weight after\t[-0.84292251 -0.14033562]\n",
      "Progress: 96.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292251 -0.14033562]\n",
      "gradient\t[-4.13923856e-09  4.99477062e-08]\n",
      "weight after\t[-0.84292252 -0.14033557]\n",
      "Progress: 96.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292252 -0.14033557]\n",
      "gradient\t[-3.15259256e-08  8.83354974e-08]\n",
      "weight after\t[-0.84292255 -0.14033548]\n",
      "Progress: 96.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292255 -0.14033548]\n",
      "gradient\t[-1.82912231e-08  2.38223095e-08]\n",
      "weight after\t[-0.84292257 -0.14033545]\n",
      "Progress: 96.9% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292257 -0.14033545]\n",
      "gradient\t[-7.76285352e-09  1.05938944e-08]\n",
      "weight after\t[-0.84292258 -0.14033544]\n",
      "Progress: 97.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292258 -0.14033544]\n",
      "gradient\t[-2.55588340e-08  4.99427784e-08]\n",
      "weight after\t[-0.8429226  -0.14033539]\n",
      "Progress: 97.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429226  -0.14033539]\n",
      "gradient\t[-3.93837877e-10  2.34076003e-11]\n",
      "weight after\t[-0.8429226  -0.14033539]\n",
      "Progress: 97.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429226  -0.14033539]\n",
      "gradient\t[-1.72731173e-09  1.54192021e-08]\n",
      "weight after\t[-0.8429226  -0.14033538]\n",
      "Progress: 97.1% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429226  -0.14033538]\n",
      "gradient\t[-4.04183456e-09  3.05261686e-09]\n",
      "weight after\t[-0.84292261 -0.14033538]\n",
      "Progress: 97.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292261 -0.14033538]\n",
      "gradient\t[-1.36645011e-08  4.37751732e-08]\n",
      "weight after\t[-0.84292262 -0.14033533]\n",
      "Progress: 97.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292262 -0.14033533]\n",
      "gradient\t[-1.01057150e-08  2.70546003e-08]\n",
      "weight after\t[-0.84292263 -0.1403353 ]\n",
      "Progress: 97.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292263 -0.1403353 ]\n",
      "gradient\t[-1.35842821e-08  1.07354231e-08]\n",
      "weight after\t[-0.84292265 -0.14033529]\n",
      "Progress: 97.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292265 -0.14033529]\n",
      "gradient\t[-3.06978621e-08  4.04960028e-08]\n",
      "weight after\t[-0.84292268 -0.14033525]\n",
      "Progress: 97.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292268 -0.14033525]\n",
      "gradient\t[-1.80898297e-08  2.15220149e-08]\n",
      "weight after\t[-0.84292269 -0.14033523]\n",
      "Progress: 97.4% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292269 -0.14033523]\n",
      "gradient\t[-1.01566491e-09  4.55654647e-08]\n",
      "weight after\t[-0.84292269 -0.14033519]\n",
      "Progress: 97.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292269 -0.14033519]\n",
      "gradient\t[-3.25941165e-09  3.12766381e-08]\n",
      "weight after\t[-0.8429227  -0.14033516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 97.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429227  -0.14033516]\n",
      "gradient\t[-1.47753325e-09  2.73543726e-09]\n",
      "weight after\t[-0.8429227  -0.14033515]\n",
      "Progress: 97.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429227  -0.14033515]\n",
      "gradient\t[-3.12741660e-08  3.76363691e-08]\n",
      "weight after\t[-0.84292273 -0.14033512]\n",
      "Progress: 97.6% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292273 -0.14033512]\n",
      "gradient\t[-1.92482904e-08  3.50719302e-08]\n",
      "weight after\t[-0.84292275 -0.14033508]\n",
      "Progress: 97.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292275 -0.14033508]\n",
      "gradient\t[-1.65208127e-08  1.81865603e-08]\n",
      "weight after\t[-0.84292277 -0.14033506]\n",
      "Progress: 97.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292277 -0.14033506]\n",
      "gradient\t[-2.42440576e-08  3.89645501e-08]\n",
      "weight after\t[-0.84292279 -0.14033502]\n",
      "Progress: 97.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292279 -0.14033502]\n",
      "gradient\t[-1.82405070e-08  3.16921752e-08]\n",
      "weight after\t[-0.84292281 -0.14033499]\n",
      "Progress: 97.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292281 -0.14033499]\n",
      "gradient\t[-4.07603561e-08  5.21680797e-08]\n",
      "weight after\t[-0.84292285 -0.14033494]\n",
      "Progress: 97.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292285 -0.14033494]\n",
      "gradient\t[-3.14739623e-09  4.20117262e-09]\n",
      "weight after\t[-0.84292285 -0.14033493]\n",
      "Progress: 97.9% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292285 -0.14033493]\n",
      "gradient\t[-1.98477898e-08  2.41321904e-08]\n",
      "weight after\t[-0.84292287 -0.14033491]\n",
      "Progress: 98.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292287 -0.14033491]\n",
      "gradient\t[-3.24580078e-08  9.91522954e-08]\n",
      "weight after\t[-0.84292291 -0.14033481]\n",
      "Progress: 98.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292291 -0.14033481]\n",
      "gradient\t[-6.66482008e-10  4.45213220e-08]\n",
      "weight after\t[-0.84292291 -0.14033477]\n",
      "Progress: 98.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292291 -0.14033477]\n",
      "gradient\t[-3.01360128e-09  3.83638924e-09]\n",
      "weight after\t[-0.84292291 -0.14033476]\n",
      "Progress: 98.1% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292291 -0.14033476]\n",
      "gradient\t[-8.32968696e-09  5.65377176e-09]\n",
      "weight after\t[-0.84292292 -0.14033476]\n",
      "Progress: 98.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292292 -0.14033476]\n",
      "gradient\t[-1.53389321e-09  5.91203411e-08]\n",
      "weight after\t[-0.84292292 -0.1403347 ]\n",
      "Progress: 98.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292292 -0.1403347 ]\n",
      "gradient\t[-2.94732441e-08  8.95441548e-08]\n",
      "weight after\t[-0.84292295 -0.14033461]\n",
      "Progress: 98.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292295 -0.14033461]\n",
      "gradient\t[-1.77154229e-08  2.03395460e-08]\n",
      "weight after\t[-0.84292297 -0.14033459]\n",
      "Progress: 98.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292297 -0.14033459]\n",
      "gradient\t[-4.41609667e-09  1.88050416e-08]\n",
      "weight after\t[-0.84292297 -0.14033457]\n",
      "Progress: 98.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292297 -0.14033457]\n",
      "gradient\t[-1.03538937e-08  8.37183447e-09]\n",
      "weight after\t[-0.84292298 -0.14033456]\n",
      "Progress: 98.4% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292298 -0.14033456]\n",
      "gradient\t[-6.14174449e-09  4.99742501e-09]\n",
      "weight after\t[-0.84292299 -0.14033456]\n",
      "Progress: 98.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292299 -0.14033456]\n",
      "gradient\t[-3.35737394e-08  5.53698030e-08]\n",
      "weight after\t[-0.84292302 -0.1403345 ]\n",
      "Progress: 98.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292302 -0.1403345 ]\n",
      "gradient\t[-2.53064009e-08  5.53147675e-08]\n",
      "weight after\t[-0.84292305 -0.14033445]\n",
      "Progress: 98.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292305 -0.14033445]\n",
      "gradient\t[-8.19505526e-09  2.39786182e-08]\n",
      "weight after\t[-0.84292305 -0.14033442]\n",
      "Progress: 98.6% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292305 -0.14033442]\n",
      "gradient\t[-4.43774360e-10  9.23617902e-10]\n",
      "weight after\t[-0.84292305 -0.14033442]\n",
      "Progress: 98.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292305 -0.14033442]\n",
      "gradient\t[-1.71405279e-08  2.31516150e-08]\n",
      "weight after\t[-0.84292307 -0.1403344 ]\n",
      "Progress: 98.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292307 -0.1403344 ]\n",
      "gradient\t[-2.45529386e-08  4.21600990e-08]\n",
      "weight after\t[-0.8429231  -0.14033436]\n",
      "Progress: 98.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429231  -0.14033436]\n",
      "gradient\t[-9.19642567e-09  1.41327347e-07]\n",
      "weight after\t[-0.84292311 -0.14033421]\n",
      "Progress: 98.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292311 -0.14033421]\n",
      "gradient\t[-1.82859134e-08  4.72669015e-08]\n",
      "weight after\t[-0.84292312 -0.14033417]\n",
      "Progress: 98.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292312 -0.14033417]\n",
      "gradient\t[-1.64236531e-08  3.32000188e-08]\n",
      "weight after\t[-0.84292314 -0.14033413]\n",
      "Progress: 98.9% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292314 -0.14033413]\n",
      "gradient\t[-1.61236130e-08  3.20420858e-08]\n",
      "weight after\t[-0.84292316 -0.1403341 ]\n",
      "Progress: 99.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292316 -0.1403341 ]\n",
      "gradient\t[-2.33154850e-08  2.07242317e-08]\n",
      "weight after\t[-0.84292318 -0.14033408]\n",
      "Progress: 99.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292318 -0.14033408]\n",
      "gradient\t[-1.68392093e-08  1.77209307e-08]\n",
      "weight after\t[-0.8429232  -0.14033406]\n",
      "Progress: 99.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429232  -0.14033406]\n",
      "gradient\t[-7.53552183e-09  8.27677035e-09]\n",
      "weight after\t[-0.8429232  -0.14033405]\n",
      "Progress: 99.1% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429232  -0.14033405]\n",
      "gradient\t[-3.34288441e-09  5.28183152e-09]\n",
      "weight after\t[-0.84292321 -0.14033405]\n",
      "Progress: 99.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292321 -0.14033405]\n",
      "gradient\t[-3.70504965e-09  4.84846423e-08]\n",
      "weight after\t[-0.84292321 -0.140334  ]\n",
      "Progress: 99.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292321 -0.140334  ]\n",
      "gradient\t[-1.75585895e-08  2.17766409e-08]\n",
      "weight after\t[-0.84292323 -0.14033398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 99.2% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292323 -0.14033398]\n",
      "gradient\t[-1.00560745e-08  1.12480085e-07]\n",
      "weight after\t[-0.84292324 -0.14033387]\n",
      "Progress: 99.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292324 -0.14033387]\n",
      "gradient\t[-1.81299170e-08  4.65443602e-08]\n",
      "weight after\t[-0.84292326 -0.14033382]\n",
      "Progress: 99.3% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292326 -0.14033382]\n",
      "gradient\t[-1.75414207e-08  3.52904706e-08]\n",
      "weight after\t[-0.84292327 -0.14033378]\n",
      "Progress: 99.4% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292327 -0.14033378]\n",
      "gradient\t[-2.31928287e-08  2.48917374e-08]\n",
      "weight after\t[-0.8429233  -0.14033376]\n",
      "Progress: 99.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429233  -0.14033376]\n",
      "gradient\t[-4.08639357e-08  8.71690073e-08]\n",
      "weight after\t[-0.84292334 -0.14033367]\n",
      "Progress: 99.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292334 -0.14033367]\n",
      "gradient\t[-6.41647037e-08  1.05343697e-07]\n",
      "weight after\t[-0.8429234  -0.14033357]\n",
      "Progress: 99.5% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.8429234  -0.14033357]\n",
      "gradient\t[-4.93625992e-08  7.26306769e-08]\n",
      "weight after\t[-0.84292345 -0.14033349]\n",
      "Progress: 99.6% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292345 -0.14033349]\n",
      "gradient\t[-1.2277183e-09  9.0206006e-10]\n",
      "weight after\t[-0.84292345 -0.14033349]\n",
      "Progress: 99.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292345 -0.14033349]\n",
      "gradient\t[-1.62125621e-08  1.65537031e-08]\n",
      "weight after\t[-0.84292347 -0.14033348]\n",
      "Progress: 99.7% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292347 -0.14033348]\n",
      "gradient\t[-1.85975463e-08  2.04550876e-08]\n",
      "weight after\t[-0.84292349 -0.14033346]\n",
      "Progress: 99.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292349 -0.14033346]\n",
      "gradient\t[-1.78039680e-08  2.21293147e-08]\n",
      "weight after\t[-0.84292351 -0.14033343]\n",
      "Progress: 99.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292351 -0.14033343]\n",
      "gradient\t[-1.59015354e-08  1.64304664e-08]\n",
      "weight after\t[-0.84292352 -0.14033342]\n",
      "Progress: 99.8% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292352 -0.14033342]\n",
      "gradient\t[-3.86098197e-09  3.00185064e-08]\n",
      "weight after\t[-0.84292353 -0.14033339]\n",
      "Progress: 99.9% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n",
      "\n",
      "weight before\t[-0.84292353 -0.14033339]\n",
      "gradient\t[-5.57310800e-09  1.90559884e-08]\n",
      "weight after\t[-0.84292353 -0.14033337]\n",
      "Progress: 100.0% ... Training loss: 0.490 ... Validation loss: 0.489 ... Training Acc: 1.0 ... Validation Acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "#### Train ####\n",
    "losses = {'train':[], 'validation':[]}\n",
    "accuracy = {'train':[], 'validation':[]}\n",
    "\n",
    "weight_history = []\n",
    "weight_history.append(network.getWeights())\n",
    "biases_history = []\n",
    "biases_history.append(network.getBiases())\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    batch_indices = np.random.choice(list(range(x_train.shape[0])), size = batch_size)\n",
    "    features = np.array([x_train[i] for i in batch_indices])\n",
    "    targets = np.array([y_train[i] for i in batch_indices])\n",
    "    \n",
    "    network.train(features, targets)\n",
    "    weight_history.append(network.getWeights())\n",
    "    biases_history.append(network.getBiases())\n",
    "    \n",
    "    # Printing out the training progress\n",
    "    train_loss = MSE(network.predict(x_train).T, y_train_raw)\n",
    "    val_loss = MSE(network.predict(x_test).T, y_test_raw)\n",
    "    train_acc = network.test(x_train, y_train)\n",
    "    val_acc = network.test(x_train, y_train)\n",
    "    sys.stdout.write(\"\\rProgress: {:2.1f}%\".format(100 * epoch/float(n_epochs)) \\\n",
    "                     + \" ... Training loss: \" + str(train_loss)[:5] \\\n",
    "                     + \" ... Validation loss: \" + str(val_loss)[:5] \\\n",
    "                     + \" ... Training Acc: \" + str(train_acc)[:5] \\\n",
    "                     + \" ... Validation Acc: \" + str(val_acc)[:5])\n",
    "    sys.stdout.flush()\n",
    "    print()\n",
    "    \n",
    "    losses['train'].append(train_loss)\n",
    "    losses['validation'].append(val_loss)\n",
    "    accuracy['train'].append(train_acc)\n",
    "    accuracy['validation'].append(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey = False, sharex = False, figsize=(16, 6))\n",
    "\n",
    "_ = ax1.plot(losses['train'], label='Training loss')\n",
    "_ = ax1.plot(losses['validation'], label='Validation loss')\n",
    "\n",
    "_ = ax2.plot(accuracy['train'], label='Training acc')\n",
    "_ = ax2.plot(accuracy['validation'], label='Validation acc')\n",
    "\n",
    "_ = fig.legend()\n",
    "# plt.plot(losses['train'], label='Training loss')\n",
    "# plt.plot(losses['validation'], label='Validation loss')\n",
    "# plt.legend()\n",
    "# _ = plt.ylim()\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(accuracy['train'], label='Training acc')\n",
    "# plt.plot(accuracy['validation'], label='Validation acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Train Set: 1.0\n",
      "Accuracy on Test Set: 0.995\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "[[False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "[[False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on Train Set:\", network.test(x_train, y_train))\n",
    "print(\"Accuracy on Test Set:\", network.test(x_test, y_test))\n",
    "\n",
    "np.set_printoptions(precision = 20)\n",
    "# print(weight_history[0])\n",
    "# print()\n",
    "# print(weight_history[-1])\n",
    "print(np.not_equal(weight_history[0][1], weight_history[-1][1]))\n",
    "\n",
    "for j in range(len(weight_history[0])):\n",
    "    print(np.not_equal(weight_history[0][j], weight_history[-1][j]))\n",
    "#     for i in range(len(weight_history[0])):\n",
    "#         if not np.array_equal(weight_history[0][i], weight_history[j][i]):\n",
    "#             print(weight_history[0][i])\n",
    "#             print(weight_history[j][i])\n",
    "#             print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Prediction 426/2000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-8f548579c1af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0marea_map_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marea_map_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0marea_map_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marea_map_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-4f0aa5b0f130>\u001b[0m in \u001b[0;36marea_map_plot\u001b[0;34m(network, area_map_set, features, targets, path, alpha)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, frameon, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2092\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2094\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2075\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2076\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \"\"\"\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mtoolbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoolbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1649\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2626\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2628\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/collections.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         \u001b[0mCollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/collections.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linewidths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linestyles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_antialiaseds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_urls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 self._offset_position)\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/path.py\u001b[0m in \u001b[0;36mvertices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_nonfinite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vertices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvertices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "area_map_set = generate_area_map(features)\n",
    "paths = []\n",
    "\n",
    "for n , (weights, biases) in enumerate(zip(weight_history, biases_history)):\n",
    "    sys.stdout.write('\\rEpoch Prediction {}/{}'.format(str(n), str(n_epochs)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # gets the current model for the epoch\n",
    "    network.setWeights(weights)\n",
    "    network.setBiases(biases)\n",
    "    \n",
    "    # saves the path that the image will be saved to\n",
    "    path = '{}{}.png'.format('figs/', 'prediction_map-{}'.format(str(n)))\n",
    "    paths.append(path)\n",
    "\n",
    "    area_map_plot(network, area_map_set, x_test, y_test_raw, path = path)\n",
    "    \n",
    "area_map_plot(network, area_map_set, x_test, y_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from imageio import imread\n",
    "from imageio import mimsave\n",
    "\n",
    "# combines all the areamap plots into a gif\n",
    "images = []\n",
    "for img in paths:\n",
    "    images.append(imread(img))\n",
    "\n",
    "cur_time = time.time()\n",
    "mimsave('{}neural_network{}.gif'.format('', cur_time), images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### END OF NOTEBOOK ####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
